var suggestions=document.getElementById("suggestions"),search=document.getElementById("search");search!==null&&document.addEventListener("keydown",inputFocus);function inputFocus(e){e.ctrlKey&&e.key==="/"&&(e.preventDefault(),search.focus()),e.key==="Escape"&&(search.blur(),suggestions.classList.add("d-none"))}document.addEventListener("click",function(e){var t=suggestions.contains(e.target);t||suggestions.classList.add("d-none")}),document.addEventListener("keydown",suggestionFocus);function suggestionFocus(e){const s=suggestions.classList.contains("d-none");if(s)return;const t=[...suggestions.querySelectorAll("a")];if(t.length===0)return;const n=t.indexOf(document.activeElement);if(e.key==="ArrowUp"){e.preventDefault();const s=n>0?n-1:0;t[s].focus()}else if(e.key==="ArrowDown"){e.preventDefault();const s=n+1<t.length?n+1:n;t[s].focus()}}(function(){var e=new FlexSearch.Document({tokenize:"forward",cache:100,document:{id:"id",store:["href","title","description"],index:["title","description","content"]}});e.add({id:0,href:"/docs/class-0/",title:"Prologue",description:"Class 0",content:""}),e.add({id:1,href:"/docs/class-0/getting-started/",title:"Getting Started",description:`Discord Server # We will use Discord to communicate between class meetings. Please use this forum to post any questions or comments.
Join the class Discord server using the invitation link: https://discord.gg/WaH4haCmmn. Note that we are using the same server as previous classes, so you may see some activity there from before. IDE Installation # Unlike other tools like Processing or TouchDesigner, openFrameworks does not come with its own development environment (IDE).`,content:`Discord Server # We will use Discord to communicate between class meetings. Please use this forum to post any questions or comments.
Join the class Discord server using the invitation link: https://discord.gg/WaH4haCmmn. Note that we are using the same server as previous classes, so you may see some activity there from before. IDE Installation # Unlike other tools like Processing or TouchDesigner, openFrameworks does not come with its own development environment (IDE). You will need to install this separately.
IDEs can be large downloads and take up a lot of disk space, so its best to install these before the start of class.
macOS # We will use Xcode on macOS.
Download Xcode directly from the Mac App Store. Wait for the download and installation to complete. Open a Terminal window (You can find the Terminal in /Applications/Utilities/Terminal.app). Install the command line tools by typing in the command (then hit ENTER!) xcode-select --install Windows # We will use Visual Studio on Windows.
Download Visual Studio Community 2022 from the official site. Open the Visual Studio Installer and select the Desktop environment with C++ workload. Press Install or Modify in the bottom right corner of the window. Wait for the download and installation to complete. `}),e.add({id:2,href:"/docs/assignments/assignment-1/",title:"Assignment 1",description:`Conway\u0026rsquo;s Game of Life # Conway\u0026rsquo;s Game of Life is a cellular automata simulation where a 2D grid of cells evolve between alive and dead states.
The Game of Life is a zero-player game, where you just set the initial state and the rules, and watch the evolution happen. A cell\u0026rsquo;s state in the next frame depends on the state of its immediate neighbors in the current frame. It is set by counting the number of live or dead neighbors and applying the corresponding rule.`,content:`Conway\u0026rsquo;s Game of Life # Conway\u0026rsquo;s Game of Life is a cellular automata simulation where a 2D grid of cells evolve between alive and dead states.
The Game of Life is a zero-player game, where you just set the initial state and the rules, and watch the evolution happen. A cell\u0026rsquo;s state in the next frame depends on the state of its immediate neighbors in the current frame. It is set by counting the number of live or dead neighbors and applying the corresponding rule. Depending on this initial state and rules, interesting patterns can emerge where cells can appear to oscillate or travel across the board. Instructions # Your assignment is to build your version of the Game of Life using openFrameworks. This will give you an opportunity to play with an image\u0026rsquo;s pixel data.
Use an ofImage as your 2D canvas. Set black 0 as the pixel value for a dead cell, and white 255 as the pixel value for a live cell. Set the initial values to whatever you want. You can use random values or try a pattern. Neighbors are the pixels on the top-left, top-center, top-right, middle-left, middle-right, bottom-left, bottom-center, and bottom-right (8 neighbors total). Make sure to handle edge cases appropriately! You can either ignore the invalid neighbors or wrap around the texture. We will follow the same rules as the original game of life:
Isolation: a live ⬜ cell with less than 2 live neighbors will die 😥. Overcrowding: a live ⬜ cell with 4 or more neighbors will die 😵. Reproduction: a dead ⬛ cell with exactly 3 live neighbors will live 🐣. Here is some pseudo-code representing these rules:
for (each cell in image): count live neighbors if (cell is live): if (num live neighbors \u0026lt; 2): cell dies if (num live neighbors \u0026gt; 3): cell dies if (cell is dead): if (num live neighbors == 3): cell lives Sorry, your browser doesn't support embedded videos. Hint: How can we fill an ofImage with values? ofImage.allocate() will allocate memory for the image without having to load a file from disk. ofImage.getPixels() will return an ofPixels object which we can use to access the pixel data. ofImage.getPixels() makes a copy of the pixel data. After we make our edits, we need to save the new data back to the ofImage using ofImage.setFromPixels(). lifeImg.allocate(40, 30, OF_IMAGE_GRAYSCALE); ofPixels lifePix = lifeImg.getPixels(); for (int y = 0; y \u0026lt; lifeImg.getHeight(); y++) { for (int x = 0; x \u0026lt; lifeImg.getWidth(); x++) { if (ofRandomuf() \u0026lt; 0.5) { lifePix.setColor(x, y, ofColor(0)); } else { lifePix.setColor(x, y, ofColor(255)); } } } // getPixels() makes a copy of the pixels, so we need to // use setFromPixels to set the new values back on the image. lifeImg.setFromPixels(lifePix); Bonus Points! # If you are looking for an additional challenge, try adding the following extra features:
Press a key to pause / start the simulation. Press a key to reset the grid to random values. Press a key to set the grid to all live cells, and another for all dead cells. Click the mouse on a cell and toggle its state! Delivery # Name your project SM01-FirstLast where First is your first name and Last is your last name. - OF/ - apps/ - seeing-machines/ - SM01-ElieZananiri/ - src/ - bin/ - addons.make - SM01-ElieZananiri.sln - SM01-ElieZananiri.vcxproj - ... Only submit the necessary files to rebuild your project.
This includes sources, the addons.make file, and any resources in your data folder. No project or compiled files. In the example above, you would only keep the src folder, addons.make file, and bin/data if you are using any external assets. Zip the SM01-ElieZananiri parent directory. - seeing-machines/ - SM01-ElieZananiri/ - src/ - addons.make OPTIONAL In true ITP fashion, you can make a blog post about your project. If you do, please send me the link!
Post your project link to the #assignments-25 channel on our Discord server. Do not send it by email. Do not send it as a DM.
Attach the packaged ZIP to your message. If that does not work, upload it to Google Drive and send the link. If you made a blog post or added your project to GitHub, send a link to that too. Come to class with a working project on a working computer, and be prepared to talk and answer questions about it. Time allowing, some of you will demo your projects to the class!
Thank you!
`}),e.add({id:3,href:"/docs/class-1/",title:"Class 1",description:"Class 1",content:""}),e.add({id:4,href:"/docs/class-1/foreword/",title:"Foreword",description:`Introductions # A bit about me:
Beta Movement A bit about you:
What did you do before ITP? Tell me about your programming experience. What are you hoping to get out of the class? Senses # What is a sense? # A capacity that allows organisms to perceive the conditions or properties of things, either around them or internally.
Human senses # We have traditionally only considered five human senses:`,content:`Introductions # A bit about me:
Beta Movement A bit about you:
What did you do before ITP? Tell me about your programming experience. What are you hoping to get out of the class? Senses # What is a sense? # A capacity that allows organisms to perceive the conditions or properties of things, either around them or internally.
Human senses # We have traditionally only considered five human senses:
Sight Hearing Smell Taste Touch Which of these would you say we use more predominantly? Neurologist Dr. Wilder Penfield conceived the Sensory Homuncilus, a physical representation of how the human body would look if the various body parts were sized in proportion to the cortical area used for their specific sensory functions.
A 2-D cortical sensory homunculus 3-D interpretation by Sharon Price James This is a simplification, but demonstrates that touch is the most predominant sense, followed by taste, hearing, smell, and finally sight.
We also have many other senses, which we use in our daily life but are less obvious:
Equilibrium Temperature Pain Thirst and hunger Direction Time Etc. Modeling machines # In order to get machines to understand their environment, we tend to outfit them with sensors that are similar to our own senses.
What are some sensors that we use on computers? Sight Digital camera IR receiver Hearing Microphone Touch Trackpad Pressure sensor Keyboard Equilibrium Gyroscope Direction Magnetometer Compass You\u0026rsquo;ve probably used some of these in your previous classes and projects.
The right tool for the job # The focus of Seeing Machines will be to use sensors with computers (rather than microcontrollers), for the purpose of building successful interactive experiences.
The devices we will use will have SDKs (software development kits) and interfaces for many platforms and languages. This is great as it allows us to use something we are already familiar with, however some tools are better suited than others for specific tasks. For example, Python is great at text and language processing, Max is best at sound analysis, and Unity is ideal to get up and running with VR.
A lot of these platforms use very similar paradigms, and the difficulty of moving from one to the other tends to be more about getting familiar with a new environment and different coding syntax than anything else.
The majority of the programming for this class will be done in openFrameworks (OF) and we will sometimes detour to another platform when it makes sense. While C++ can be daunting, it is a very high performance language that is widely used, and OF takes a lot of the initial hurdles away!
About halfway through the semester, we will have a lecture on communication, where we will learn various methods for different pieces of software and hardware \u0026ldquo;talk\u0026rdquo; to each other.
`}),e.add({id:5,href:"/docs/class-1/intro-to-of/",title:"Intro to OF",description:`What is openFrameworks? # openFrameworks (OF) is an open source cross-platform C++ toolkit designed to assist the creative process, by providing a simple and intuitive framework for experimentation.
OF is distributed under the MIT License, which gives everyone the freedoms to use openFrameworks in any context:
Commercial or non-commercial. Public or private. Open or closed source. What is C++? # A programming language. General purpose. Fairly low level, but can be programmed in a high level way.`,content:`What is openFrameworks? # openFrameworks (OF) is an open source cross-platform C++ toolkit designed to assist the creative process, by providing a simple and intuitive framework for experimentation.
OF is distributed under the MIT License, which gives everyone the freedoms to use openFrameworks in any context:
Commercial or non-commercial. Public or private. Open or closed source. What is C++? # A programming language. General purpose. Fairly low level, but can be programmed in a high level way. Compiled (it\u0026rsquo;s really fast). Widely used. Libraries # OF is written in C++. It makes it easier to interface with the many libraries that have been written in C and C++ without needing to rely on a wrapper for another language.
Libraries are collections of code that do something common or useful. For example:
OpenGL for drawing graphics. FreeType for loading and rendering fonts. FreeImage for loading image files. AVFoundation for playing videos. OF is the glue that ensures these libraries work together well.
It is a consistent and intuitive interface to these libraries.
For example, loading a font using FreeType directly would look something like this:
FT_New_Face(...); FT_Set_Char_Size(...); And with OF would look like this:
ofTrueTypeFont font; font.load(...); Loading an image using FreeImage directly:
FreeImage_OpenMemory(...); FreeImage_LoadFromMemory(...); FreeImage_GetBits(...); And with OF:
ofImage img; img.load(...); Open Source # OF is distributed as source code.
An open book, giving the curious a good starting point for learning about C++ library wrangling. A work in progress, keeping the code visible allowing for easier changes and feedback. An invitation for users to modify the toolkit to their taste or needs. Over 70 people have contributed to the core, and there are more than 1500 addons extending the base functionality of the toolkit.
Comparisons with Processing # openFrameworks and Processing have many similarities. In fact, OF is inspired by Processing!
When possible, openFrameworks tries to maintain parity with Processing, making moving from one to the other very easy. Compare the following code snippets:
void setup() { frameRate(60); background(0); } void draw() { fill(255, 0, 0); rect(10, 10, 50, 50); } void ofApp::setup() { ofSetFrameRate(60); ofBackground(0); } void ofApp::draw() { ofSetColor(255, 0, 0); ofDrawRectangle(10, 10, 50, 50); } ✌️ What does the :: mean?
:: is a scope resolution operator in C++. It is used to show the relationship between methods (functions) and classes. Methods can be defined anywhere in the source code, so we need a way to know where they belong when they are defined.
For example, void ofApp::draw() means \u0026ldquo;define the draw() function that belongs to the ofApp class\u0026rdquo;.
Getting Started # Installation # Download the openFrameworks package for your environment.
Follow the corresponding setup guide.
Unlike Processing, OF does not come with its own development environment (IDE). Instructions to set this up will be included in the guide. You will use Xcode for development under macOS and Visual Studio for development under Windows. Please refer to the Getting Started page for details. ⚠️ If you encounter a build system error when compiling for Xcode, try changing the Build System dropdown in the Project Settings.
Project Generation # To create a new project, you are strongly encouraged to use the OF Project Generator.
This application can be found in your downloaded package, under /path/to/OF/projectGenerator-XXX. The Project Generator will take care of adding any files and libraries needed to build your applications. The first time you run the Project Generator, you\u0026rsquo;ll be asked to set the path to the openFrameworks installation on your system.
You can then create a project by giving it a name and a save path. It is recommended to save your projects under path/to/OF/apps/seeing-machines/.
Click Generate to create the project files. Once that is complete, you can click on the Open in IDE button to open the project.
Anatomy of an OF Project # A basic OF project will include three files you can edit.
main.cpp contains the main() function. This is the entry point to the program.
The main function is where the application window is set. You can set up the window dimensions, renderer used, graphics quality, additional windows, etc.
#include \u0026quot;ofMain.h\u0026quot; #include \u0026quot;ofApp.h\u0026quot; int main() { ofSetupOpenGL(1920, 1080, OF_WINDOW); ofRunApp(new ofApp()); } ✌️ What does #include mean?
The # symbol is used to indicate a compiler directive. When a file has the line #include \u0026quot;someFile.h\u0026quot;, this tells the compiler to insert the code from that specific file into the source code.
If we want to use any classes or functions defined in other files, we need to #include these in our code so that the compiler knows where to look for them.
The other two files define the ofApp class. You can think of ofApp as the main class that holds and runs all the components belonging to your program, kind of like a sketch in Processing.
In C++, classes are defined in two parts: the header (declaration) and the implementation (definition). The header defines what a class is, and the implementation defines how a class operates.
The header will usually have extension .h or .hpp. This is where all variables and methods in the class are listed. You can think of this as a table of contents for the class. When classes link to each other using #include, they will only refer to the header class as they only need to \u0026ldquo;know\u0026rdquo; what variables and methods are available to them, but not how these are implemented. This reduces dependencies and in turn compilation times.
#pragma once #include \u0026quot;ofMain.h\u0026quot; class ofApp : public ofBaseApp { public: void setup(); void update(); void draw(); void keyPressed(int key); void keyReleased(int key); void mouseMoved(int x, int y); void mouseDragged(int x, int y, int button); void mousePressed(int x, int y, int button); void mouseReleased(int x, int y, int button); void mouseEntered(int x, int y); void mouseExited(int x, int y); void windowResized(int w, int h); void dragEvent(ofDragInfo dragInfo); void gotMessage(ofMessage msg); }; ✌️ What does #pragma once mean?
We now know #include will insert the contents of another file into our code, however we only want to include every piece of code once in our application. You will notice many files will have #include \u0026quot;ofMain.h\u0026quot; at the top, but that code cannot be inserted over and over, as this will give us duplicate classes and functions with the same name.
This is where the #pragma once directive comes in. It tells the compiler to only include the contents of the file once, no matter how many times it is referenced with #include.
As a general rule, you should always start your header files with the line #pragma once.
The implementation will have extension .cpp. This is where all the methods declared in the header are defined.
#include \u0026quot;ofApp.h\u0026quot; void ofApp::setup() { // Called once at app startup. } void ofApp::update() { // Called at the start of every frame. } void ofApp::draw() { // Called every frame after update. } void ofApp::keyPressed(int key) { // Called when a key is pressed. } void ofApp::keyReleased(int key) { // Called when a key is released. } void ofApp::mouseMoved(int x, int y) { // Called when the mouse is moved and no buttons are pressed. } void ofApp::mouseDragged(int x, int y, int button) { // Called when the mouse is moved while a button is pressed down. } void ofApp::mousePressed(int x, int y, int button) { // Called when a mouse button is pressed. } void ofApp::mouseReleased(int x, int y, int button) { // Called when a mouse button is released. } void ofApp::mouseEntered(int x, int y) { // Called when the mouse cursor enters the application window. } void ofApp::mouseExited(int x, int y) { // Called when the mouse cursor exits the application window. } void ofApp::windowResized(int w, int h) { // Called when the application window is resized. } void ofApp::gotMessage(ofMessage msg) { // I have no idea :/ } void ofApp::dragEvent(ofDragInfo dragInfo) { // Called when a file or set of files are dragged onto the application window. } Note that the placeholder ofApp already has stubs for common methods you may want to use. You can keep these in or delete them, but if you get rid of them you\u0026rsquo;ll need to do so in both the header and the implementation files.
Reference # OF ships with a multitude of examples in the path/to/OF/examples folder, and this is the best way to get familiar with the tool. Note that project files need to be created for these using the Project Generator before they can be built.
OF also has comprehensive documentation on its website, as well as an active user forum, which are other great places to get information.
`}),e.add({id:6,href:"/docs/class-2/",title:"Class 2",description:"Class 2",content:""}),e.add({id:7,href:"/docs/assignments/assignment-2/",title:"Assignment 2",description:`Video Effect # Instructions # Your assignment is to create an original video effect using openFrameworks and OpenCV. This will give you an opportunity to play with an image’s pixel data, and to get familiar with computer vision algorithms.
You can use some of the algorithms we covered in class (background subtraction, color tracking, etc.) or any other CV algorithm. Make sure to browse through ofxCv examples to see what is available to you!`,content:`Video Effect # Instructions # Your assignment is to create an original video effect using openFrameworks and OpenCV. This will give you an opportunity to play with an image’s pixel data, and to get familiar with computer vision algorithms.
You can use some of the algorithms we covered in class (background subtraction, color tracking, etc.) or any other CV algorithm. Make sure to browse through ofxCv examples to see what is available to you! If you have an idea but are not sure how to do it, ask about it on Discord and we can break it down and figure it out together. Expose your parameters and use a GUI or some form of controller to tweak them for best results. Some of you will demo your project in class. Your effect should therefore work in the conditions of our classroom (size, layout, light, etc.) Bonus Points! # If you are looking for an additional challenge, try adding the following extra features:
Press a key or GUI button to freeze / restart the video capture. Press a key or GUI toggle to switch between live video (ofVideoGrabber) and on-disk video (ofVideoPlayer) as the input. Delivery # Name your project SM02-FirstLast where First is your first name and Last is your last name. - OF/ - apps/ - seeing-machines/ - SM02-ElieZananiri/ - src/ - bin/ - addons.make - SM02-ElieZananiri.sln - SM02-ElieZananiri.vcxproj - ... Only submit the necessary files to rebuild your project.
This includes sources, the addons.make file, and any resources in your data folder. No project or compiled files. In the example above, you would only keep the src folder, addons.make file, and bin/data if you are using any external assets. Zip the SM02-ElieZananiri parent directory. - seeing-machines/ - SM02-ElieZananiri/ - src/ - addons.make OPTIONAL In true ITP fashion, you can make a blog post about your project. If you do, please send me the link!
Post your project link to the #assignments-25 channel on our Discord server. Do not send it by email. Do not send it as a DM.
Attach the packaged ZIP to your message. If that does not work, upload it to Google Drive and send the link. If you made a blog post or added your project to GitHub, send a link to that too. Come to class with a working project on a working computer, and be prepared to talk and answer questions about it. Time allowing, some of you will demo your projects to the class!
Thank you!
`}),e.add({id:8,href:"/docs/class-2/data-types/",title:"Data Types",description:`Let\u0026rsquo;s start with the basics and review data types in C++.
Main Primitives # int # 32 bits of data (usually but not always) represents a whole number between -2,147,483,648 and 2,147,483,647 int videoWidth = 1920; int videoHeight = 1080; int numVideoPixels = videoWidth * videoHeight; integers do not support decimal points ✌️ Integer division / and modulo % operators
Operations on integers return integers. This is particularly important to remember with division /.`,content:`Let\u0026rsquo;s start with the basics and review data types in C++.
Main Primitives # int # 32 bits of data (usually but not always) represents a whole number between -2,147,483,648 and 2,147,483,647 int videoWidth = 1920; int videoHeight = 1080; int numVideoPixels = videoWidth * videoHeight; integers do not support decimal points ✌️ Integer division / and modulo % operators
Operations on integers return integers. This is particularly important to remember with division /.
int numStudents = 17; int studentsPerTeam = 4; int numTeams = numStudents / studentsPerTeam; // 4 not 4.25! The modulo % operator is used on integers to get the remainder of a division.
int leftoverStudents = numStudents % studentsPerTeam; // 1 student without a team :( unsigned int # the unsigned (no +/- sign) version of int, only positive numbers represents 0 and positive whole numbers up to 4,294,967,295 char # 8 bits of data represents a whole number between -128 and 127 char numStudents = 17; char studentsPerTeam = 4; char numTeams = numStudents / studentsPerTeam; // 4 not 4.25! if we try to use a char to represent a larger number, we will end up with the wrong value but C++ will not flag an error! char videoWidth = 1920; // ? unsigned char # the unsigned (no +/- sign) version of char, only positive numbers represents 0 and positive whole numbers up to 255 often used to represent characters in a string, using the ASCII table for conversion unsigned char H = 72; unsigned char i = 'i'; cout \u0026lt;\u0026lt; H \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl; ✌️ What do cout and endl do?
cout is a command to send text output to the console. The \u0026lt;\u0026lt; (left shift) operator is used to send data to the output, and can be used multiple times to add more text to the output.
New lines are not automatically added. The endl command is used to send a new line. This will usually be found at the end of a cout line of code.
bool # 1 bit of data represents true or false, 0 or 1, \u0026ldquo;yes\u0026rdquo; or \u0026ldquo;no\u0026rdquo;, etc. we can use the keywords true and false to set a boolean value bool isTheSkyBlue = true; bool isThisBoring = false; we can also use numbers, where 0 evaluates to false and any other number evaluates to true bool numStudents = 17; // true if (numStudents) { cout \u0026lt;\u0026lt; \u0026quot;Class is in session!\u0026quot; \u0026lt;\u0026lt; endl; } ⚠️ Note that even though you can use numbers to represent a boolean, the bool data type only has enough memory to represent 0 or 1.
bool numStudents = 17; cout \u0026lt;\u0026lt; \u0026quot;There are \u0026quot; \u0026lt;\u0026lt; numStudents \u0026lt;\u0026lt; \u0026quot; students in class\u0026quot; \u0026lt;\u0026lt; endl; // 1 float # 32 bits of data represents a decimal number with ~7 significant digits float is short for \u0026ldquo;floating point\u0026rdquo;, which means that the decimal point can move positions (e.g. we can represent 1.23456 and 123.456 with the same amount of memory) float videoWidth = 1920; float videoHeight = 1080; float aspectRatio = videoWidth / videoHeight; // 1.777778 Additional Primitives # The following primitive types are not used as often but are still useful if we need to optimize and use less memory, or increase precision and use more memory.
short and unsigned short # 16 bits of data represents whole numbers between -32,768 and 32,767 (signed) or 0 and 65,535 (unsigned) long and unsigned long # 64 bits of data represents whole numbers between -9M and 9M (signed) or 0 and 18M (unsigned) double # 64 bits of data represents floating point numbers with ~15 significant digits Strings # Like in most programming languages, strings (sequences of characters) are a complex class type, but they have special rules and optimizations applied to them since they are used very often.
string name = \u0026quot;John Doe\u0026quot;; string objects have a variety of methods (class functions) we can use to access their properties.
string name; if (name.empty()) { cout \u0026lt;\u0026lt; \u0026quot;No name has been set, using default...\u0026quot; \u0026lt;\u0026lt; endl; name = \u0026quot;John Doe\u0026quot;; } cout \u0026lt;\u0026lt; \u0026quot;Hello, \u0026quot; \u0026lt;\u0026lt; name \u0026lt;\u0026lt; endl; We can iterate through a string to get the characters it is made up of.
string name = \u0026quot;John Doe\u0026quot;; cout \u0026lt;\u0026lt; \u0026quot;Your name is: \u0026quot;; for (int i = 0; i \u0026lt; name.size(); i++) { cout \u0026lt;\u0026lt; name.at(i); } cout \u0026lt;\u0026lt; endl; Concatenation # string objects can be concatenated using the + operator.
string first = \u0026quot;John\u0026quot;; string last = \u0026quot;Doe\u0026quot;; string name = first + \u0026quot; \u0026quot; + last; This also sometimes works with non-string types, but not always as the compiler might not know how to use the + operator.
int videoWidth = 1920; int videoHeight = 1080; string resolution = videoWidth + \u0026quot;x\u0026quot; + videoHeight; // OK? float videoWidthf = 1920; float videoHeightf = 1080; string resolutionf = videoWidthf + \u0026quot;x\u0026quot; + videoHeightf; // ERROR! OF has ofToString() helper functions, which can be used to convert other variable types into string.
int videoWidth = 1920; int videoHeight = 1080; string resolution = ofToString(videoWidth) + \u0026quot;x\u0026quot; + ofToString(videoHeight); float videoWidthf = 1920; float videoHeightf = 1080; string resolutionf = ofToString(videoWidthf, 1) + \u0026quot;x\u0026quot; + ofToString(videoHeightf, 1); `}),e.add({id:9,href:"/docs/class-2/arrays/",title:"Arrays",description:`Array Access # Arrays are used to store multiple values of the same type under a single variable (vs declaring one variable per value).
// An array containing 10 integers (uninitialized). int values[10]; Array elements are accessed using the square bracket [] operator. We can pass in an index to access the corresponding element in the array. Note that arrays are 0-indexed (the index of the first element is 0) in C++.`,content:`Array Access # Arrays are used to store multiple values of the same type under a single variable (vs declaring one variable per value).
// An array containing 10 integers (uninitialized). int values[10]; Array elements are accessed using the square bracket [] operator. We can pass in an index to access the corresponding element in the array. Note that arrays are 0-indexed (the index of the first element is 0) in C++.
int values[10]; for (int i = 0; i \u0026lt; 10; i++) { values[i] = i + 1; } Strings as Arrays # A string is an array of char under the hood (along with some extra functionality). Each character in a string is an element in the array and can be accessed using the [] notation.
How would we print out the value of a string one character at a time, using array notation? string name = \u0026quot;John Doe\u0026quot;; cout \u0026lt;\u0026lt; \u0026quot;The name '\u0026quot;; for (int i = 0; i \u0026lt; name.size(); i++) { cout \u0026lt;\u0026lt; name[i]; } cout \u0026lt;\u0026lt; \u0026quot;' has \u0026quot; \u0026lt;\u0026lt; name.size() \u0026lt;\u0026lt; \u0026quot; characters\u0026quot; \u0026lt;\u0026lt; endl; 2D Arrays # Arrays of other arrays are called multidimensional arrays. Instead of each array position holding a single element, it holds an entire array of elements.
Although arrays can have any number of dimensions, we will most often work with two-dimensional arrays.
// An array containing 10 arrays each containing 2 integers (uninitialized). int values[10][2]; Array elements are accessed using multiple square brackets [][] (one per dimension). Nested for-loops can be used to access all the elements.
int values[10][2]; // 10 columns by 2 rows for (int y = 0; y \u0026lt; 2; y++) { for (int x = 0; x \u0026lt; 10; x++) { values[x][y] = x + y; } } How would we set each value to a sequential index (from 0 to 19)? We need to consider each dimension separately as columns and rows, and look at the array as \u0026ldquo;columns of rows\u0026rdquo;. To access a row index (0-1), we always need to add the column offset first (0-9). Each column has 10 rows, so the offset must be multiplied by 10.
int values[10][2]; // 10 columns by 2 rows for (int y = 0; y \u0026lt; 2; y++) { for (int x = 0; x \u0026lt; 10; x++) { values[x][y] = y * 10 + x; } } How would we fill an array of 40 columns by 30 rows with a random true or false value? How could we print it out to the console as a grid layout? We can use the ofRandomuf() OF function, which returns a random value between 0 and 1 (the \u0026ldquo;uf\u0026rdquo; stands for unsigned float). We will set our element to false if the random value is less than 0.5, and set it to true if the value is greater than 0.5.
bool values[40][30]; // Fill the 2D array with 0s and 1s. for (int y = 0; y \u0026lt; 30; y++) // rows { for (int x = 0; x \u0026lt; 40; x++) // columns { if (ofRandomuf() \u0026lt; 0.5) { values[x][y] = false; } else { values[x][y] = true; } } } To output the values as a grid, we can once again use nested for-loops to go through the 2D array, print out the characters one at a time, and print out a new line whenever we increment the row index.
// Read back the values as a grid. for (int y = 0; y \u0026lt; 30; y++) // rows { for (int x = 0; x \u0026lt; 40; x++) // columns { cout \u0026lt;\u0026lt; values[x][y]; } cout \u0026lt;\u0026lt; endl; // Add a new line after every row. } How would we visualize this grid as pixels on screen? We can draw a cell for each grid position using ofDrawRectangle(...), setting the color for each cell in the loop using ofSetColor(...).
// Draw the array as a grid. int gridSize = 10; for (int y = 0; y \u0026lt; 30; y++) // rows { for (int x = 0; x \u0026lt; 40; x++) // columns { if (values[x][y]) { ofSetColor(255); } else { ofSetColor(0); } ofDrawRectangle(x * gridSize, y * gridSize, gridSize, gridSize); } } How would we only set the edge values (border pixels) to true and the remaining pixels to false?
The left edge elements have their column index set to 0. The top edge elements have their row index set to 0. The right edge elements have their column index set to the number of columns (the width) minus 1. In our case, this is 39. The bottom edge elements have their row index set to the number of rows (the height) minus 1. In our case, this is 29. If any of the above conditions are true, our value should also be true.
for (int y = 0; y \u0026lt; 30; y++) // rows { for (int x = 0; x \u0026lt; 40; x++) // columns { if (x == 0 || y == 0 || x == 39 || y == 29) { values[x][y] = true; } else { values[x][y] = false; } // The following does the same thing as a single line of code. //values[x][y] = (x == 0 || y == 0 || x == 39 || y == 29); } } How would we create a grid pattern where each cell is 10x10 units?
We want every 10th element in each direction to be true, and the remaining values to be false. We can use the modulo % operator, which is ideal for whenever we want to count things periodically (e.g. every X count, do something).
for (int y = 0; y \u0026lt; 30; y++) // rows { for (int x = 0; x \u0026lt; 40; x++) // columns { if (x % 10 == 0 || y % 10 == 0) { values[x][y] = true; } else { values[x][y] = false; } // The following does the same thing as a single line of code. //values[x][y] = (x % 10 == 0 || y % 10 == 0); } } We do not end up with a border on the right or the bottom because 39 and 29 are not divisible by 10. If this is something we wanted, one option would be to increase our 2D array size to 41 by 31, making the last column index 40 and the last row index 30.
1D to 2D Interpretation # There is no difference in computer between a 1D and a 2D array, they are both just many indexed elements in sequence.
We could re-write some of our previous examples using a one-dimensional array, but using two-dimensional access.
bool values[40*30]; // Fill the 2D array with 0s and 1s. for (int y = 0; y \u0026lt; 30; y++) // rows { for (int x = 0; x \u0026lt; 40; x++) // columns { // Calculate the index using the column value, the row value, and the row offset. int idx = y * 40 + x; if (x == 0 || y == 0 || x == 39 || y == 29) { values[idx] = true; } else { values[idx] = false; } // The following does the same thing as a single line of code. //values[idx] = (x == 0 || y == 0 || x == 39 || y == 29); } } In the last few examples, we have been using arrays to generate images. We have interpreted the array element values as colors. This is, in fact, how images are usually stored in computer memory. We will explore this further in the next section.
`}),e.add({id:10,href:"/docs/class-2/images-and-video/",title:"Images and Video",description:`File Formats # Digital images come in a variety of formats, each with their own properties.
Vector Graphics # Vector formats define a set of points and instructions on how to draw them. The instructions are run by a program to raster the image in order to view it.
Some of the more common vector formats are SVG, EPS, PDF, and AI.
If we open the following SVG file in a text editor, we will notice that it is fairly easy to read the format.`,content:`File Formats # Digital images come in a variety of formats, each with their own properties.
Vector Graphics # Vector formats define a set of points and instructions on how to draw them. The instructions are run by a program to raster the image in order to view it.
Some of the more common vector formats are SVG, EPS, PDF, and AI.
If we open the following SVG file in a text editor, we will notice that it is fairly easy to read the format. It almost reads like a Processing program 😉
\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot; standalone=\u0026quot;no\u0026quot;?\u0026gt; \u0026lt;svg ... height=\u0026quot;512\u0026quot; width=\u0026quot;512\u0026quot;\u0026gt; ... \u0026lt;g transform=\u0026quot;translate(0,-161.53332)\u0026quot; id=\u0026quot;layer1\u0026quot;\u0026gt; \u0026lt;circle style=\u0026quot;stroke-width:0.26458332;fill:#00ffff;fill-opacity:1\u0026quot; r=\u0026quot;52.916664\u0026quot; cy=\u0026quot;229.26665\u0026quot; cx=\u0026quot;67.73333\u0026quot; id=\u0026quot;path3713\u0026quot; /\u0026gt; \u0026lt;rect y=\u0026quot;228.20831\u0026quot; x=\u0026quot;5.2916665\u0026quot; height=\u0026quot;63.5\u0026quot; width=\u0026quot;63.5\u0026quot; id=\u0026quot;rect4520\u0026quot; style=\u0026quot;fill:#ff0000;fill-opacity:1;stroke-width:0.25843021\u0026quot; /\u0026gt; \u0026lt;path id=\u0026quot;path4524\u0026quot; d=\u0026quot;M 49.514879,171.88985 123.5982,282.2589 Z\u0026quot; style=\u0026quot;fill:none;stroke:#00b400;stroke-width:2.64583325;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1\u0026quot; /\u0026gt; \u0026lt;/g\u0026gt; \u0026lt;/svg\u0026gt; Pros:
Small file sizes, because minimal information is being stored. Images can be scaled up without any quality loss or increase in file size. This is because the instruction set does not change, the only thing that changes is the point values. Cons:
Low level of detail. Limited types of effects, because we don\u0026rsquo;t have all the image data available in the format. Raster Graphics # Raster formats define pixel values in a rectangular grid of pixels. The bigger the image, the greater the data set, and thus the larger the file size.
Some of the more common vector formats are JPG, PNG, GIF, and TIF.
Pros:
High quality and detail, especially at high resolutions. More advanced image effects, because every pixel can be edited. Cons:
File sizes tend to be bigger. Images lose quality when scaled up. In order not to end up with huge file sizes, many raster formats are compressed. Some compression methods are lossy, meaning that some of the data is lost when it is compressed, and others are lossless, meaning that all the data is recovered once the data is uncompressed.
Video # Videos are just a series of images that need to be processed and displayed very quickly.
Video formats are always rasters and are mostly compressed.
Some formats are simply extensions of their image counterparts, like Motion JPG for example, which is just a series of JPG-compressed frames. Others are specific to video, like H.264, which has a form of compression over time, where some pixels are predicted based on known pixels in previous and future key frames. This is called temporal compression. Efficient compression is necessary for video because of the huge amount of data that it carries. While film used to run at 24 frames per second, high definition video now runs standard at 60 frames per second, and sometimes goes as high as 240 fps! Combining these fast frame rates with large resolutions like 4K means that hundreds of millions of pixels need to be processed every second for a video to play smoothly.
Processing Images # When working with image data, we will usually want to work with rasterized uncompressed images. This is because many algorithms require looping efficiently through all pixels in an image, or doing quick look-ups between neighboring pixels.
The good news is that this usually happens in the image loader or video codec, before an image or video frame gets to us. For example in OF, FreeImage will automatically decompress JPG or PNG images and provide us the \u0026ldquo;final\u0026rdquo; pixels in the frame.
While we will almost never have to worry about decoding an image or a video frame ourselves, we should still be mindful of what format the data comes in, and make sure that it is suitable for our application.
Images in OF # The data Folder # The simplest way to access files in an OF app is to include them in the project\u0026rsquo;s data folder. If this looks familiar, it\u0026rsquo;s because this idea is borrowed from Processing. The data folder is located in \u0026lt;project\u0026gt;/bin/data and each project will have its own dedicated data folder.
If we drop our files in the data folder, they can be accessed in the app without having to figure out the full path on disk where the file is located, which can be very handy.
ofImage # ofImage is the general type to use to work with images in openFrameworks. ofImage includes methods to load files from disk, draw images to the screen, access pixel data, etc.
ofImage is a type, which we can create like any other variable type.
// ofApp.h #pragma once #include \u0026quot;ofMain.h\u0026quot; class ofApp : public ofBaseApp { public: void setup(); void draw(); ofImage dogImg; }; ✌️ Declaring variables in the header file
Variables we want to use in any method (function) of our class should be declared in the header. This means that they are in the entire class\u0026rsquo; scope.
If we declare a variable inside one of our methods like ofApp::setup() or ofApp::draw(), that variable will only be part of that specific method\u0026rsquo;s scope, and will not be accessible outside of it.
We will load an image named dog-grass.jpg from our data folder in the ofApp::setup() function. We only need to load the image into memory once, so we do it when the app starts up.
We want to draw the image every frame, so we will do that in the ofApp::draw() function.
// ofApp.cpp #include \u0026quot;ofApp.h\u0026quot; void ofApp::setup() { dogImg.load(\u0026quot;dog-grass.jpg\u0026quot;); } void ofApp::draw() { dogImg.draw(0, 0); } ✌️ What happened to the other built-in ofApp methods?
In this specific example, we are not using most of the ofApp placeholder methods like ofApp::update(), ofApp::keyPressed(), ofApp::mouseMoved(), etc. I am removing them from the code to increase readability.
However, note that the method needs to be removed from both the header .h and the implementation .cpp files or else the compiler will assume something is missing and will throw an error.
If we navigate under the hood and see what ofImage::load() is actually doing, we see that it calls many functions from the FreeImage library to determine the file\u0026rsquo;s format, uncompress the data, and load it into values for each pixel.
Image Attributes # An image data structure usually comprises of:
a size (a width and height) a pixel format a value for each pixel Pixel Arrays # This structure looks a lot like the arrays we have been exploring in the previous section. This makes arrays great options to represent image data in a computer program.
Even though an image has two dimensions (a width and a height), the pixel array is usually one-dimensional, packing the rows one after the other in sequence.
Some frameworks allow accessing pixels using the column x and row y, like PImage.get() in Processing and ofImage.getColor() in openFrameworks. These convenience functions are very useful as they take care of figuring out all the index arithmetic for us.
The following example draws an image one pixel at a time, using nested for-loops to iterate through each row and column.
// ofApp.cpp #include \u0026quot;ofApp.h\u0026quot; void ofApp::setup() { // Load the dog image. dogImg.load(\u0026quot;dog-grass.jpg\u0026quot;); // Set the window size to match the image. ofSetWindowShape(dogImg.getWidth(), dogImg.getHeight()); } void ofApp::draw() { for (int y = 0; y \u0026lt; dogImg.getHeight(); y++) { for (int x = 0; x \u0026lt; dogImg.getWidth(); x++) { ofColor color = dogImg.getColor(x, y); ofSetColor(color); ofDrawRectangle(x, y, 1, 1); } } } ofSetWindowShape() resizes the window to the size of the loaded image. Note that this function can be called any time while the app is running, and can override the starting window dimensions that are set in main.cpp. ofImage.getColor() returns the ofColor value at a specified column and row index. ofColor is a data structure used to access the different channels that make up a color value. How would we read the value of a pixel under the mouse cursor? We can use ofImage.getColor() and pass the mouse coordinates as the column and row index.
// ofApp.cpp #include \u0026quot;ofApp.h\u0026quot; void ofApp::setup() { // Load the dog image. dogImg.load(\u0026quot;dog-grass.jpg\u0026quot;); // Set the window size to match the image. ofSetWindowShape(dogImg.getWidth(), dogImg.getHeight()); } void ofApp::draw() { // Draw the image as the background. ofSetColor(255); dogImg.draw(0, 0); // Get a reference to the image pixels. ofPixels dogPix = dogImg.getPixels(); // Get the color value under the mouse. ofColor color = dogPix.getColor(mouseX, mouseY); // Draw a rectangle under the mouse using the pixel color. ofFill(); ofSetColor(color); ofDrawRectangle(mouseX - 25, mouseY - 25, 50, 50); // Add an outline so we can see the rectangle better. ofNoFill(); ofSetColor(0); ofDrawRectangle(mouseX - 25, mouseY - 25, 50, 50); } Note that this only works if the window and image have equal resolutions. If they didn\u0026rsquo;t, we would need to remap the mouse coordinates to the window coordinates. We will cover this in a later class.
Size and Scale # In the previous examples, the drawn image is anchored in the top-left corner of the window (0, 0) and by default, it is drawn at full resolution. This means that the image might be smaller or larger than our window.
If we want the image to fill and fit in the exact window bounds, we have two options:
We can resize the window to match the image resolution. This is what we have been doing in the previous examples.
// ofApp.cpp #include \u0026quot;ofApp.h\u0026quot; void ofApp::setup() { // Load the dog image. dogImg.load(\u0026quot;dog-grass.jpg\u0026quot;); // Set the window size to match the image. ofSetWindowShape(dogImg.getWidth(), dogImg.getHeight()); } void ofApp::draw() { dogImg.draw(0, 0); } We can scale the image to match the window size.
// ofApp.cpp #include \u0026quot;ofApp.h\u0026quot; void ofApp::setup() { // Load the dog image. dogImg.load(\u0026quot;dog-grass.jpg\u0026quot;); ofSetWindowShape(1280, 720); } void ofApp::draw() { dogImg.draw(0, 0, ofGetWidth(), ofGetHeight()); } If ofImage::draw() is called with 4 arguments, the first 2 set the top-left coordinates and the last 2 set the width and height. ✌️ Pixels and Textures
At this point, it\u0026rsquo;s a good idea to have a basic understanding of how modern computers draw images to the screen.
Two different processing units are used for this to occur.
A pixel color array lives on the CPU. We can load data into this array and read it and change it. In OF, this is represented by ofPixels. A texture lives on the GPU. It cannot be manipulated (easily) and is read to be rendered on a screen. In OF, this is represented by ofTexture. When the image is ready to be drawn, the pixel array is sent from the CPU to the GPU and converted to a texture. ofImage contains an ofPixels and an ofTexture and will try to handle the CPU to GPU transfer automatically.
If we use an image that is smaller than the window, it will be scaled up to fit the window. We can tell OF how to upscale the image by setting a filter on the texture.
When an image is scaled up, it needs additional pixels to fill in the extra resolution. Conversely, when an image is scaled down, it removes some of its original pixels because the resolution is smaller. The min and mag filters define how the renderer should handle these situations.
The default mode uses linear interpolation GL_LINEAR. This blends the nearby pixels together to make new pixels and may look blurry. The nearest neighbor mode GL_NEAREST uses the nearest pixel value for the added pixels without any blending. This keeps the image sharp at any resolution, but it may look pixelated. // ofApp.h #pragma once #include \u0026quot;ofMain.h\u0026quot; class ofApp : public ofBaseApp { public: void setup(); void draw(); void mousePressed(int button, int x, int y); void mouseReleased(int button, int x, int y); ofImage dogImg; }; // ofApp.cpp #include \u0026quot;ofApp.h\u0026quot; void ofApp::setup() { dogImg.load(\u0026quot;dog-grass-low.jpg\u0026quot;); ofSetWindowShape(1280, 720); } void ofApp::draw() { dogImg.draw(0, 0, ofGetWidth(), ofGetHeight()); } void ofApp::mousePressed(int button, int x, int y) { dogImg.getTexture().setTextureMinMagFilter(GL_NEAREST, GL_NEAREST); } void ofApp::mouseReleased(int button, int x, int y) { dogImg.getTexture().setTextureMinMagFilter(GL_LINEAR, GL_LINEAR); } We can access the texture with ofImage.getTexture() and set the min (scale down) and mag (scale up) filters with ofTexture.setTextureMinMagFilter(). Texture filters do not use any additional computation, because they are handled automatically by the GPU! Dog using GL_LINEAR Dog using GL_NEAREST Pixel Access # A standard color pixel will have 3 color channels: red, green, and blue (RGB). While Processing packs all channels into a single int, this is not common practice.
The color values are usually packed sequentially in the array. Instead of each pixel holding a single value, it will hold 3.
The pixel array then has total size:
size = width * height * channels In order to access the pixel in a 1D array using a 2D index, we first need to convert it.
index = y * width + x How do we access a pixel index in an RGB image?
Because each pixel has three color values (for each RGB channel), we need to multiply our pixel index by 3 to take that offset into account.
pixel = y * width + x index = pixel * 3 index = (y * width + x) * 3 ofPixels.getColor() can also accept a single argument for the index (instead of two arguments for the column and row). How can we modify the previous example to use the single index version of getColor()? We can use the formula above to convert our column and row to an index value in the color array.
// ofApp.cpp // ... void ofApp::draw() { // ... // Get a reference to the image pixels. ofPixels dogPix = dogImg.getPixels(); // Get the color value under the mouse. //ofColor color = dogPix.getColor(mouseX, mouseY); int index = (mouseY * dogPix.getWidth() + mouseX) * dogPix.getNumChannels(); ofColor color = dogPix.getColor(index); // ... } Note the use of ofPixels.getNumChannels() instead of the literal 3. This ensures the code will work with all image types and not just RGB images.
Conversely, if we want to get a 2D value from a 1D index, we can use integer division:
x = index % width y = index / width The following example reads the value of a pixel sequentially, based on the sketch frame number.
// ofApp.cpp #include \u0026quot;ofApp.h\u0026quot; void ofApp::setup() { // Load the dog image. dogImg.load(\u0026quot;dog-grass.jpg\u0026quot;); // Set the window size to match the image. ofSetWindowShape(dogImg.getWidth(), dogImg.getHeight()); } void ofApp::draw() { // Draw the image as the background. ofSetColor(255); dogImg.draw(0, 0); // Cache the image dimensions in variables for easy access. int imgWidth = dogImg.getWidth(); int imgHeight = dogImg.getHeight(); // Use the modulo operator to make sure the frame index is never // greater than the max number of pixels in the image. int frameIndex = ofGetFrameNum() % (imgWidth * imgHeight); int x = frameIndex % imgWidth; int y = frameIndex / imgWidth; // Get a reference to the image pixels. ofPixels dogPix = dogImg.getPixels(); // Get the color value for this frame. int pixelIndex = frameIndex * dogPix.getNumChannels(); ofColor color = dogPix.getColor(pixelIndex); // Draw a rectangle under the mouse using the pixel color. ofFill(); ofSetColor(color); ofDrawRectangle(x - 25, y - 25, 50, 50); // Add an outline so we can see the rectangle better. ofNoFill(); ofSetColor(0); ofDrawRectangle(x - 25, y - 25, 50, 50); } Data Formats # Image Format # The most common image type we will work with is RGB color images.
We will also work with single-channel formats, usually called grayscale or luminance. These are particularly handy for devices that only capture a brightness level, like infrared cameras or depth sensors.
Some images also have an alpha channel for transparency, like RGBA. Our example image happens to have transparency, but we will encounter this rarely in this class as most sensors do not use the alpha channel.
Another format worth mentioning is YUV, which is a color encoding that is based on the range of human perception. Instead of using three channels for color, it uses one for brightness and two for color shift. This gives similar results to RGB but at much smaller sizes (usually a third), and this is why YUV formats are often used for webcam streams.
Pixel Format # Pixel color values can be stored in a few different formats. The more bits a format can hold, the more range the values can have, and the larger the size of the frame gets.
unsigned char is the most common format. It uses integers and each channel has 8 bits of data and values range from 0 to 255. float uses floating point 32 bit data. The usual range is from 0.0 to 1.0 but this format can be used for HDR effects, where the values can extend past 1.0 or for storing non-color data, where we can even use negative values. We will use float when working with depth sensors and when storing non-color data inside our pixels. unsigned short is another integer format but with 16 bits of data, meaning values range from 0 to 65535. We will also use this format when working with depth sensors, where precision is very important and we need more than the 256 distinct values that we get from unsigned char. The following example demonstrates how to access the pixel array data directly, using ofPixels.getData().
This is a bit more complicated, and may not be necessary in most applications. However, it tends to be the fastest way to manipulate pixel values and is the recommended approach when having to process large images pixel by pixel.
// ofApp.cpp // ... void ofApp::draw() { // ... // Get a reference to the image pixels. unsigned char* dogData = dogImg.getPixels().getData(); // Get the color value for this frame. int numChannels = dogImg.getPixels().getNumChannels(); int pixelIndex = mouseY * dogImg.getWidth() + mouseX; ofColor color = ofColor( dogData[pixelIndex * numChannels + 0], // R dogData[pixelIndex * numChannels + 1], // G dogData[pixelIndex * numChannels + 2] // B ); // ... } ✌️ What does the * after unsigned char mean?
The * represents something called a pointer. Pointers are a complex topic that we will cover in depth later in the course, but for now just think of them as representing arrays with a variable size (or arrays with a size we do not know at compile time).
The code above needs to work for any image of any size, so we cannot assume that the unsigned char array will have a specific number of elements in it. Using unsigned char* tells the compiler that the array size will be dynamically allocated when it is created.
`}),e.add({id:11,href:"/docs/class-3/",title:"Class 3",description:"Class 3",content:""}),e.add({id:12,href:"/docs/class-3/computer-vision/",title:"Computer Vision",description:`Computer vision allows computers to \u0026ldquo;see\u0026rdquo;, and to understand what they are seeing. This is done by reading and interpreting digital images and video.
Operations # What are some common computer vision operations?
Image filtering Convert from one color space to another (e.g. RGB to grayscale). Adjust brightness and contrast. Blur or sharpen the image. Edge detection. Understanding Edge Detection (Sobel Operator) Background subtraction Detect moving objects by comparing them to a reference frame.`,content:`Computer vision allows computers to \u0026ldquo;see\u0026rdquo;, and to understand what they are seeing. This is done by reading and interpreting digital images and video.
Operations # What are some common computer vision operations?
Image filtering Convert from one color space to another (e.g. RGB to grayscale). Adjust brightness and contrast. Blur or sharpen the image. Edge detection. Understanding Edge Detection (Sobel Operator) Background subtraction Detect moving objects by comparing them to a reference frame. IHDC: Idiap Human Detection Code Object recognition Blob detection Contour finding OpenCV Contours \u0026amp; Convex Hull 2 Structure plugin Motion estimation Track pixel movement between consecutive frames and infer the direction objects are moving into. Dense Realtime Optical Flow on the GPU Face detection Feature recognition Smile detection Object Detection : Face Detection using Haar Cascade Classifiers Camera and projector calibration Procamcalib Box by Bot \u0026 Dolly Image Segmentation # One of the most common operations we will have to perform when working with computer vision is image segmentation. Image segmentation simply means dividing up the image pixels into meaningful groups. These meaningful groups depend on the application we are creating. For example, we may want to only consider the brightest pixels in an image, pixels of a certain color, clusters of pixels of a specific size, etc.
Robust hand gesture recognition using multiple shape-oriented visual cues Image segmentation is the first step into many applications as it is a way to discard unwanted data and only keep what we need to focus on.
Video Capture # Let\u0026rsquo;s begin with a simple app to stream data from a connected webcam.
We will use an ofVideoGrabber to capture frames from video.
// ofApp.h #pragma once #include \u0026quot;ofMain.h\u0026quot; class ofApp : public ofBaseApp { public: void setup(); void update(); void draw(); ofVideoGrabber grabber; }; // ofApp.cpp #include \u0026quot;ofApp.h\u0026quot; void ofApp::setup() { grabber.setup(1280, 720); } void ofApp::update() { grabber.update(); } void ofApp::draw() { grabber.draw(0, 0, ofGetWidth(), ofGetHeight()); } Note that we call the ofVideoGrabber::update() function every frame. This method checks if there\u0026rsquo;s a new video frame available and if so, refreshes the grabber to make it available.
We will use an ofImage to store our thresholded image. Let\u0026rsquo;s start with a loop that just copies the video pixels into the image one at a time.
// ofApp.h #pragma once #include \u0026quot;ofMain.h\u0026quot; class ofApp : public ofBaseApp { public: void setup(); void update(); void draw(); ofVideoGrabber grabber; ofImage resultImg; }; // ofApp.cpp #include \u0026quot;ofApp.h\u0026quot; void ofApp::setup() { grabber.setup(1280, 720); resultImg.allocate(1280, 720, OF_IMAGE_COLOR); } void ofApp::update() { grabber.update(); ofPixels grabberPix = grabber.getPixels(); ofPixels resultPix = resultImg.getPixels(); for (int y = 0; y \u0026lt; grabberPix.getHeight(); y++) { for (int x = 0; x \u0026lt; grabberPix.getWidth(); x++) { ofColor pixColor = grabberPix.getColor(x, y); resultPix.setColor(x, y, pixColor); } } } void ofApp::draw() { resultImg.draw(0, 0, ofGetWidth(), ofGetHeight()); } Pass by Reference vs. Pass by Value # You\u0026rsquo;ll notice that our drawn image is not displaying anything.
In C++, there are a few ways to pass data (aka arguments or parameters) between objects and functions. We can pass data by reference, by value, or by pointer.
Pass by reference means that we are passing the actual data object itself. Any changes we make to the received object will be kept in the original reference, as it is the same object. Pass by value means that we are just passing the value of the data, not the data object itself. This means making a copy of the original object and passing that copy. This does not make a difference when the data is a number (like an int or a float), but it matters when the data is an object, as any changes we make to the received object are only applied to this new copy object. Pass by pointer means that we are passing the memory address of the data object. We will look at this later on in the course. By default, data is passed by value in C++.
In our app, the line ofPixels resultPix = resultImg.getPixels(); creates a copy of the image pixels and stores it in resultPix. Any changes we make to resultPix are changes made on the copy and not on the ofPixels belonging to resultImg. This is why we are not seeing the image get updated.
One way to resolve this would be to save back the modified pixels to resultImg at the end of the loop:
resultImg.setFromPixels(resultPix); Our code works! However it is highly unoptimized as we are now making two additional copies of our pixel array every frame.
// ofApp.cpp // ... void ofApp::update() { grabber.update(); ofPixels grabberPix = grabber.getPixels(); ofPixels resultPix = resultImg.getPixels(); // COPY! for (int y = 0; y \u0026lt; grabberPix.getHeight(); y++) { for (int x = 0; x \u0026lt; grabberPix.getWidth(); x++) { ofColor pixColor = grabberPix.getColor(x, y); resultPix.setColor(x, y, pixColor); } } resultImg.setFromPixels(resultPix); // COPY! } // ... A better approach is to pass the original pixels by reference using the \u0026amp; operator. The reference ofPixels from the ofImage is then modified directly. We can even go ahead and pass the grabber pixels by reference and avoid making a copy there too.
// ofApp.cpp // ... void ofApp::update() { grabber.update(); // Use a reference to the ofPixels in both the grabber and the image. ofPixels\u0026amp; grabberPix = grabber.getPixels(); ofPixels\u0026amp; resultPix = resultImg .getPixels(); for (int y = 0; y \u0026lt; grabberPix.getHeight(); y++) { for (int x = 0; x \u0026lt; grabberPix.getWidth(); x++) { ofColor pixColor = grabberPix.getColor(x, y); resultPix.setColor(x, y, pixColor); } } } // ... ⚠️ Why is the drawn image not updating?
Remember that an ofImage is made up of two parts: ofPixels, which is the data component of the image (on the CPU), and ofTexture, which is the graphics component of the image (on the GPU). For an image to get drawn to the screen, the data in ofPixels must be copied over to the ofTexture.
When manipulating pixels directly as we are doing, this process needs to be triggered manually by calling ofImage::update().
// ofApp.cpp #include \u0026quot;ofApp.h\u0026quot; void ofApp::setup() { grabber.setup(1280, 720); resultImg.allocate(1280, 720, OF_IMAGE_COLOR); } void ofApp::update() { grabber.update(); // Use a reference to the ofPixels in both the grabber and the image. ofPixels\u0026amp; grabberPix = grabber.getPixels(); ofPixels\u0026amp; resultPix = resultImg .getPixels(); for (int y = 0; y \u0026lt; grabberPix.getHeight(); y++) { for (int x = 0; x \u0026lt; grabberPix.getWidth(); x++) { ofColor pixColor = grabberPix.getColor(x, y); resultPix.setColor(x, y, pixColor); } } // Update the internal texture (GPU) with the new pixel data. resultImg.update(); } void ofApp::draw() { resultImg.draw(0, 0, ofGetWidth(), ofGetHeight()); } How would we set the result image to create a negative film effect?
A negative of a pixel of color is the inverse of that color. Because every pixel channel\u0026rsquo;s value has range 0-255, the inverse is the value substracted from 255.
negCol.r = 255 - pixCol.r; negCol.g = 255 - pixCol.g; negCol.b = 255 - pixCol.b; ofColor has an ofColor::invert() method which does this for us.
// ofApp.cpp #include \u0026quot;ofApp.h\u0026quot; // ... void ofApp::update() { grabber.update(); // Use a reference to the ofPixels in both the grabber and the image. ofPixels\u0026amp; grabberPix = grabber.getPixels(); ofPixels\u0026amp; resultPix = resultImg.getPixels(); for (int y = 0; y \u0026lt; grabberPix.getHeight(); y++) { for (int x = 0; x \u0026lt; grabberPix.getWidth(); x++) { ofColor pixColor = grabberPix.getColor(x, y); resultPix.setColor(x, y, pixColor.invert()); } } // Update the internal texture (GPU) with the new pixel data. resultImg.update(); } // ... How would we set the result image to create a gray tone effect?
We have a few options that could work. In all cases, we need to convert the image from the 3 RGB channels into a single channel value.
We could use the max value, called the brightness. unsigned char gray = max(pixColor.r, max(pixColor.g, pixColor.b)); We could use the average value, called the lightness. unsigned char gray = (pixColor.r + pixColor.g + pixColor.b) / 3; We could calculate a weighted average, called the luminance. The following formula takes into account human eye perception, which is more sensitive to green. unsigned char gray = 0.21 * pixColor.r + 0.71 * pixColor.g + 0.07 * pixColor.b; ofColor has ofColor::getBrightness() and ofColor::getLightness() methods which can help.
// ofApp.cpp #include \u0026quot;ofApp.h\u0026quot; // ... void ofApp::update() { grabber.update(); // Use a reference to the ofPixels in both the grabber and the image. ofPixels\u0026amp; grabberPix = grabber.getPixels(); ofPixels\u0026amp; resultPix = resultImg.getPixels(); for (int y = 0; y \u0026lt; grabberPix.getHeight(); y++) { for (int x = 0; x \u0026lt; grabberPix.getWidth(); x++) { ofColor pixColor = grabberPix.getColor(x, y); resultPix.setColor(x, y, pixColor.getLightness()); //unsigned char gray = 0.21 * pixColor.r + 0.71 * pixColor.g + 0.07 * pixColor.b; //resultPix.setColor(x, y, gray); } } // Update the internal texture (GPU) with the new pixel data. resultImg.update(); } // ... Thresholding # Thresholding is a simple segmentation technique where a pixel value is either on or off. If it is on we will color it white and if it is off we will color it black. Thresholded images can be used as masks into our input image, used to discard any pixels we want to ignore.
night lights from zach lieberman on Vimeo. Let\u0026rsquo;s write a simple thresholding algorithm that only keeps the brightest parts of an image. We will use the brightness of each pixel color to determine if it should be on or off in our result image.
// ofApp.cpp #include \u0026quot;ofApp.h\u0026quot; void ofApp::setup() { grabber.setup(1280, 720); resultImg.allocate(1280, 720, OF_IMAGE_COLOR); } void ofApp::update() { grabber.update(); int brightnessThreshold = 128; ofPixels\u0026amp; grabberPix = grabber.getPixels(); ofPixels\u0026amp; resultPix = resultImg.getPixels(); for (int y = 0; y \u0026lt; grabberPix.getHeight(); y++) { for (int x = 0; x \u0026lt; grabberPix.getWidth(); x++) { ofColor pixColor = grabberPix.getColor(x, y); if (pixColor.getBrightness() \u0026gt; brightnessThreshold) { // Set the pixel white if its value is above the threshold. resultPix.setColor(x, y, ofColor(255)); } else { // Set the pixel black if its value is below the threshold. resultPix.setColor(x, y, ofColor(0)); } } } resultImg.update(); } void ofApp::draw() { resultImg.draw(0, 0, ofGetWidth(), ofGetHeight()); } We should make our threshold value editable, as we do not know what environment this app will run in.
Let\u0026rsquo;s make brightnessThreshold a class variable by moving the declaration to the header file. We can then use the mouse position to adjust the value in every update loop. We will use the ofMap() function to easily convert our mouse position (from 0 to the width of the window) to our brightness range (from 0 to 255).
// ofApp.h #pragma once #include \u0026quot;ofMain.h\u0026quot; class ofApp : public ofBaseApp { public: void setup(); void update(); void draw(); ofVideoGrabber grabber; ofImage resultImg; int brightnessThreshold; }; // ofApp.cpp #include \u0026quot;ofApp.h\u0026quot; void ofApp::setup() { grabber.setup(1280, 720); resultImg.allocate(1280, 720, OF_IMAGE_COLOR); } void ofApp::update() { grabber.update(); brightnessThreshold = ofMap(mouseX, 0, ofGetWidth(), 255, 0); ofPixels\u0026amp; grabberPix = grabber.getPixels(); ofPixels\u0026amp; resultPix = resultImg.getPixels(); for (int y = 0; y \u0026lt; grabberPix.getHeight(); y++) { for (int x = 0; x \u0026lt; grabberPix.getWidth(); x++) { ofColor pixColor = grabberPix.getColor(x, y); if (pixColor.getBrightness() \u0026gt; brightnessThreshold) { // Set the pixel white if its value is above the threshold. resultPix.setColor(x, y, ofColor(255)); } else { // Set the pixel black if its value is below the threshold. resultPix.setColor(x, y, ofColor(0)); } } } resultImg.update(); } void ofApp::draw() { resultImg.draw(0, 0, ofGetWidth(), ofGetHeight()); } This is functional, but the way we are setting the threshold is a little clunky. We want better control and feedback for our threshold variable, and we can do this by replacing the mouse position by a GUI with a slider.
We will achieve this using two new elements: the ofxGui addon and the ofParameter template class.
ofxGui # The ofxGui addon ships with OF and is used for creating GUI elements.
\u0026ldquo;Addon\u0026rdquo; means it is not part of the OF core files. We need additional files in our project to use the addon. This can be complex if we do it manually, but thankfully we can select addons in the Project Generator and let it take care of the hard work.
When we regenerate our project files, we will now have access to all the ofxGui classes.
For this example, we will use ofxPanel, which is simply a container that can hold other GUI controls like buttons and sliders.
ofxGui cannot use data types like int, float, string directly, because it needs additional information like a name, a range, etc.
One option is to use special classes that are part of the ofxGui addon, like ofxIntSlider, ofxColorSlider, ofxButton, etc. The example examples\\gui\\guiExample demonstrates how to do this.
ofParameter # Another option is to use a special OF class called ofParameter. This is more useful because ofParameter objects are not tied to ofxGui and can be used with other GUI frameworks, events, etc.
ofParameter is a wrapper class that is used to give other data types super powers. For example:
Min and max values can be defined and the value will always stay within that range. A notification gets triggered whenever the value is changed. This is especially useful for GUIs where we need to respond right away when a variable changes. ofParameter uses the template syntax, meaning that whatever type they hold is set between the \u0026lt; \u0026gt; symbols. In our case, since the threshold is an int, our ofParameter will be defined using ofParameter\u0026lt;int\u0026gt;.
✌️ What is a template?
C++ has a concept of templates. The idea with templates is to use data types as parameters, similar to how we have been using values as parameters. If a class is templated, it can work with various data types without having to write the same code multiple times.
We will see classes or functions be templated.
In fact, we have already been using templates with ofPixels! The ofPixels type is actually a shorthand for ofPixels_\u0026lt;unsigned char\u0026gt;. This means it is an ofPixels_ template where the data type of the pixels is unsigned char (and that is why our values go from 0 to 255).
ofPixels_ can also be used with float and unsigned short pixels, using ofPixels_\u0026lt;float\u0026gt; or ofPixels_\u0026lt;unsigned short\u0026gt;. The shorthands ofFloatPixels and ofShortPixels are also available, and they represent exactly the same thing.
ofParameter works in a similar way, it is a template class. We need to specify the type and precision of the data it will control, in this case int. This is done when declaring the variable with type ofParameter\u0026lt;int\u0026gt;.
Our code now looks like the following, and our app window has a slider in the top-left corner we can use to edit the threshold value.
// ofApp.h #pragma once #include \u0026quot;ofMain.h\u0026quot; #include \u0026quot;ofxGui.h\u0026quot; class ofApp : public ofBaseApp { public: void setup(); void update(); void draw(); ofVideoGrabber grabber; ofImage resultImg; ofParameter\u0026lt;int\u0026gt; brightnessThreshold; ofxPanel guiPanel; }; // ofApp.cpp #include \u0026quot;ofApp.h\u0026quot; void ofApp::setup() { grabber.setup(1280, 720); resultImg.allocate(1280, 720, OF_IMAGE_COLOR); // Initialize the threshold parameter with range [0, 255]. brightnessThreshold.set(\u0026quot;Bri Thresh\u0026quot;, 120, 0, 255); // Setup the GUI panel and add the threshold parameter. guiPanel.setup(\u0026quot;Threshold\u0026quot;); guiPanel.add(brightnessThreshold); } void ofApp::update() { grabber.update(); ofPixels\u0026amp; grabberPix = grabber.getPixels(); ofPixels\u0026amp; resultPix = resultImg.getPixels(); for (int y = 0; y \u0026lt; grabberPix.getHeight(); y++) { for (int x = 0; x \u0026lt; grabberPix.getWidth(); x++) { ofColor pixColor = grabberPix.getColor(x, y); if (pixColor.getBrightness() \u0026gt; brightnessThreshold) { // Set the pixel white if its value is above the threshold. resultPix.setColor(x, y, ofColor(255)); } else { // Set the pixel black if its value is below the threshold. resultPix.setColor(x, y, ofColor(0)); } } } resultImg.update(); } void ofApp::draw() { resultImg.draw(0, 0, ofGetWidth(), ofGetHeight()); guiPanel.draw(); } Background Subtraction # Background subtraction is a segmentation technique where the background pixels of an image are removed, leaving only the foreground data for processing.
✌️ What defines the background?
This varies depending on the type of sensor used, the environment, and the application.
When using a depth sensor, we can actually use a pixel\u0026rsquo;s distance from the camera to determine if it\u0026rsquo;s in the background or not. In general for 2D video, a background pixel is one that is considered stable, i.e. that does not change its value much or at all.
Background subtraction requires that we have a background frame as a reference. We can do this by saving a video frame in memory, and comparing future frames to it in our update() loop.
Video pixel values change slightly over time, so we cannot expect them to be identical frame by frame. We will add a threshold value and compare the difference between the pixels to determine if it should be on or off.
// ofApp.h #pragma once #include \u0026quot;ofMain.h\u0026quot; #include \u0026quot;ofxGui.h\u0026quot; class ofApp : public ofBaseApp { public: void setup(); void update(); void draw(); ofVideoGrabber grabber; ofImage backgroundImg; ofImage resultImg; ofParameter\u0026lt;bool\u0026gt; captureBackground; ofParameter\u0026lt;int\u0026gt; colorThreshold; ofxPanel guiPanel; }; // ofApp.cpp #include \u0026quot;ofApp.h\u0026quot; void ofApp::setup() { grabber.setup(1280, 720); resultImg.allocate(1280, 720, OF_IMAGE_COLOR); captureBackground.set(\u0026quot;Capture BG\u0026quot;, true); colorThreshold.set(\u0026quot;Color Thresh\u0026quot;, 120, 0, 255); guiPanel.setup(\u0026quot;BG Subtraction\u0026quot;); guiPanel.add(captureBackground); guiPanel.add(colorThreshold); } void ofApp::update() { grabber.update(); ofPixels\u0026amp; grabberPix = grabber.getPixels(); if (captureBackground) { backgroundImg.setFromPixels(grabber.getPixels()); captureBackground = false; } ofPixels\u0026amp; resultPix = resultImg.getPixels(); for (int y = 0; y \u0026lt; grabberPix.getHeight(); y++) { for (int x = 0; x \u0026lt; grabberPix.getWidth(); x++) { ofColor grabColor = grabberPix.getColor(x, y); ofColor bgColor = backgroundImg.getColor(x, y); if (abs(grabColor.r - bgColor.r) \u0026gt; colorThreshold || abs(grabColor.g - bgColor.g) \u0026gt; colorThreshold || abs(grabColor.b - bgColor.b) \u0026gt; colorThreshold) { resultPix.setColor(x, y, grabColor); } else { resultPix.setColor(x, y, ofColor(0)); } } } resultImg.update(); } void ofApp::draw() { resultImg.draw(0, 0, ofGetWidth(), ofGetHeight()); guiPanel.draw(); } Devices # Color # While using built-in webcams is convenient for testing, it is not a great choice for deployed projects. They tend to be low quality and not offer manual controls for white balance, exposure, focus, etc.
Higher end webcams like the Logitech C9XX or Brio series are a good alternative. For best quality, a DSLR or video camera can be used with a capture card, like the Blackmagic UltraStudio Recorder 3G. Infrared # Depending on the application and environment, it might be better to use an alternative to a color camera for capturing images.
Infrared cameras are often used for sensing because they see light that is invisible to humans. They tend to be a more versatile choice as they can be used in a bright room, a pitch dark room, facing a video projector, behind a touch surface, etc.
presence [a.k.a soft \u0026amp; silky] from smallfly on Vimeo. Infrared USB cameras can be hard to come by.
One option is to get a depth sensor like an Intel RealSense. Most of these also include an IR light emitter, which means it will always have enough light to work properly. Another popular option is to \u0026ldquo;hack\u0026rdquo; regular color cameras by adding a piece of processed film in front of the lens (which acts as an IR filter). There are a few tutorials on Instructables for doing this. A popular device for this hack is the PS3 Eye camera. Finally, we can opt for security cameras. These tend to have emitters around the lens to ensure there is enough light for the sensor. However, the quality is not great and they usually do not have USB connectivity and will require an adapter. Thermographic cameras, commonly known as FLIR, can be an interesting option. These infrared cameras sense radiation/heat and represent it as a color map. This can be very useful for tracking humans or animals as they can easily be segmented from their surroundings.
AGGRO DR1FT `}),e.add({id:13,href:"/docs/assignments/",title:"Assignments",description:"Assignments",content:""}),e.add({id:14,href:"/docs/",title:"Docs",description:"Seeing Machines Docs",content:""}),search.addEventListener("input",t,!0);function t(){const s=5;var n=this.value,o=e.search(n,{limit:s,enrich:!0});const t=new Map;for(const e of o.flatMap(e=>e.result)){if(t.has(e.doc.href))continue;t.set(e.doc.href,e.doc)}if(suggestions.innerHTML="",suggestions.classList.remove("d-none"),t.size===0&&n){const e=document.createElement("div");e.innerHTML=`No results for "<strong>${n}</strong>"`,e.classList.add("suggestion__no-results"),suggestions.appendChild(e);return}for(const[r,a]of t){const n=document.createElement("div");suggestions.appendChild(n);const e=document.createElement("a");e.href=r,n.appendChild(e);const o=document.createElement("span");o.textContent=a.title,o.classList.add("suggestion__title"),e.appendChild(o);const i=document.createElement("span");if(i.textContent=a.description,i.classList.add("suggestion__description"),e.appendChild(i),suggestions.appendChild(n),suggestions.childElementCount==s)break}}})()