<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=preload as=font href=https://seeingmachines.betamovement.net/fonts/vendor/jost/jost-v4-latin-regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://seeingmachines.betamovement.net/fonts/vendor/jost/jost-v4-latin-500.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://seeingmachines.betamovement.net/fonts/vendor/jost/jost-v4-latin-700.woff2 type=font/woff2 crossorigin><script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script><link rel=stylesheet href=https://seeingmachines.betamovement.net/main.42fe22dfe022cc0fba3cb6f20f694a40a705e406951e7b127a5e079472bea667f273069c4efd2734ed2815f651a67b23df404c97418ea6c6b1c0b74114bac9c5.css integrity="sha512-Qv4i3+AizA+6PLbyD2lKQKcF5AaVHnsSel4HlHK+pmfycwacTv0nNO0oFfZRpnsj30BMl0GOpsaxwLdBFLrJxQ==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>Object Tracking - Seeing Machines</title><meta name=description content="Object Tracking"><link rel=canonical href=https://seeingmachines.betamovement.net/docs/class-4/object-tracking/><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="Object Tracking"><meta property="og:description" content="Object Tracking"><meta property="og:url" content="https://seeingmachines.betamovement.net/docs/class-4/object-tracking/"><meta property="og:site_name" content="Seeing Machines"><meta property="article:published_time" content="2022-10-01T20:48:41-04:00"><meta property="article:modified_time" content="2022-10-01T20:48:41-04:00"><meta property="og:image" content="https://seeingmachines.betamovement.net/default-image.png"><meta property="og:image:alt" content="Seeing Machines"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content><meta name=twitter:creator content="@prisonerjohn"><meta name=twitter:title content="Object Tracking"><meta name=twitter:description content="Object Tracking"><meta name=twitter:image content="https://seeingmachines.betamovement.net/default-image.png"><meta name=twitter:image:alt content="Object Tracking"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://seeingmachines.betamovement.net/#/schema/person/1","name":"Seeing Machines","url":"https://seeingmachines.betamovement.net/","sameAs":[],"image":{"@type":"ImageObject","@id":"https://seeingmachines.betamovement.net/#/schema/image/1","url":"https://seeingmachines.betamovement.net/default-image.png","width":1024,"height":768,"caption":"Seeing Machines"}},{"@type":"WebSite","@id":"https://seeingmachines.betamovement.net/#/schema/website/1","url":"https://seeingmachines.betamovement.net/","name":"Seeing Machines","description":"A programming course where weâ€™ll explore various techniques and solutions for tracking and sensing people or objects in space.","publisher":{"@id":"https://seeingmachines.betamovement.net/#/schema/person/1"}},{"@type":"WebPage","@id":"https://seeingmachines.betamovement.net/docs/class-4/object-tracking/","url":"https://seeingmachines.betamovement.net/docs/class-4/object-tracking/","name":"Object Tracking","description":"Object Tracking","isPartOf":{"@id":"https://seeingmachines.betamovement.net/#/schema/website/1"},"about":{"@id":"https://seeingmachines.betamovement.net/#/schema/person/1"},"datePublished":"2022-10-01T20:48:41CET","dateModified":"2022-10-01T20:48:41CET","breadcrumb":{"@id":"https://seeingmachines.betamovement.net/docs/class-4/object-tracking/#/schema/breadcrumb/1"},"primaryImageOfPage":{"@id":"https://seeingmachines.betamovement.net/docs/class-4/object-tracking/#/schema/image/2"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://seeingmachines.betamovement.net/docs/class-4/object-tracking/"]}]},{"@type":"BreadcrumbList","@id":"https://seeingmachines.betamovement.net/docs/class-4/object-tracking/#/schema/breadcrumb/1","name":"Breadcrumbs","itemListElement":[{"@type":"ListItem","position":1,"item":{"@type":"WebPage","@id":"https://seeingmachines.betamovement.net/","url":"https://seeingmachines.betamovement.net/","name":"Home"}},{"@type":"ListItem","position":2,"item":{"@type":"WebPage","@id":"https://seeingmachines.betamovement.net/docs/","url":"https://seeingmachines.betamovement.net/docs/","name":"Docs"}},{"@type":"ListItem","position":3,"item":{"@type":"WebPage","@id":"https://seeingmachines.betamovement.net/docs/class-4/","url":"https://seeingmachines.betamovement.net/docs/class-4/","name":"Class 4"}},{"@type":"ListItem","position":4,"item":{"@id":"https://seeingmachines.betamovement.net/docs/class-4/object-tracking/"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Article","@id":"https://seeingmachines.betamovement.net/#/schema/article/1","headline":"Object Tracking","description":"Object Tracking","isPartOf":{"@id":"https://seeingmachines.betamovement.net/docs/class-4/object-tracking/"},"mainEntityOfPage":{"@id":"https://seeingmachines.betamovement.net/docs/class-4/object-tracking/"},"datePublished":"2022-10-01T20:48:41CET","dateModified":"2022-10-01T20:48:41CET","author":{"@id":"https://seeingmachines.betamovement.net/#/schema/person/2"},"publisher":{"@id":"https://seeingmachines.betamovement.net/#/schema/person/1"},"image":{"@id":"https://seeingmachines.betamovement.net/docs/class-4/object-tracking/#/schema/image/2"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://seeingmachines.betamovement.net/#/schema/person/2","name":"Elie Zananiri","sameAs":["https://twitter.com/prisonerjohn","https://www.linkedin.com/in/prisonerjohn/","https://github.com/prisonerjohn"]}]},{"@context":"https://schema.org","@graph":[{"@type":"ImageObject","@id":"https://seeingmachines.betamovement.net/docs/class-4/object-tracking/#/schema/image/2","url":"https://seeingmachines.betamovement.net/default-image.png","contentUrl":"https://seeingmachines.betamovement.net/default-image.png","caption":"Object Tracking"}]}]}</script><meta name=theme-color content="#fff"><link rel=icon href=https://seeingmachines.betamovement.net/favicon.ico sizes=any><link rel=icon type=image/svg+xml href=https://seeingmachines.betamovement.net/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=https://seeingmachines.betamovement.net/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://seeingmachines.betamovement.net/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://seeingmachines.betamovement.net/favicon-16x16.png><link rel=manifest crossorigin=use-credentials href=https://seeingmachines.betamovement.net/site.webmanifest></head><body class="docs single"><div class=sticky-top><div class=header-bar></div><header class="navbar navbar-expand-lg navbar-light doks-navbar"><nav class="container-xxl flex-wrap flex-lg-nowrap" aria-label="Main navigation"><a class="navbar-brand order-0" href=https://seeingmachines.betamovement.net/ aria-label="Seeing Machines">Seeing Machines</a>
<button class="btn btn-link order-0 ms-auto d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasExample aria-controls=offcanvasExample><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-more-horizontal"><circle cx="12" cy="12" r="1"/><circle cx="19" cy="12" r="1"/><circle cx="5" cy="12" r="1"/></svg></button><div class="offcanvas offcanvas-start d-lg-none" tabindex=-1 id=offcanvasExample aria-labelledby=offcanvasExampleLabel><div class=header-bar></div><div class=offcanvas-header><h5 class=offcanvas-title id=offcanvasExampleLabel>Browse docs</h5><button type=button class=btn-close data-bs-dismiss=offcanvas aria-label=Close></button></div><div class=offcanvas-body><aside class="doks-sidebar mt-n3"><nav id=doks-docs-nav aria-label="Tertiary navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-5f2cae171c6192fa410df4385f7218aa aria-expanded=false>
Prologue</button><div class=collapse id=section-5f2cae171c6192fa410df4385f7218aa><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-0/getting-started/>Getting Started</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e43c4a6cb52ad623673f8e77a5b10104 aria-expanded=false>
Class 1</button><div class=collapse id=section-e43c4a6cb52ad623673f8e77a5b10104><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/foreword/>Foreword</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/intro-to-of/>Intro to OF</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-2ef5a7f02774e1be242988dba4c3056c aria-expanded=false>
Class 2</button><div class=collapse id=section-2ef5a7f02774e1be242988dba4c3056c><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/data-types/>Data Types</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/arrays/>Arrays</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/images-and-video/>Images and Video</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-6a3be28bcd9707b6b8ff8ac55a6b8cb2 aria-expanded=false>
Class 3</button><div class=collapse id=section-6a3be28bcd9707b6b8ff8ac55a6b8cb2><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-3/computer-vision/>Computer Vision</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e01cc216a97c1db953e2304e6aa8998a aria-expanded=true>
Class 4</button><div class="collapse show" id=section-e01cc216a97c1db953e2304e6aa8998a><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/intro-to-opencv/>Intro to OpenCV</a></li><li><a class="docs-link rounded active" href=https://seeingmachines.betamovement.net/docs/class-4/object-tracking/>Object Tracking</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-cb8d2462ebd86364c3502e7084b7f391 aria-expanded=false>
Class 5</button><div class=collapse id=section-cb8d2462ebd86364c3502e7084b7f391><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/logging/>Logging</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/depth-sensing/>Depth Sensing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c5400dee9e161c6d7e46af7661005794 aria-expanded=false>
Class 6</button><div class=collapse id=section-c5400dee9e161c6d7e46af7661005794><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/pointers/>Pointers</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/depth-images/>Depth Images</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ff9150b580f893ddadd43394cb6173a3 aria-expanded=false>
Class 7</button><div class=collapse id=section-ff9150b580f893ddadd43394cb6173a3><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/3d-primer/>3D Primer</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/depth-world/>Depth World</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c28d8545333b2785a226d11aa3b3b4ed aria-expanded=false>
Class 8</button><div class=collapse id=section-c28d8545333b2785a226d11aa3b3b4ed><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/networking/>Networking</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/texture-sharing/>Texture Sharing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-0bbdd9311c2cb50588b0a462a5438610 aria-expanded=false>
Class 9</button><div class=collapse id=section-0bbdd9311c2cb50588b0a462a5438610><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-9/draw-bounds/>Draw Bounds</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/>Frame Buffers</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c75af093fd3f2e096e4fe21c7e51e7c7 aria-expanded=false>
Class 10</button><div class=collapse id=section-c75af093fd3f2e096e4fe21c7e51e7c7><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/classes/>Classes</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/mapping/>Mapping</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ddbaeabfbe390c84589d5d1c423b9284 aria-expanded=false>
Class 11</button><div class=collapse id=section-ddbaeabfbe390c84589d5d1c423b9284><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-11/machine-learning/>Machine Learning</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-960119d951e6b24e70eaf82d456d181f aria-expanded=false>
Class 12</button><div class=collapse id=section-960119d951e6b24e70eaf82d456d181f><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-12/mobile-development/>Mobile Development</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-37c0442fba31d7a7923dce6846a60711 aria-expanded=false>
Class 13</button><div class=collapse id=section-37c0442fba31d7a7923dce6846a60711><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-13/sound/>Sound</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-56c4b82e7a8861de86a5ebe5eaa62225 aria-expanded=false>
Assignments</button><div class=collapse id=section-56c4b82e7a8861de86a5ebe5eaa62225><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-1/>Assignment 1</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-2/>Assignment 2</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-3/>Assignment 3</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-4/>Assignment 4</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/final-project/>Final Project</a></li></ul></div></li></ul></nav></aside></div></div><button class="btn btn-menu order-2 d-block d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasDoks aria-controls=offcanvasDoks aria-label="Open main menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><div class="offcanvas offcanvas-end border-0 py-lg-1" tabindex=-1 id=offcanvasDoks data-bs-backdrop=true aria-labelledby=offcanvasDoksLabel><div class="header-bar d-lg-none"></div><div class="offcanvas-header d-lg-none"><h2 class="h5 offcanvas-title ps-2" id=offcanvasDoksLabel><a class=text-dark href=https://seeingmachines.betamovement.net/>Seeing Machines</a></h2><button type=button class="btn-close text-reset me-2" data-bs-dismiss=offcanvas aria-label="Close main menu"></button></div><div class="offcanvas-body p-4 p-lg-0"><ul class="nav flex-column flex-lg-row align-items-lg-center mt-2 mt-lg-0 ms-lg-2 me-lg-auto"><li class=nav-item><a class="nav-link ps-0 py-1 active" href=https://seeingmachines.betamovement.net/docs>Docs</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=https://seeingmachines.betamovement.net/docs/assignments>Assignments</a></li></ul><hr class="text-black-50 my-4 d-lg-none"><form class="doks-search position-relative flex-grow-1 ms-lg-auto me-lg-2"><input id=search class="form-control is-search" type=search placeholder="Search docs..." aria-label="Search docs..." autocomplete=off><div id=suggestions class="shadow bg-white rounded d-none"></div></form><hr class="text-black-50 my-4 d-lg-none"><ul class="nav flex-column flex-lg-row"><li class=nav-item><a class="nav-link social-link" href=https://github.com/prisonerjohn/seeing-machines><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg><small class="ms-2 d-lg-none">GitHub</small></a></li><li class=nav-item><a class="nav-link social-link" href=https://twitter.com/prisonerjohn><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-twitter"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg><small class="ms-2 d-lg-none">Twitter</small></a></li></ul><hr class="text-black-50 my-4 d-lg-none"><button id=mode class="btn btn-link" type=button aria-label="Toggle user interface mode">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></div></div></nav></header></div><div class=container-xxl><aside class=doks-sidebar><nav id=doks-docs-nav class="collapse d-lg-none" aria-label="Tertiary navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-5f2cae171c6192fa410df4385f7218aa aria-expanded=false>
Prologue</button><div class=collapse id=section-5f2cae171c6192fa410df4385f7218aa><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-0/getting-started/>Getting Started</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e43c4a6cb52ad623673f8e77a5b10104 aria-expanded=false>
Class 1</button><div class=collapse id=section-e43c4a6cb52ad623673f8e77a5b10104><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/foreword/>Foreword</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/intro-to-of/>Intro to OF</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-2ef5a7f02774e1be242988dba4c3056c aria-expanded=false>
Class 2</button><div class=collapse id=section-2ef5a7f02774e1be242988dba4c3056c><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/data-types/>Data Types</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/arrays/>Arrays</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/images-and-video/>Images and Video</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-6a3be28bcd9707b6b8ff8ac55a6b8cb2 aria-expanded=false>
Class 3</button><div class=collapse id=section-6a3be28bcd9707b6b8ff8ac55a6b8cb2><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-3/computer-vision/>Computer Vision</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e01cc216a97c1db953e2304e6aa8998a aria-expanded=true>
Class 4</button><div class="collapse show" id=section-e01cc216a97c1db953e2304e6aa8998a><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/intro-to-opencv/>Intro to OpenCV</a></li><li><a class="docs-link rounded active" href=https://seeingmachines.betamovement.net/docs/class-4/object-tracking/>Object Tracking</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-cb8d2462ebd86364c3502e7084b7f391 aria-expanded=false>
Class 5</button><div class=collapse id=section-cb8d2462ebd86364c3502e7084b7f391><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/logging/>Logging</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/depth-sensing/>Depth Sensing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c5400dee9e161c6d7e46af7661005794 aria-expanded=false>
Class 6</button><div class=collapse id=section-c5400dee9e161c6d7e46af7661005794><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/pointers/>Pointers</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/depth-images/>Depth Images</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ff9150b580f893ddadd43394cb6173a3 aria-expanded=false>
Class 7</button><div class=collapse id=section-ff9150b580f893ddadd43394cb6173a3><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/3d-primer/>3D Primer</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/depth-world/>Depth World</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c28d8545333b2785a226d11aa3b3b4ed aria-expanded=false>
Class 8</button><div class=collapse id=section-c28d8545333b2785a226d11aa3b3b4ed><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/networking/>Networking</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/texture-sharing/>Texture Sharing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-0bbdd9311c2cb50588b0a462a5438610 aria-expanded=false>
Class 9</button><div class=collapse id=section-0bbdd9311c2cb50588b0a462a5438610><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-9/draw-bounds/>Draw Bounds</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/>Frame Buffers</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c75af093fd3f2e096e4fe21c7e51e7c7 aria-expanded=false>
Class 10</button><div class=collapse id=section-c75af093fd3f2e096e4fe21c7e51e7c7><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/classes/>Classes</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/mapping/>Mapping</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ddbaeabfbe390c84589d5d1c423b9284 aria-expanded=false>
Class 11</button><div class=collapse id=section-ddbaeabfbe390c84589d5d1c423b9284><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-11/machine-learning/>Machine Learning</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-960119d951e6b24e70eaf82d456d181f aria-expanded=false>
Class 12</button><div class=collapse id=section-960119d951e6b24e70eaf82d456d181f><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-12/mobile-development/>Mobile Development</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-37c0442fba31d7a7923dce6846a60711 aria-expanded=false>
Class 13</button><div class=collapse id=section-37c0442fba31d7a7923dce6846a60711><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-13/sound/>Sound</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-56c4b82e7a8861de86a5ebe5eaa62225 aria-expanded=false>
Assignments</button><div class=collapse id=section-56c4b82e7a8861de86a5ebe5eaa62225><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-1/>Assignment 1</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-2/>Assignment 2</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-3/>Assignment 3</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-4/>Assignment 4</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/final-project/>Final Project</a></li></ul></div></li></ul></nav></aside></div><div class="wrap container-xxl" role=document><div class=content><div class="row flex-xl-nowrap"><div class="col-lg-5 col-xl-4 docs-sidebar d-none d-lg-block"><nav class=docs-links aria-label="Main navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-5f2cae171c6192fa410df4385f7218aa aria-expanded=false>
Prologue</button><div class=collapse id=section-5f2cae171c6192fa410df4385f7218aa><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-0/getting-started/>Getting Started</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e43c4a6cb52ad623673f8e77a5b10104 aria-expanded=false>
Class 1</button><div class=collapse id=section-e43c4a6cb52ad623673f8e77a5b10104><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/foreword/>Foreword</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/intro-to-of/>Intro to OF</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-2ef5a7f02774e1be242988dba4c3056c aria-expanded=false>
Class 2</button><div class=collapse id=section-2ef5a7f02774e1be242988dba4c3056c><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/data-types/>Data Types</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/arrays/>Arrays</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/images-and-video/>Images and Video</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-6a3be28bcd9707b6b8ff8ac55a6b8cb2 aria-expanded=false>
Class 3</button><div class=collapse id=section-6a3be28bcd9707b6b8ff8ac55a6b8cb2><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-3/computer-vision/>Computer Vision</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e01cc216a97c1db953e2304e6aa8998a aria-expanded=true>
Class 4</button><div class="collapse show" id=section-e01cc216a97c1db953e2304e6aa8998a><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/intro-to-opencv/>Intro to OpenCV</a></li><li><a class="docs-link rounded active" href=https://seeingmachines.betamovement.net/docs/class-4/object-tracking/>Object Tracking</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-cb8d2462ebd86364c3502e7084b7f391 aria-expanded=false>
Class 5</button><div class=collapse id=section-cb8d2462ebd86364c3502e7084b7f391><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/logging/>Logging</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/depth-sensing/>Depth Sensing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c5400dee9e161c6d7e46af7661005794 aria-expanded=false>
Class 6</button><div class=collapse id=section-c5400dee9e161c6d7e46af7661005794><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/pointers/>Pointers</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/depth-images/>Depth Images</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ff9150b580f893ddadd43394cb6173a3 aria-expanded=false>
Class 7</button><div class=collapse id=section-ff9150b580f893ddadd43394cb6173a3><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/3d-primer/>3D Primer</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/depth-world/>Depth World</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c28d8545333b2785a226d11aa3b3b4ed aria-expanded=false>
Class 8</button><div class=collapse id=section-c28d8545333b2785a226d11aa3b3b4ed><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/networking/>Networking</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/texture-sharing/>Texture Sharing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-0bbdd9311c2cb50588b0a462a5438610 aria-expanded=false>
Class 9</button><div class=collapse id=section-0bbdd9311c2cb50588b0a462a5438610><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-9/draw-bounds/>Draw Bounds</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/>Frame Buffers</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c75af093fd3f2e096e4fe21c7e51e7c7 aria-expanded=false>
Class 10</button><div class=collapse id=section-c75af093fd3f2e096e4fe21c7e51e7c7><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/classes/>Classes</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/mapping/>Mapping</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ddbaeabfbe390c84589d5d1c423b9284 aria-expanded=false>
Class 11</button><div class=collapse id=section-ddbaeabfbe390c84589d5d1c423b9284><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-11/machine-learning/>Machine Learning</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-960119d951e6b24e70eaf82d456d181f aria-expanded=false>
Class 12</button><div class=collapse id=section-960119d951e6b24e70eaf82d456d181f><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-12/mobile-development/>Mobile Development</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-37c0442fba31d7a7923dce6846a60711 aria-expanded=false>
Class 13</button><div class=collapse id=section-37c0442fba31d7a7923dce6846a60711><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-13/sound/>Sound</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-56c4b82e7a8861de86a5ebe5eaa62225 aria-expanded=false>
Assignments</button><div class=collapse id=section-56c4b82e7a8861de86a5ebe5eaa62225><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-1/>Assignment 1</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-2/>Assignment 2</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-3/>Assignment 3</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-4/>Assignment 4</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/final-project/>Final Project</a></li></ul></div></li></ul></nav></div><nav class="docs-toc d-none d-xl-block col-xl-3" aria-label="Secondary navigation"><div class=d-xl-none><button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#onThisPage aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>On this page</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button><div class=collapse id=onThisPage><div class="card card-body mt-3 py-1"><div class=page-links><nav id=TableOfContents><ul><li><a href=#contour-finding>Contour Finding</a></li><li><a href=#color-space>Color Space</a></li><li><a href=#mouse-selector>Mouse Selector</a></li><li><a href=#area-range>Area Range</a></li><li><a href=#filtering>Filtering</a><ul><li><a href=#blur>Blur</a></li><li><a href=#dilate--erode>Dilate / Erode</a></li></ul></li><li><a href=#tracking>Tracking</a></li></ul></nav></div></div></div></div><div class="page-links d-none d-xl-block"><h3>On this page</h3><nav id=TableOfContents><ul><li><a href=#contour-finding>Contour Finding</a></li><li><a href=#color-space>Color Space</a></li><li><a href=#mouse-selector>Mouse Selector</a></li><li><a href=#area-range>Area Range</a></li><li><a href=#filtering>Filtering</a><ul><li><a href=#blur>Blur</a></li><li><a href=#dilate--erode>Dilate / Erode</a></li></ul></li><li><a href=#tracking>Tracking</a></li></ul></nav></div></nav><main class="docs-content col-lg-11 col-xl-9"><h1>Object Tracking</h1><p class=lead></p><nav class=d-xl-none aria-label="Quaternary navigation"><div class=d-xl-none><button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#onThisPage aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>On this page</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button><div class=collapse id=onThisPage><div class="card card-body mt-3 py-1"><div class=page-links><nav id=TableOfContents><ul><li><a href=#contour-finding>Contour Finding</a></li><li><a href=#color-space>Color Space</a></li><li><a href=#mouse-selector>Mouse Selector</a></li><li><a href=#area-range>Area Range</a></li><li><a href=#filtering>Filtering</a><ul><li><a href=#blur>Blur</a></li><li><a href=#dilate--erode>Dilate / Erode</a></li></ul></li><li><a href=#tracking>Tracking</a></li></ul></nav></div></div></div></div><div class="page-links d-none d-xl-block"><h3>On this page</h3><nav id=TableOfContents><ul><li><a href=#contour-finding>Contour Finding</a></li><li><a href=#color-space>Color Space</a></li><li><a href=#mouse-selector>Mouse Selector</a></li><li><a href=#area-range>Area Range</a></li><li><a href=#filtering>Filtering</a><ul><li><a href=#blur>Blur</a></li><li><a href=#dilate--erode>Dilate / Erode</a></li></ul></li><li><a href=#tracking>Tracking</a></li></ul></nav></div></nav><p>Let&rsquo;s build an app together that tracks an object in the frame over time.</p><p>We are going to track a red playing card and can assume that the card will be the &ldquo;most red&rdquo; element in the frame.</p><figure style='display:block;margin:1em auto;width:600px'><a href=red-card.jpg><img style='display:block;margin:0 auto' src=red-card.jpg alt="A Red Card"></a></figure><h2 id=contour-finding>Contour Finding <a href=#contour-finding class=anchor aria-hidden=true>#</a></h2><p>In order to do this, we will use a <em>Contour Finding</em> algorithm.</p><p>Contour finding consists of identifying regions of images matching a particular pattern. These patterns can be defined by color, size, shape, speed, etc. Contour finding can be used to follow objects or people in an image.</p><figure style="width:600px;height:400px;display:block;margin:0 auto" markdown=1><div style="padding:56.25% 0 0;position:relative"><iframe src=https://player.vimeo.com/video/141447523 style=position:absolute;top:0;left:0;width:100%;height:100% frameborder=0 allow="autoplay; fullscreen" allowfullscreen></iframe></div><script src=https://player.vimeo.com/api/player.js></script><figcaption><i><a href=https://vimeo.com/141447523>BloodBank - Video game</a> from <a href=https://vimeo.com/vincentdevevey>Vincent de Vevey</a> on <a href=https://vimeo.com>Vimeo</a>.</i></figcaption></figure><p>If we break it down, this usually consist of many steps:</p><ol><li>Convert the pixel data to an appropriate color space.</li><li>Threshold the image based on a target color and offset. As we saw previously, video pixel colors vary over frames, so we need to use an offset to look for a color range.</li><li>Run the OpenCV contour finding operation on the image.</li><li>Filter the array of contours and only keep the ones that match the requested parameters.</li></ol><p>This is where <code>ofxCv</code> comes in very handy, as we can use the <code>ofxCv::ContourFinder</code> class to handle a big part of the work.</p><pre><code class=language-cpp>// ofApp.h
#pragma once

#include &quot;ofMain.h&quot;
#include &quot;ofxCv.h&quot;
#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void update();
  void draw();

  ofVideoGrabber grabber;

  ofxCv::ContourFinder contourFinder;

  ofParameter&lt;ofColor&gt; colorTarget;
  ofParameter&lt;int&gt; colorOffset;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  ofSetWindowShape(640, 480);

  // Setup the grabber.
  grabber.setup(640, 480);

  // Setup the contour finder and parameters.
  contourFinder.setUseTargetColor(true);

  colorTarget.set(&quot;Color Target&quot;, ofColor(255, 0, 0));
  colorOffset.set(&quot;Color Offset&quot;, 10, 0, 255);

  // Setup the gui.
  guiPanel.setup(&quot;Color Tracker&quot;, &quot;settings.json&quot;);
  guiPanel.add(colorTarget);
  guiPanel.add(colorOffset);
}

void ofApp::update()
{
  grabber.update();
  if (grabber.isFrameNew())
  {
    // Update parameters.
    contourFinder.setTargetColor(colorTarget);
    contourFinder.setThreshold(colorOffset);

    // Find contours.
    contourFinder.findContours(grabber);
  }
}

void ofApp::draw()
{
  ofSetColor(255);

  // Draw the grabber image.
  grabber.draw(0, 0, ofGetWidth(), ofGetHeight());

  // Draw the found contours.
  contourFinder.draw();

  // Draw the gui.
  guiPanel.draw();
}
</code></pre><h2 id=color-space>Color Space <a href=#color-space class=anchor aria-hidden=true>#</a></h2><p>While this application technically works, it is hard to get the settings right. Let&rsquo;s modify it to make it easier to use.</p><p>We often get better results when comparing colors in HSV rather than RGB space.</p><ul><li>RGB defines how much red, green, and blue is in an image.<ul><li>A small change in values might result in a greater difference seen, and vice-versa.</li><li>When working near the grayscale range (white to black), it is hard to evaluate how much red, green, and blue is actually in the pixel.</li></ul></li><li>HSV defines colors as levels of hue, saturation, and brightness.<ul><li>This is closer to how humans perceive color, and differentiate objects they see in space.</li><li>It is easier to isolate parameters. We will often just care about the brightness of an image, particularly in the grayscale range.</li><li>It is a more logical set of parameters for many image analysis algorithms.</li></ul></li></ul><p>We can tell <code>ofxCv::ContourFinder</code> to use HSV by passing a second parameter to the <code>setTargetColor()</code> method:</p><pre><code class=language-cpp>contourFinder.setTargetColor(colorTarget, ofxCv::TRACK_COLOR_HSV);
</code></pre><h2 id=mouse-selector>Mouse Selector <a href=#mouse-selector class=anchor aria-hidden=true>#</a></h2><p>We can use the mouse to interactively select the color under the cursor. This will remove any guesswork from setting the target color accurately.</p><pre><code class=language-cpp>// ofApp.h
#pragma once

#include &quot;ofMain.h&quot;
#include &quot;ofxCv.h&quot;
#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void update();
  void draw();

  void mousePressed(int x, int y, int button);

  ofVideoGrabber grabber;
  ofImage processImg;

  ofxCv::ContourFinder contourFinder;

  ofParameter&lt;ofColor&gt; colorTarget;
  ofParameter&lt;int&gt; colorOffset;
  
  ofColor colorUnderMouse;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  ofSetWindowShape(640, 480);

  // Setup the grabber.
  grabber.setup(640, 480);

  // Setup the contour finder and parameters.
  contourFinder.setUseTargetColor(true);

  colorTarget.set(&quot;Color Target&quot;, ofColor(255, 0, 0));
  colorOffset.set(&quot;Color Offset&quot;, 10, 0, 255);

  // Setup the gui.
  guiPanel.setup(&quot;Color Tracker&quot;, &quot;settings.json&quot;);
  guiPanel.add(colorTarget);
  guiPanel.add(colorOffset);
}

void ofApp::update()
{
  grabber.update();
  if (grabber.isFrameNew())
  {
    processImg.setFromPixels(grabber.getPixels());

    // Save the color of the pixel under the mouse.
    colorUnderMouse = processImg.getColor(ofGetMouseX(), ofGetMouseY());

    // Update parameters.
    contourFinder.setTargetColor(colorTarget, ofxCv::TRACK_COLOR_HSV);
    contourFinder.setThreshold(colorOffset);

    // Find contours.
    contourFinder.findContours(processImg);
  }
}

void ofApp::draw()
{
  ofSetColor(255);

  // Draw the grabber image.
  grabber.draw(0, 0, ofGetWidth(), ofGetHeight());

  // Draw the found contours.
  contourFinder.draw();
  
  // Draw the color under the mouse.
  ofPushStyle();
  ofSetColor(colorUnderMouse);
  ofDrawRectangle(ofGetMouseX() - 25, ofGetMouseY() - 25, 50, 50);
  ofNoFill();
  ofSetColor(colorUnderMouse.getInverted());
  ofDrawRectangle(ofGetMouseX() - 25, ofGetMouseY() - 25, 50, 50);
  ofPopStyle();

  // Draw the gui.
  guiPanel.draw();
}

void ofApp::mousePressed(int x, int y, int button)
{
  if (!guiPanel.getShape().inside(x, y))
  {
    // Track the color under the mouse.
    colorTarget = colorUnderMouse;
  }
}
</code></pre><h2 id=area-range>Area Range <a href=#area-range class=anchor aria-hidden=true>#</a></h2><p>The contour finder seems to be working too well. We are getting many blobs, and most are too big or too small to consider.</p><p>We can limit the range of blob sizes to look for, and only match the ones within this range.</p><p><code>ofxCv::ContourFinder</code> gives us a few different options for this. In all cases, we are looking at the area of the blob bounding box. The difference is simply in how this gets calculated.</p><ul><li><code>setMinArea()</code> / <code>setMaxArea()</code> set the range in pixels. The max range depends on the size of the image as a larger image will have more pixel area.<ul><li>e.g. If a blob&rsquo;s dimensions are 20px width by 10px height, the area is <code>w x h</code> = 200px<sup>2</sup>.</li></ul></li><li><code>setMinAreaRadius()</code> / <code>setMaxAreaRadius()</code> set the area using the blob radius. This can be useful if the blobs we are looking for are circular in shape.</li><li><code>setMinAreaNorm()</code> / <code>setMaxAreaNorm()</code> set the area using <em>normalized</em> coordinates. This means the range is always between <code>0.0</code> and <code>1.0</code>, no matter what the image size is.</li></ul><pre><code class=language-cpp>// ofApp.h
#pragma once

#include &quot;ofMain.h&quot;
#include &quot;ofxCv.h&quot;
#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void update();
  void draw();

  void mousePressed(int x, int y, int button);

  ofVideoGrabber grabber;
  ofImage processImg;

  ofxCv::ContourFinder contourFinder;

  ofParameter&lt;ofColor&gt; colorTarget;
  ofParameter&lt;int&gt; colorOffset;
  
  ofColor colorUnderMouse;

  ofParameter&lt;float&gt; minArea;
  ofParameter&lt;float&gt; maxArea;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  ofSetWindowShape(640, 480);

  // Setup the grabber.
  grabber.setup(640, 480);

  // Setup the contour finder and parameters.
  contourFinder.setUseTargetColor(true);

  colorTarget.set(&quot;Color Target&quot;, ofColor(255, 0, 0));
  colorOffset.set(&quot;Color Offset&quot;, 10, 0, 255);
  minArea.set(&quot;Min Area&quot;, 0.01f, 0, 0.5f);
  maxArea.set(&quot;Max Area&quot;, 0.05f, 0, 0.5f);

  // Setup the gui.
  guiPanel.setup(&quot;Color Tracker&quot;, &quot;settings.json&quot;);
  guiPanel.add(colorTarget);
  guiPanel.add(colorOffset);
  guiPanel.add(minArea);
  guiPanel.add(maxArea);
}

void ofApp::update()
{
  grabber.update();
  if (grabber.isFrameNew())
  {
    processImg.setFromPixels(grabber.getPixels());

    // Save the color of the pixel under the mouse.
    colorUnderMouse = processImg.getColor(ofGetMouseX(), ofGetMouseY());

    // Update parameters.
    contourFinder.setTargetColor(colorTarget, ofxCv::TRACK_COLOR_HSV);
    contourFinder.setThreshold(colorOffset);
    contourFinder.setMinAreaNorm(minArea);
    contourFinder.setMaxAreaNorm(maxArea);

    // Find contours.
    contourFinder.findContours(processImg);
  }
}

void ofApp::draw()
{
  ofSetColor(255);

  // Draw the grabber image.
  grabber.draw(0, 0, ofGetWidth(), ofGetHeight());
  
  // Draw the found contours.
  contourFinder.draw();

  // Draw the color under the mouse.
  ofPushStyle();
  ofSetColor(colorUnderMouse);
  ofDrawRectangle(ofGetMouseX() - 25, ofGetMouseY() - 25, 50, 50);
  ofNoFill();
  ofSetColor(colorUnderMouse.getInverted());
  ofDrawRectangle(ofGetMouseX() - 25, ofGetMouseY() - 25, 50, 50);
  ofPopStyle();

  // Draw the gui.
  guiPanel.draw();
}

void ofApp::mousePressed(int x, int y, int button)
{
  if (!guiPanel.getShape().inside(x, y))
  {
    // Track the color under the mouse.
    colorTarget = colorUnderMouse;
  }
}
</code></pre><figure style="width:600px;height:400px;display:block;margin:0 auto" markdown=1><div style="padding:56.25% 0 0;position:relative"><iframe src=https://player.vimeo.com/video/1859773 style=position:absolute;top:0;left:0;width:100%;height:100% frameborder=0 allow="autoplay; fullscreen" allowfullscreen></iframe></div><script src=https://player.vimeo.com/api/player.js></script><figcaption><i><a href=https://vimeo.com/1859773>Royal Opera House - Audience: "chatting and following"</a> from <a href=https://vimeo.com/randomvids>RANDOM INTERNATIONAL</a> on <a href=https://vimeo.com>Vimeo</a>.</figcaption></i></figure><h2 id=filtering>Filtering <a href=#filtering class=anchor aria-hidden=true>#</a></h2><p>The pattern on the back of the card is making it hard to get a clean blob. It is getting separated into different parts. Let&rsquo;s try to filter the image before sending it to the contour finder to get better results.</p><p>The following operations are called <em>convolution</em> operations. A convolution is a process by which a pixel looks at its neighbours values to calculate its own value. The rules to calculate this value are set in a <em>kernel</em>.</p><p>A <em>kernel</em> has a size and weights.</p><ul><li>The size, also called the <em>window</em>, specifies how many neighbours to look at when making the calculation. For example, a <code>3x3</code> kernel will consider the 8 direct neighbours and the pixel itself.</li><li>The weights represent how much of each pixel in the kernel to take in when calculating the final value. A <em>normalized</em> kernel will have the same weights throughout, while a non-normalized one will have different weight values.</li><li>The window is usually odd and square, also called <em>box</em>, (e.g. <code>3x3</code> or <code>5x5</code>) and the pixel in question is in the middle of it.</li></ul><pre><code class=language-python>                          [ 1  4  6  4 1 ]
[ 1 1 1 ]    [ 1 2 1 ]    [ 4 16 24 16 4 ]
[ 1 1 1 ]    [ 2 4 2 ]    [ 6 24 36 24 6 ]
[ 1 1 1 ]    [ 1 2 1 ]    [ 4 16 24 16 4 ]
                          [ 1  4  6  4 1 ]
</code></pre><h3 id=blur>Blur <a href=#blur class=anchor aria-hidden=true>#</a></h3><p>Blurring the image is a good first step to smooth out unwanted details in an image and make it more homogenous.</p><p><code>ofxCv</code> offers a few options for blurring:</p><ul><li><a href=https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga8c45db9afe636703801b0b2e440fce37><code>cv::blur()</code></a> uses a normalized kernel.</li><li><a href=https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1><code>cv::GaussianBlur()</code></a> uses a weighted <a href=https://en.wikipedia.org/wiki/Gaussian_blur>Gaussian</a> kernel.</li><li><a href=https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga564869aa33e58769b4469101aac458f9><code>cv::medianBlur()</code></a> uses the median value of the neighbours in the kernel.</li></ul><p>For this application, it makes the most sense to use the median blur, as that will allow the larger red part of the card to overtake the smaller white parts.</p><pre><code class=language-cpp>// ofApp.h
#pragma once

#include &quot;ofMain.h&quot;
#include &quot;ofxCv.h&quot;
#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void update();
  void draw();

  void mousePressed(int x, int y, int button);

  ofVideoGrabber grabber;
  ofImage processImg;

  ofxCv::ContourFinder contourFinder;

  ofParameter&lt;ofColor&gt; colorTarget;
  ofParameter&lt;int&gt; colorOffset;
  
  ofColor colorUnderMouse;

  ofParameter&lt;float&gt; minArea;
  ofParameter&lt;float&gt; maxArea;

  ofParameter&lt;int&gt; blurAmount;

  ofParameter&lt;bool&gt; debugProcess;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  ofSetWindowShape(640, 480);

  // Setup the grabber.
  grabber.setup(640, 480);

  // Setup the contour finder and parameters.
  contourFinder.setUseTargetColor(true);

  colorTarget.set(&quot;Color Target&quot;, ofColor(255, 0, 0));
  colorOffset.set(&quot;Color Offset&quot;, 10, 0, 255);
  minArea.set(&quot;Min Area&quot;, 0.01f, 0, 0.5f);
  maxArea.set(&quot;Max Area&quot;, 0.05f, 0, 0.5f);
  blurAmount.set(&quot;Blur Amount&quot;, 0, 0, 100);
  debugProcess.set(&quot;Debug Process&quot;, false);

  // Setup the gui.
  guiPanel.setup(&quot;Color Tracker&quot;, &quot;settings.json&quot;);
  guiPanel.add(colorTarget);
  guiPanel.add(colorOffset);
  guiPanel.add(minArea);
  guiPanel.add(maxArea);
  guiPanel.add(blurAmount);
  guiPanel.add(debugProcess);
}

void ofApp::update()
{
  grabber.update();
  if (grabber.isFrameNew())
  {
    processImg.setFromPixels(grabber.getPixels());

    // Filter the image.
    if (blurAmount &gt; 0)
    {
      //ofxCv::blur(processImg, blurAmount);
      //ofxCv::GaussianBlur(processImg, blurAmount);
      ofxCv::medianBlur(processImg, blurAmount);
      processImg.update();
    }

    // Save the color of the pixel under the mouse.
    colorUnderMouse = processImg.getColor(ofGetMouseX(), ofGetMouseY());

    // Update parameters.
    contourFinder.setTargetColor(colorTarget, ofxCv::TRACK_COLOR_HSV);
    contourFinder.setThreshold(colorOffset);
    contourFinder.setMinAreaNorm(minArea);
    contourFinder.setMaxAreaNorm(maxArea);

    // Find contours.
    contourFinder.findContours(processImg);
  }
}

void ofApp::draw()
{
  ofSetColor(255);

  if (debugProcess)
  {
    // Draw the process image.
    processImg.draw(0, 0, ofGetWidth(), ofGetHeight());
  }
  else
  {
    // Draw the grabber image.
    grabber.draw(0, 0, ofGetWidth(), ofGetHeight());
  }

  // Draw the found contours.
  contourFinder.draw();

  // Draw the color under the mouse.
  ofPushStyle();
  ofSetColor(colorUnderMouse);
  ofDrawRectangle(ofGetMouseX() - 25, ofGetMouseY() - 25, 50, 50);
  ofNoFill();
  ofSetColor(colorUnderMouse.getInverted());
  ofDrawRectangle(ofGetMouseX() - 25, ofGetMouseY() - 25, 50, 50);
  ofPopStyle();

  // Draw the gui.
  guiPanel.draw();
}

void ofApp::mousePressed(int x, int y, int button)
{
  if (!guiPanel.getShape().inside(x, y))
  {
    // Track the color under the mouse.
    colorTarget = colorUnderMouse;
  }
}
</code></pre><h3 id=dilate--erode>Dilate / Erode <a href=#dilate--erode class=anchor aria-hidden=true>#</a></h3><p><a href=https://docs.opencv.org/2.4/doc/tutorials/imgproc/erosion_dilatation/erosion_dilatation.html>Dilation and erosion</a> are <em>morphology</em> based operations, meaning that they are based on shapes in the image. These tend to be used to remove noise, or to find features in an image like holes.</p><p>Dilation and erosion are counterparts of each other.</p><ul><li><a href=https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga4ff0f3318642c4f469d0e11f242f3b6c><code>dilate()</code></a> grows the bright regions of the image to take up more pixels.</li></ul><figure style='display:block;margin:1em auto;width:600px'><a href=https://docs.opencv.org/2.4/_images/Morphology_1_Tutorial_Theory_Dilatation_2.png><img style='display:block;margin:0 auto' src=https://docs.opencv.org/2.4/_images/Morphology_1_Tutorial_Theory_Dilatation_2.png alt=Dilation></a><figcaption><a href=https://docs.opencv.org/2.4/doc/tutorials/imgproc/erosion_dilatation/erosion_dilatation.html><em>Eroding and Dilating</em></a></figcaption></figure><ul><li><a href=https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaeb1e0c1033e3f6b891a25d0511362aeb><code>erode()</code></a> grows the dark regions of the image to take up more pixels.</li></ul><figure style='display:block;margin:1em auto;width:600px'><a href=https://docs.opencv.org/2.4/_images/Morphology_1_Tutorial_Theory_Erosion_2.png><img style='display:block;margin:0 auto' src=https://docs.opencv.org/2.4/_images/Morphology_1_Tutorial_Theory_Erosion_2.png alt=Dilation></a><figcaption><a href=https://docs.opencv.org/2.4/doc/tutorials/imgproc/erosion_dilatation/erosion_dilatation.html><em>Eroding and Dilating</em></a></figcaption></figure><p>For this application, we should use erosion as we want the darker red parts of the card to overtake the brighter white parts.</p><pre><code class=language-cpp>// ofApp.h
#pragma once

#include &quot;ofMain.h&quot;
#include &quot;ofxCv.h&quot;
#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void update();
  void draw();

  void mousePressed(int x, int y, int button);

  ofVideoGrabber grabber;
  ofImage processImg;

  ofxCv::ContourFinder contourFinder;

  ofParameter&lt;ofColor&gt; colorTarget;
  ofParameter&lt;int&gt; colorOffset;
  
  ofColor colorUnderMouse;

  ofParameter&lt;float&gt; minArea;
  ofParameter&lt;float&gt; maxArea;

  ofParameter&lt;int&gt; blurAmount;
  ofParameter&lt;int&gt; erodeIterations;

  ofParameter&lt;bool&gt; debugProcess;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  ofSetWindowShape(640, 480);

  // Setup the grabber.
  grabber.setup(640, 480);

  // Setup the contour finder and parameters.
  contourFinder.setUseTargetColor(true);

  colorTarget.set(&quot;Color Target&quot;, ofColor(255, 0, 0));
  colorOffset.set(&quot;Color Offset&quot;, 10, 0, 255);
  minArea.set(&quot;Min Area&quot;, 0.01f, 0, 0.5f);
  maxArea.set(&quot;Max Area&quot;, 0.05f, 0, 0.5f);
  blurAmount.set(&quot;Blur Amount&quot;, 0, 0, 100);
  erodeIterations.set(&quot;Erode Iterations&quot;, 0, 0, 10);
  debugProcess.set(&quot;Debug Process&quot;, false);

  // Setup the gui.
  guiPanel.setup(&quot;Color Tracker&quot;, &quot;settings.json&quot;);
  guiPanel.add(colorTarget);
  guiPanel.add(colorOffset);
  guiPanel.add(minArea);
  guiPanel.add(maxArea);
  guiPanel.add(blurAmount);
  guiPanel.add(erodeIterations);
  guiPanel.add(debugProcess);
}

void ofApp::update()
{
  grabber.update();
  if (grabber.isFrameNew())
  {
    processImg.setFromPixels(grabber.getPixels());

    // Filter the image.
    if (blurAmount &gt; 0)
    {
      //ofxCv::blur(processImg, blurAmount);
      //ofxCv::GaussianBlur(processImg, blurAmount);
      ofxCv::medianBlur(processImg, blurAmount);
    }
    if (erodeIterations &gt; 0)
    {
      ofxCv::erode(processImg, erodeIterations.get());
    }
    processImg.update();

    // Save the color of the pixel under the mouse.
    colorUnderMouse = processImg.getColor(ofGetMouseX(), ofGetMouseY());

    // Update parameters.
    contourFinder.setTargetColor(colorTarget, ofxCv::TRACK_COLOR_HSV);
    contourFinder.setThreshold(colorOffset);
    contourFinder.setMinAreaNorm(minArea);
    contourFinder.setMaxAreaNorm(maxArea);

    // Find contours.
    contourFinder.findContours(processImg);
  }
}

void ofApp::draw()
{
  ofSetColor(255);

  if (debugProcess)
  {
    // Draw the process image.
    processImg.draw(0, 0, ofGetWidth(), ofGetHeight());
  }
  else
  {
    // Draw the grabber image.
    grabber.draw(0, 0, ofGetWidth(), ofGetHeight());
  }

  // Draw the found contours.
  contourFinder.draw();

  // Draw the color under the mouse.
  ofPushStyle();
  ofSetColor(colorUnderMouse);
  ofDrawRectangle(ofGetMouseX() - 25, ofGetMouseY() - 25, 50, 50);
  ofNoFill();
  ofSetColor(colorUnderMouse.getInverted());
  ofDrawRectangle(ofGetMouseX() - 25, ofGetMouseY() - 25, 50, 50);
  ofPopStyle();

  // Draw the gui.
  guiPanel.draw();
}

void ofApp::mousePressed(int x, int y, int button)
{
  if (!guiPanel.getShape().inside(x, y))
  {
    // Track the color under the mouse.
    colorTarget = colorUnderMouse;
  }
}
</code></pre><h2 id=tracking>Tracking <a href=#tracking class=anchor aria-hidden=true>#</a></h2><p>Blob tracking means to follow and track objects over time. Instead of interpreting each frame as a unique &ldquo;event&rdquo;, we can compare the current blobs detected to previous ones and see if there are correspondences. By tracking blobs over time, we can assign them parameters like an age, a direction of movement, a velocity, and use those parameters to build rich interactive applications.</p><figure style="width:600px;height:400px;display:block;margin:0 auto" markdown=1><div style="padding:56.25% 0 0;position:relative"><iframe src=https://player.vimeo.com/video/137879996 style=position:absolute;top:0;left:0;width:100%;height:100% frameborder=0 allow="autoplay; fullscreen" allowfullscreen></iframe></div><script src=https://player.vimeo.com/api/player.js></script><figcaption><i><a href=https://vimeo.com/137879996>collimation</a> from <a href=https://vimeo.com/user22070294>Brad Todd</a> on <a href=https://vimeo.com>Vimeo</a>.</i></figcaption></figure><p>Tracking is not part of the OpenCV library but it is such a common operation to perform post contour finding that a set of tracking functions are included with <code>ofxCv</code>.</p><p><code>ofxCv::Tracker</code> is a powerful blob tracker that can be used on its own or with <code>ofxCv::ContourFinder</code>. In fact, <code>ofxCv::ContourFinder</code> has a tracker embedded in it which can be accessed using <code>ofxCv::ContourFinder.getTracker()</code>.</p><p>Tracked blobs are identified using a label. If two blobs from different frames have the same label, then they are considered the same.</p><p>The tracker takes in parameters to set how it operates.</p><ul><li><em>Persistence</em> is the amount of time a blob can disappear before it is actually considered dead.<ul><li>This is set in frames.</li><li>If it is set to <code>0</code> then a blob will stop being tracked as soon as it disappears.</li><li>If it is set higher, for example to <code>15</code>, then a blob can disappear for up to 15 frames and then reappear and keep its previous label.</li><li>This can be helpful if the video feed is not stable and blobs seem to flicker on and off.</li></ul></li><li><em>Max distance</em> is the maximum distance a blob can travel between two frames.<ul><li>This is set in pixels.</li><li>If a blob is less than the max distance away from a previous blob, it is considered one and the same and keeps its label.</li><li>If a blob is further away than max distance from any previous blobs, it is considered new and gets a new label.</li></ul></li></ul><pre><code class=language-cpp>// ofApp.h
#pragma once

#include &quot;ofMain.h&quot;
#include &quot;ofxCv.h&quot;
#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void update();
  void draw();

  void mousePressed(int x, int y, int button);

  ofVideoGrabber grabber;
  ofImage processImg;

  ofxCv::ContourFinder contourFinder;

  ofParameter&lt;ofColor&gt; colorTarget;
  ofParameter&lt;int&gt; colorOffset;
  
  ofColor colorUnderMouse;

  ofParameter&lt;float&gt; minArea;
  ofParameter&lt;float&gt; maxArea;

  ofParameter&lt;int&gt; blurAmount;
  ofParameter&lt;int&gt; erodeIterations;

  ofParameter&lt;int&gt; persistence;
  ofParameter&lt;float&gt; maxDistance;

  ofParameter&lt;bool&gt; showLabels;
  ofParameter&lt;bool&gt; debugProcess;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  ofSetWindowShape(640, 480);

  // Setup the grabber.
  grabber.setup(640, 480);

  // Setup the contour finder and parameters.
  contourFinder.setUseTargetColor(true);

  colorTarget.set(&quot;Color Target&quot;, ofColor(255, 0, 0));
  colorOffset.set(&quot;Color Offset&quot;, 10, 0, 255);
  minArea.set(&quot;Min Area&quot;, 0.01f, 0, 0.5f);
  maxArea.set(&quot;Max Area&quot;, 0.05f, 0, 0.5f);
  blurAmount.set(&quot;Blur Amount&quot;, 0, 0, 100);
  erodeIterations.set(&quot;Erode Iterations&quot;, 0, 0, 10);
  persistence.set(&quot;Persistence&quot;, 15, 0, 60);
  maxDistance.set(&quot;Max Distance&quot;, 64, 0, 640);
  showLabels.set(&quot;Show Labels&quot;, false);
  debugProcess.set(&quot;Debug Process&quot;, false);

  // Setup the gui.
  guiPanel.setup(&quot;Color Tracker&quot;, &quot;settings.json&quot;);
  guiPanel.add(colorTarget);
  guiPanel.add(colorOffset);
  guiPanel.add(minArea);
  guiPanel.add(maxArea);
  guiPanel.add(blurAmount);
  guiPanel.add(erodeIterations);
  guiPanel.add(persistence);
  guiPanel.add(maxDistance);
  guiPanel.add(showLabels);
  guiPanel.add(debugProcess);
}

void ofApp::update()
{
  grabber.update();
  if (grabber.isFrameNew())
  {
    processImg.setFromPixels(grabber.getPixels());

    // Filter the image.
    if (blurAmount &gt; 0)
    {
      //ofxCv::blur(processImg, blurAmount);
      //ofxCv::GaussianBlur(processImg, blurAmount);
      ofxCv::medianBlur(processImg, blurAmount);
    }
    if (erodeIterations &gt; 0)
    {
      ofxCv::erode(processImg, erodeIterations.get());
    }
    processImg.update();

    // Save the color of the pixel under the mouse.
    colorUnderMouse = processImg.getColor(ofGetMouseX(), ofGetMouseY());

    // Update parameters.
    contourFinder.setTargetColor(colorTarget, ofxCv::TRACK_COLOR_HSV);
    contourFinder.setThreshold(colorOffset);
    contourFinder.setMinAreaNorm(minArea);
    contourFinder.setMaxAreaNorm(maxArea);
    contourFinder.getTracker().setPersistence(persistence);
    contourFinder.getTracker().setMaximumDistance(maxDistance);

    // Find contours.
    contourFinder.findContours(processImg);
  }
}

void ofApp::draw()
{
  ofSetColor(255);

  if (debugProcess)
  {
    // Draw the process image.
    processImg.draw(0, 0, ofGetWidth(), ofGetHeight());
  }
  else
  {
    // Draw the grabber image.
    grabber.draw(0, 0, ofGetWidth(), ofGetHeight());
  }

  // Draw the found contours.
  contourFinder.draw();

  if (showLabels)
  {
    ofxCv::RectTracker&amp; tracker = contourFinder.getTracker();

    ofSetColor(255);
    for (int i = 0; i &lt; contourFinder.size(); i++) 
    {
      ofPoint center = ofxCv::toOf(contourFinder.getCenter(i));
      int label = contourFinder.getLabel(i);
      string msg = ofToString(label) + &quot;:&quot; + ofToString(tracker.getAge(label));
      ofDrawBitmapString(msg, center.x, center.y);
      ofVec2f velocity = ofxCv::toOf(contourFinder.getVelocity(i));
      ofDrawLine(center.x, center.y, center.x + velocity.x, center.y + velocity.y);
    }
  }

  // Draw the color under the mouse.
  ofPushStyle();
  ofSetColor(colorUnderMouse);
  ofDrawRectangle(ofGetMouseX() - 25, ofGetMouseY() - 25, 50, 50);
  ofNoFill();
  ofSetColor(colorUnderMouse.getInverted());
  ofDrawRectangle(ofGetMouseX() - 25, ofGetMouseY() - 25, 50, 50);
  ofPopStyle();

  // Draw the gui.
  guiPanel.draw();
}

void ofApp::mousePressed(int x, int y, int button)
{
  if (!guiPanel.getShape().inside(x, y))
  {
    // Track the color under the mouse.
    colorTarget = colorUnderMouse;
  }
}
</code></pre><div class="page-footer-meta d-flex flex-column flex-md-row justify-content-between"></div><div class="docs-navigation d-flex justify-content-between"><a href=https://seeingmachines.betamovement.net/docs/class-4/intro-to-opencv/><div class="card my-1"><div class="card-body py-2">&larr; Intro to OpenCV</div></div></a><a class=ms-auto href=https://seeingmachines.betamovement.net/docs/class-5/logging/><div class="card my-1"><div class="card-body py-2">Logging &rarr;</div></div></a></div></main></div></div></div><footer class="footer text-muted"><div class=container-xxl><div class=row><div class="col-lg-8 order-last order-lg-first"><ul class=list-inline><li class=list-inline-item>Powered by <a class=text-muted href=https://github.com/>GitHub</a>, <a class=text-muted href=https://gohugo.io/>Hugo</a>, and <a class=text-muted href=https://getdoks.org/>Doks</a></li></ul></div><div class="col-lg-8 order-first order-lg-last text-lg-end"><ul class=list-inline></ul></div></div></div></footer><script src=https://seeingmachines.betamovement.net/js/bootstrap.min.7315382e899a7d7132d93fdf0d6682c67a93f0e72ee1a757f33f3207de3b14e2460a935c9d4cec78f86d94ab892d053c70540695eed0bbb7bf5bdc979e6f5a9f.js integrity="sha512-cxU4LomafXEy2T/fDWaCxnqT8Ocu4adX8z8yB947FOJGCpNcnUzsePhtlKuJLQU8cFQGle7Qu7e/W9yXnm9anw==" crossorigin=anonymous defer></script>
<script src=https://seeingmachines.betamovement.net/js/highlight.min.93c197e7097c47fc0788b21721b3c308e18e43299f1e45e8ff2697d13cd62908cc5949a053c1fb7242d7b4a60eb07bd106061252f7aa925ef7e91033ea59d9b9.js integrity="sha512-k8GX5wl8R/wHiLIXIbPDCOGOQymfHkXo/yaX0TzWKQjMWUmgU8H7ckLXtKYOsHvRBgYSUveqkl736RAz6lnZuQ==" crossorigin=anonymous defer></script>
<script src=https://seeingmachines.betamovement.net/main.min.162c56a0426544de0d010e66c56e321579655c400c9aae06a6823e7682de379adadf2165bd416fea191e4e7e410fbf1fd2c35a759aa43ff2e3787067669bf81b.js integrity="sha512-FixWoEJlRN4NAQ5mxW4yFXllXEAMmq4GpoI+doLeN5ra3yFlvUFv6hkeTn5BD78f0sNadZqkP/LjeHBnZpv4Gw==" crossorigin=anonymous defer></script>
<script src=https://seeingmachines.betamovement.net/index.min.203346894d44c56c3b03d0375f007f24897adc9fda8be4dcb3c8ccd7311025cad3b3b51b8ca51857ff1c89d4f4e9aba969ea61443d1cfe4bf11fa044adad8312.js integrity="sha512-IDNGiU1ExWw7A9A3XwB/JIl63J/ai+Tcs8jM1zEQJcrTs7UbjKUYV/8cidT06aupaephRD0c/kvxH6BEra2DEg==" crossorigin=anonymous defer></script></body></html>