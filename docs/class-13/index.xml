<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Class 13 on</title><link>https://seeingmachines.betamovement.net/docs/class-13/</link><description>Recent content in Class 13 on</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Wed, 22 Nov 2023 14:33:17 -0500</lastBuildDate><atom:link href="https://seeingmachines.betamovement.net/docs/class-13/index.xml" rel="self" type="application/rss+xml"/><item><title>Sound</title><link>https://seeingmachines.betamovement.net/docs/class-13/sound/</link><pubDate>Wed, 22 Nov 2023 14:33:17 -0500</pubDate><guid>https://seeingmachines.betamovement.net/docs/class-13/sound/</guid><description>Almost all the material we&amp;rsquo;ve covered so far has dealt with computer vision. The following notes deal with another important &amp;ldquo;sense&amp;rdquo;, sound.
openFrameworks might not seem like the obvious choice for manipulating sound. Part of the issue is that development of the sound modules in OF have been stop-and-go since the beginning; especially compared to other tools like Max which place audio front and center, and have a more visual approach to working with sound data and devices.</description></item></channel></rss>