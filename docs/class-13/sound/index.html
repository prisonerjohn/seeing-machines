<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=preload as=font href=https://seeingmachines.betamovement.net/fonts/vendor/jost/jost-v4-latin-regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://seeingmachines.betamovement.net/fonts/vendor/jost/jost-v4-latin-500.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://seeingmachines.betamovement.net/fonts/vendor/jost/jost-v4-latin-700.woff2 type=font/woff2 crossorigin><script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script><link rel=stylesheet href=https://seeingmachines.betamovement.net/main.42fe22dfe022cc0fba3cb6f20f694a40a705e406951e7b127a5e079472bea667f273069c4efd2734ed2815f651a67b23df404c97418ea6c6b1c0b74114bac9c5.css integrity="sha512-Qv4i3+AizA+6PLbyD2lKQKcF5AaVHnsSel4HlHK+pmfycwacTv0nNO0oFfZRpnsj30BMl0GOpsaxwLdBFLrJxQ==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>Sound - Seeing Machines</title><meta name=description content="Almost all the material we&amp;rsquo;ve covered so far has dealt with computer vision. The following notes deal with another important &amp;ldquo;sense&amp;rdquo;, sound.
openFrameworks might not seem like the obvious choice for manipulating sound. Part of the issue is that development of the sound modules in OF have been stop-and-go since the beginning; especially compared to other tools like Max which place audio front and center, and have a more visual approach to working with sound data and devices."><link rel=canonical href=https://seeingmachines.betamovement.net/docs/class-13/sound/><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="Sound"><meta property="og:description" content="Almost all the material we&rsquo;ve covered so far has dealt with computer vision. The following notes deal with another important &ldquo;sense&rdquo;, sound.
openFrameworks might not seem like the obvious choice for manipulating sound. Part of the issue is that development of the sound modules in OF have been stop-and-go since the beginning; especially compared to other tools like Max which place audio front and center, and have a more visual approach to working with sound data and devices."><meta property="og:url" content="https://seeingmachines.betamovement.net/docs/class-13/sound/"><meta property="og:site_name" content="Seeing Machines"><meta property="article:published_time" content="2023-11-22T14:33:17-05:00"><meta property="article:modified_time" content="2023-11-22T14:33:17-05:00"><meta property="og:image" content="https://seeingmachines.betamovement.net/default-image.png"><meta property="og:image:alt" content="Seeing Machines"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content><meta name=twitter:creator content="@prisonerjohn"><meta name=twitter:title content="Sound"><meta name=twitter:description content><meta name=twitter:image content="https://seeingmachines.betamovement.net/default-image.png"><meta name=twitter:image:alt content="Sound"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://seeingmachines.betamovement.net/#/schema/person/1","name":"Seeing Machines","url":"https://seeingmachines.betamovement.net/","sameAs":[],"image":{"@type":"ImageObject","@id":"https://seeingmachines.betamovement.net/#/schema/image/1","url":"https://seeingmachines.betamovement.net/default-image.png","width":1024,"height":768,"caption":"Seeing Machines"}},{"@type":"WebSite","@id":"https://seeingmachines.betamovement.net/#/schema/website/1","url":"https://seeingmachines.betamovement.net/","name":"Seeing Machines","description":"A programming course where weâ€™ll explore various techniques and solutions for tracking and sensing people or objects in space.","publisher":{"@id":"https://seeingmachines.betamovement.net/#/schema/person/1"}},{"@type":"WebPage","@id":"https://seeingmachines.betamovement.net/docs/class-13/sound/","url":"https://seeingmachines.betamovement.net/docs/class-13/sound/","name":"Sound","description":"","isPartOf":{"@id":"https://seeingmachines.betamovement.net/#/schema/website/1"},"about":{"@id":"https://seeingmachines.betamovement.net/#/schema/person/1"},"datePublished":"2023-11-22T14:33:17CET","dateModified":"2023-11-22T14:33:17CET","breadcrumb":{"@id":"https://seeingmachines.betamovement.net/docs/class-13/sound/#/schema/breadcrumb/1"},"primaryImageOfPage":{"@id":"https://seeingmachines.betamovement.net/docs/class-13/sound/#/schema/image/2"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://seeingmachines.betamovement.net/docs/class-13/sound/"]}]},{"@type":"BreadcrumbList","@id":"https://seeingmachines.betamovement.net/docs/class-13/sound/#/schema/breadcrumb/1","name":"Breadcrumbs","itemListElement":[{"@type":"ListItem","position":1,"item":{"@type":"WebPage","@id":"https://seeingmachines.betamovement.net/","url":"https://seeingmachines.betamovement.net/","name":"Home"}},{"@type":"ListItem","position":2,"item":{"@type":"WebPage","@id":"https://seeingmachines.betamovement.net/docs/","url":"https://seeingmachines.betamovement.net/docs/","name":"Docs"}},{"@type":"ListItem","position":3,"item":{"@type":"WebPage","@id":"https://seeingmachines.betamovement.net/docs/class-13/","url":"https://seeingmachines.betamovement.net/docs/class-13/","name":"Class 13"}},{"@type":"ListItem","position":4,"item":{"@id":"https://seeingmachines.betamovement.net/docs/class-13/sound/"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Article","@id":"https://seeingmachines.betamovement.net/#/schema/article/1","headline":"Sound","description":"","isPartOf":{"@id":"https://seeingmachines.betamovement.net/docs/class-13/sound/"},"mainEntityOfPage":{"@id":"https://seeingmachines.betamovement.net/docs/class-13/sound/"},"datePublished":"2023-11-22T14:33:17CET","dateModified":"2023-11-22T14:33:17CET","author":{"@id":"https://seeingmachines.betamovement.net/#/schema/person/2"},"publisher":{"@id":"https://seeingmachines.betamovement.net/#/schema/person/1"},"image":{"@id":"https://seeingmachines.betamovement.net/docs/class-13/sound/#/schema/image/2"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://seeingmachines.betamovement.net/#/schema/person/2","name":"Elie Zananiri","sameAs":["https://twitter.com/prisonerjohn","https://www.linkedin.com/in/prisonerjohn/","https://github.com/prisonerjohn"]}]},{"@context":"https://schema.org","@graph":[{"@type":"ImageObject","@id":"https://seeingmachines.betamovement.net/docs/class-13/sound/#/schema/image/2","url":"https://seeingmachines.betamovement.net/default-image.png","contentUrl":"https://seeingmachines.betamovement.net/default-image.png","caption":"Sound"}]}]}</script><meta name=theme-color content="#fff"><link rel=icon href=https://seeingmachines.betamovement.net/favicon.ico sizes=any><link rel=icon type=image/svg+xml href=https://seeingmachines.betamovement.net/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=https://seeingmachines.betamovement.net/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://seeingmachines.betamovement.net/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://seeingmachines.betamovement.net/favicon-16x16.png><link rel=manifest crossorigin=use-credentials href=https://seeingmachines.betamovement.net/site.webmanifest></head><body class="docs single"><div class=sticky-top><div class=header-bar></div><header class="navbar navbar-expand-lg navbar-light doks-navbar"><nav class="container-xxl flex-wrap flex-lg-nowrap" aria-label="Main navigation"><a class="navbar-brand order-0" href=https://seeingmachines.betamovement.net/ aria-label="Seeing Machines">Seeing Machines</a>
<button class="btn btn-link order-0 ms-auto d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasExample aria-controls=offcanvasExample><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-more-horizontal"><circle cx="12" cy="12" r="1"/><circle cx="19" cy="12" r="1"/><circle cx="5" cy="12" r="1"/></svg></button><div class="offcanvas offcanvas-start d-lg-none" tabindex=-1 id=offcanvasExample aria-labelledby=offcanvasExampleLabel><div class=header-bar></div><div class=offcanvas-header><h5 class=offcanvas-title id=offcanvasExampleLabel>Browse docs</h5><button type=button class=btn-close data-bs-dismiss=offcanvas aria-label=Close></button></div><div class=offcanvas-body><aside class="doks-sidebar mt-n3"><nav id=doks-docs-nav aria-label="Tertiary navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-5f2cae171c6192fa410df4385f7218aa aria-expanded=false>
Prologue</button><div class=collapse id=section-5f2cae171c6192fa410df4385f7218aa><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-0/getting-started/>Getting Started</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e43c4a6cb52ad623673f8e77a5b10104 aria-expanded=false>
Class 1</button><div class=collapse id=section-e43c4a6cb52ad623673f8e77a5b10104><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/foreword/>Foreword</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/intro-to-of/>Intro to OF</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-2ef5a7f02774e1be242988dba4c3056c aria-expanded=false>
Class 2</button><div class=collapse id=section-2ef5a7f02774e1be242988dba4c3056c><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/data-types/>Data Types</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/arrays/>Arrays</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/images-and-video/>Images and Video</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-6a3be28bcd9707b6b8ff8ac55a6b8cb2 aria-expanded=false>
Class 3</button><div class=collapse id=section-6a3be28bcd9707b6b8ff8ac55a6b8cb2><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-3/computer-vision/>Computer Vision</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e01cc216a97c1db953e2304e6aa8998a aria-expanded=false>
Class 4</button><div class=collapse id=section-e01cc216a97c1db953e2304e6aa8998a><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/intro-to-opencv/>Intro to OpenCV</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/object-tracking/>Object Tracking</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-cb8d2462ebd86364c3502e7084b7f391 aria-expanded=false>
Class 5</button><div class=collapse id=section-cb8d2462ebd86364c3502e7084b7f391><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/logging/>Logging</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/depth-sensing/>Depth Sensing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c5400dee9e161c6d7e46af7661005794 aria-expanded=false>
Class 6</button><div class=collapse id=section-c5400dee9e161c6d7e46af7661005794><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/pointers/>Pointers</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/depth-images/>Depth Images</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ff9150b580f893ddadd43394cb6173a3 aria-expanded=false>
Class 7</button><div class=collapse id=section-ff9150b580f893ddadd43394cb6173a3><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/3d-primer/>3D Primer</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/depth-world/>Depth World</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c28d8545333b2785a226d11aa3b3b4ed aria-expanded=false>
Class 8</button><div class=collapse id=section-c28d8545333b2785a226d11aa3b3b4ed><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/networking/>Networking</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/texture-sharing/>Texture Sharing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-0bbdd9311c2cb50588b0a462a5438610 aria-expanded=false>
Class 9</button><div class=collapse id=section-0bbdd9311c2cb50588b0a462a5438610><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-9/draw-bounds/>Draw Bounds</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/>Frame Buffers</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c75af093fd3f2e096e4fe21c7e51e7c7 aria-expanded=false>
Class 10</button><div class=collapse id=section-c75af093fd3f2e096e4fe21c7e51e7c7><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/classes/>Classes</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/mapping/>Mapping</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ddbaeabfbe390c84589d5d1c423b9284 aria-expanded=false>
Class 11</button><div class=collapse id=section-ddbaeabfbe390c84589d5d1c423b9284><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-11/machine-learning/>Machine Learning</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-960119d951e6b24e70eaf82d456d181f aria-expanded=false>
Class 12</button><div class=collapse id=section-960119d951e6b24e70eaf82d456d181f><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-12/mobile-development/>Mobile Development</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-37c0442fba31d7a7923dce6846a60711 aria-expanded=true>
Class 13</button><div class="collapse show" id=section-37c0442fba31d7a7923dce6846a60711><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded active" href=https://seeingmachines.betamovement.net/docs/class-13/sound/>Sound</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-56c4b82e7a8861de86a5ebe5eaa62225 aria-expanded=false>
Assignments</button><div class=collapse id=section-56c4b82e7a8861de86a5ebe5eaa62225><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-1/>Assignment 1</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-2/>Assignment 2</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-3/>Assignment 3</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-4/>Assignment 4</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/final-project/>Final Project</a></li></ul></div></li></ul></nav></aside></div></div><button class="btn btn-menu order-2 d-block d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasDoks aria-controls=offcanvasDoks aria-label="Open main menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><div class="offcanvas offcanvas-end border-0 py-lg-1" tabindex=-1 id=offcanvasDoks data-bs-backdrop=true aria-labelledby=offcanvasDoksLabel><div class="header-bar d-lg-none"></div><div class="offcanvas-header d-lg-none"><h2 class="h5 offcanvas-title ps-2" id=offcanvasDoksLabel><a class=text-dark href=https://seeingmachines.betamovement.net/>Seeing Machines</a></h2><button type=button class="btn-close text-reset me-2" data-bs-dismiss=offcanvas aria-label="Close main menu"></button></div><div class="offcanvas-body p-4 p-lg-0"><ul class="nav flex-column flex-lg-row align-items-lg-center mt-2 mt-lg-0 ms-lg-2 me-lg-auto"><li class=nav-item><a class="nav-link ps-0 py-1 active" href=https://seeingmachines.betamovement.net/docs>Docs</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=https://seeingmachines.betamovement.net/docs/assignments>Assignments</a></li></ul><hr class="text-black-50 my-4 d-lg-none"><form class="doks-search position-relative flex-grow-1 ms-lg-auto me-lg-2"><input id=search class="form-control is-search" type=search placeholder="Search docs..." aria-label="Search docs..." autocomplete=off><div id=suggestions class="shadow bg-white rounded d-none"></div></form><hr class="text-black-50 my-4 d-lg-none"><ul class="nav flex-column flex-lg-row"><li class=nav-item><a class="nav-link social-link" href=https://github.com/prisonerjohn/seeing-machines><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg><small class="ms-2 d-lg-none">GitHub</small></a></li><li class=nav-item><a class="nav-link social-link" href=https://twitter.com/prisonerjohn><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-twitter"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg><small class="ms-2 d-lg-none">Twitter</small></a></li></ul><hr class="text-black-50 my-4 d-lg-none"><button id=mode class="btn btn-link" type=button aria-label="Toggle user interface mode">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></div></div></nav></header></div><div class=container-xxl><aside class=doks-sidebar><nav id=doks-docs-nav class="collapse d-lg-none" aria-label="Tertiary navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-5f2cae171c6192fa410df4385f7218aa aria-expanded=false>
Prologue</button><div class=collapse id=section-5f2cae171c6192fa410df4385f7218aa><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-0/getting-started/>Getting Started</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e43c4a6cb52ad623673f8e77a5b10104 aria-expanded=false>
Class 1</button><div class=collapse id=section-e43c4a6cb52ad623673f8e77a5b10104><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/foreword/>Foreword</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/intro-to-of/>Intro to OF</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-2ef5a7f02774e1be242988dba4c3056c aria-expanded=false>
Class 2</button><div class=collapse id=section-2ef5a7f02774e1be242988dba4c3056c><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/data-types/>Data Types</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/arrays/>Arrays</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/images-and-video/>Images and Video</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-6a3be28bcd9707b6b8ff8ac55a6b8cb2 aria-expanded=false>
Class 3</button><div class=collapse id=section-6a3be28bcd9707b6b8ff8ac55a6b8cb2><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-3/computer-vision/>Computer Vision</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e01cc216a97c1db953e2304e6aa8998a aria-expanded=false>
Class 4</button><div class=collapse id=section-e01cc216a97c1db953e2304e6aa8998a><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/intro-to-opencv/>Intro to OpenCV</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/object-tracking/>Object Tracking</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-cb8d2462ebd86364c3502e7084b7f391 aria-expanded=false>
Class 5</button><div class=collapse id=section-cb8d2462ebd86364c3502e7084b7f391><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/logging/>Logging</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/depth-sensing/>Depth Sensing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c5400dee9e161c6d7e46af7661005794 aria-expanded=false>
Class 6</button><div class=collapse id=section-c5400dee9e161c6d7e46af7661005794><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/pointers/>Pointers</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/depth-images/>Depth Images</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ff9150b580f893ddadd43394cb6173a3 aria-expanded=false>
Class 7</button><div class=collapse id=section-ff9150b580f893ddadd43394cb6173a3><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/3d-primer/>3D Primer</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/depth-world/>Depth World</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c28d8545333b2785a226d11aa3b3b4ed aria-expanded=false>
Class 8</button><div class=collapse id=section-c28d8545333b2785a226d11aa3b3b4ed><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/networking/>Networking</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/texture-sharing/>Texture Sharing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-0bbdd9311c2cb50588b0a462a5438610 aria-expanded=false>
Class 9</button><div class=collapse id=section-0bbdd9311c2cb50588b0a462a5438610><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-9/draw-bounds/>Draw Bounds</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/>Frame Buffers</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c75af093fd3f2e096e4fe21c7e51e7c7 aria-expanded=false>
Class 10</button><div class=collapse id=section-c75af093fd3f2e096e4fe21c7e51e7c7><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/classes/>Classes</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/mapping/>Mapping</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ddbaeabfbe390c84589d5d1c423b9284 aria-expanded=false>
Class 11</button><div class=collapse id=section-ddbaeabfbe390c84589d5d1c423b9284><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-11/machine-learning/>Machine Learning</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-960119d951e6b24e70eaf82d456d181f aria-expanded=false>
Class 12</button><div class=collapse id=section-960119d951e6b24e70eaf82d456d181f><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-12/mobile-development/>Mobile Development</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-37c0442fba31d7a7923dce6846a60711 aria-expanded=true>
Class 13</button><div class="collapse show" id=section-37c0442fba31d7a7923dce6846a60711><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded active" href=https://seeingmachines.betamovement.net/docs/class-13/sound/>Sound</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-56c4b82e7a8861de86a5ebe5eaa62225 aria-expanded=false>
Assignments</button><div class=collapse id=section-56c4b82e7a8861de86a5ebe5eaa62225><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-1/>Assignment 1</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-2/>Assignment 2</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-3/>Assignment 3</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-4/>Assignment 4</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/final-project/>Final Project</a></li></ul></div></li></ul></nav></aside></div><div class="wrap container-xxl" role=document><div class=content><div class="row flex-xl-nowrap"><div class="col-lg-5 col-xl-4 docs-sidebar d-none d-lg-block"><nav class=docs-links aria-label="Main navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-5f2cae171c6192fa410df4385f7218aa aria-expanded=false>
Prologue</button><div class=collapse id=section-5f2cae171c6192fa410df4385f7218aa><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-0/getting-started/>Getting Started</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e43c4a6cb52ad623673f8e77a5b10104 aria-expanded=false>
Class 1</button><div class=collapse id=section-e43c4a6cb52ad623673f8e77a5b10104><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/foreword/>Foreword</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/intro-to-of/>Intro to OF</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-2ef5a7f02774e1be242988dba4c3056c aria-expanded=false>
Class 2</button><div class=collapse id=section-2ef5a7f02774e1be242988dba4c3056c><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/data-types/>Data Types</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/arrays/>Arrays</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/images-and-video/>Images and Video</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-6a3be28bcd9707b6b8ff8ac55a6b8cb2 aria-expanded=false>
Class 3</button><div class=collapse id=section-6a3be28bcd9707b6b8ff8ac55a6b8cb2><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-3/computer-vision/>Computer Vision</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e01cc216a97c1db953e2304e6aa8998a aria-expanded=false>
Class 4</button><div class=collapse id=section-e01cc216a97c1db953e2304e6aa8998a><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/intro-to-opencv/>Intro to OpenCV</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/object-tracking/>Object Tracking</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-cb8d2462ebd86364c3502e7084b7f391 aria-expanded=false>
Class 5</button><div class=collapse id=section-cb8d2462ebd86364c3502e7084b7f391><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/logging/>Logging</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/depth-sensing/>Depth Sensing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c5400dee9e161c6d7e46af7661005794 aria-expanded=false>
Class 6</button><div class=collapse id=section-c5400dee9e161c6d7e46af7661005794><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/pointers/>Pointers</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/depth-images/>Depth Images</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ff9150b580f893ddadd43394cb6173a3 aria-expanded=false>
Class 7</button><div class=collapse id=section-ff9150b580f893ddadd43394cb6173a3><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/3d-primer/>3D Primer</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/depth-world/>Depth World</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c28d8545333b2785a226d11aa3b3b4ed aria-expanded=false>
Class 8</button><div class=collapse id=section-c28d8545333b2785a226d11aa3b3b4ed><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/networking/>Networking</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/texture-sharing/>Texture Sharing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-0bbdd9311c2cb50588b0a462a5438610 aria-expanded=false>
Class 9</button><div class=collapse id=section-0bbdd9311c2cb50588b0a462a5438610><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-9/draw-bounds/>Draw Bounds</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/>Frame Buffers</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c75af093fd3f2e096e4fe21c7e51e7c7 aria-expanded=false>
Class 10</button><div class=collapse id=section-c75af093fd3f2e096e4fe21c7e51e7c7><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/classes/>Classes</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/mapping/>Mapping</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ddbaeabfbe390c84589d5d1c423b9284 aria-expanded=false>
Class 11</button><div class=collapse id=section-ddbaeabfbe390c84589d5d1c423b9284><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-11/machine-learning/>Machine Learning</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-960119d951e6b24e70eaf82d456d181f aria-expanded=false>
Class 12</button><div class=collapse id=section-960119d951e6b24e70eaf82d456d181f><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-12/mobile-development/>Mobile Development</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-37c0442fba31d7a7923dce6846a60711 aria-expanded=true>
Class 13</button><div class="collapse show" id=section-37c0442fba31d7a7923dce6846a60711><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded active" href=https://seeingmachines.betamovement.net/docs/class-13/sound/>Sound</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-56c4b82e7a8861de86a5ebe5eaa62225 aria-expanded=false>
Assignments</button><div class=collapse id=section-56c4b82e7a8861de86a5ebe5eaa62225><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-1/>Assignment 1</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-2/>Assignment 2</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-3/>Assignment 3</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-4/>Assignment 4</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/final-project/>Final Project</a></li></ul></div></li></ul></nav></div><nav class="docs-toc d-none d-xl-block col-xl-3" aria-label="Secondary navigation"><div class=d-xl-none><button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#onThisPage aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>On this page</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button><div class=collapse id=onThisPage><div class="card card-body mt-3 py-1"><div class=page-links><nav id=TableOfContents><ul><li><a href=#sound-stream>Sound Stream</a></li><li><a href=#sound-buffer>Sound Buffer</a></li><li><a href=#sound-input>Sound Input</a><ul><li><a href=#rms>RMS</a></li><li><a href=#onset-detection>Onset Detection</a></li><li><a href=#fft>FFT</a></li></ul></li><li><a href=#sound-player>Sound Player</a></li><li><a href=#sound-synthesis>Sound Synthesis</a><ul><li><a href=#signal-generator>Signal Generator</a></li><li><a href=#noise-generator>Noise Generator</a></li></ul></li><li><a href=#midi>MIDI</a></li><li><a href=#sound-addons>Sound Addons</a></li></ul></nav></div></div></div></div><div class="page-links d-none d-xl-block"><h3>On this page</h3><nav id=TableOfContents><ul><li><a href=#sound-stream>Sound Stream</a></li><li><a href=#sound-buffer>Sound Buffer</a></li><li><a href=#sound-input>Sound Input</a><ul><li><a href=#rms>RMS</a></li><li><a href=#onset-detection>Onset Detection</a></li><li><a href=#fft>FFT</a></li></ul></li><li><a href=#sound-player>Sound Player</a></li><li><a href=#sound-synthesis>Sound Synthesis</a><ul><li><a href=#signal-generator>Signal Generator</a></li><li><a href=#noise-generator>Noise Generator</a></li></ul></li><li><a href=#midi>MIDI</a></li><li><a href=#sound-addons>Sound Addons</a></li></ul></nav></div></nav><main class="docs-content col-lg-11 col-xl-9"><h1>Sound</h1><p class=lead></p><nav class=d-xl-none aria-label="Quaternary navigation"><div class=d-xl-none><button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#onThisPage aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>On this page</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button><div class=collapse id=onThisPage><div class="card card-body mt-3 py-1"><div class=page-links><nav id=TableOfContents><ul><li><a href=#sound-stream>Sound Stream</a></li><li><a href=#sound-buffer>Sound Buffer</a></li><li><a href=#sound-input>Sound Input</a><ul><li><a href=#rms>RMS</a></li><li><a href=#onset-detection>Onset Detection</a></li><li><a href=#fft>FFT</a></li></ul></li><li><a href=#sound-player>Sound Player</a></li><li><a href=#sound-synthesis>Sound Synthesis</a><ul><li><a href=#signal-generator>Signal Generator</a></li><li><a href=#noise-generator>Noise Generator</a></li></ul></li><li><a href=#midi>MIDI</a></li><li><a href=#sound-addons>Sound Addons</a></li></ul></nav></div></div></div></div><div class="page-links d-none d-xl-block"><h3>On this page</h3><nav id=TableOfContents><ul><li><a href=#sound-stream>Sound Stream</a></li><li><a href=#sound-buffer>Sound Buffer</a></li><li><a href=#sound-input>Sound Input</a><ul><li><a href=#rms>RMS</a></li><li><a href=#onset-detection>Onset Detection</a></li><li><a href=#fft>FFT</a></li></ul></li><li><a href=#sound-player>Sound Player</a></li><li><a href=#sound-synthesis>Sound Synthesis</a><ul><li><a href=#signal-generator>Signal Generator</a></li><li><a href=#noise-generator>Noise Generator</a></li></ul></li><li><a href=#midi>MIDI</a></li><li><a href=#sound-addons>Sound Addons</a></li></ul></nav></div></nav><p>Almost all the material we&rsquo;ve covered so far has dealt with computer vision. The following notes deal with another important &ldquo;sense&rdquo;, sound.</p><p>openFrameworks might not seem like the obvious choice for manipulating sound. Part of the issue is that development of the sound modules in OF have been stop-and-go since the beginning; especially compared to other tools like <a href=https://cycling74.com/>Max</a> which place audio front and center, and have a more visual approach to working with sound data and devices. That being said, sound analysis and manipulation is still quite developed in OF and involves some interesting concepts that should be explored.</p><h2 id=sound-stream>Sound Stream <a href=#sound-stream class=anchor aria-hidden=true>#</a></h2><p>The primary object for working with sound is <a href=https://openframeworks.cc/documentation/sound/ofSoundStream/><code>ofSoundStream</code></a>. An <code>ofSoundStream</code> controls access to the computer&rsquo;s audio input and output devices, and allows the manipulation of the sound data in real-time.</p><p>Typical apps will only use a single sound stream, and openFrameworks gives you easy access to a default <code>ofSoundStream</code> using <code>ofSoundStreamXXX()</code> global functions like <a href=https://openframeworks.cc/documentation/sound/ofSoundStream/#show_ofSoundStreamSetup><code>ofSoundStreamSetup()</code></a> or <a href=https://openframeworks.cc/documentation/sound/ofSoundStream/#show_ofSoundStreamClose><code>ofSoundStreamClose()</code></a>. However, we like to be explicit in this class so our examples will always create our own <code>ofSoundStream</code> object :)</p><p>An <code>ofSoundStream</code> is set up with an <a href=https://openframeworks.cc/documentation/sound/ofSoundStreamSettings/><code>ofSoundStreamSettings</code></a>. This sets the sound hardware to use, the buffer properties like number of channels and sample rate, the callbacks for reading and writing sound data, etc.</p><pre><code class=language-cpp>ofSoundStreamSettings settings;
settings.sampleRate = 44100;
settings.bufferSize = 256;
settings.numOutputChannels = 2;
settings.numInputChannels = 0;

soundStream.setup(settings);
</code></pre><p>We can list the installed sound devices on our system using <a href=https://openframeworks.cc/documentation/sound/ofSoundStream/#show_printDeviceList><code>ofSoundStream::printDeviceList()</code></a>. This will print all the information out to the console, including the interface used and the number of available input and output channels per device.</p><p>The output will look something like:</p><pre><code class=language-python>[notice ] ofBaseSoundStream::printDeviceList: Api: MS WASAPI
[notice ] ofBaseSoundStream::printDeviceList: [MS WASAPI: 0] DELL U2713HM (NVIDIA High Definition Audio) [in:0 out:2]
[MS WASAPI: 1] Speakers (Realtek High Definition Audio) [in:0 out:2] (default out)
[MS WASAPI: 2] Realtek Digital Output(Optical) (Realtek High Definition Audio) [in:0 out:2]
[MS WASAPI: 3] Realtek Digital Output (Realtek High Definition Audio) [in:0 out:2]
[MS WASAPI: 4] Microphone (HD Pro Webcam C920) [in:2 out:0]
[MS WASAPI: 5] Microphone Array (Xbox NUI Sensor) [in:4 out:0] (default in)
</code></pre><p>It is a good idea to close the sound stream with <a href=https://openframeworks.cc/documentation/sound/ofSoundStream/#show_close><code>ofSoundStream::close()</code></a> when we are finished with it as that will prevent our app from receiving unwanted sound bytes. We will do this in <code>ofApp::exit()</code> in the following examples.</p><h2 id=sound-buffer>Sound Buffer <a href=#sound-buffer class=anchor aria-hidden=true>#</a></h2><p>Sound data is packed into an <a href=https://openframeworks.cc/documentation/sound/ofSoundBuffer/><code>ofSoundBuffer</code></a>.</p><p>As the name implies, <code>ofSoundBuffer</code> includes the sound buffer data.</p><ul><li>Buffer values are <code>float</code>, with range from <code>-1</code> to <code>1</code>. Think of this as a waveform, with <code>0</code> at the origin.</li><li>This can be used like an array, using the <a href=https://openframeworks.cc/documentation/sound/ofSoundBuffer/#show_operator%5B%5D><code>[]</code></a> operator and an index to access each element.</li><li>Just like an <code>ofPixels</code> array, the sound data is <em>interleaved</em> in the buffer. This means that if we have 2 channels of audio, it will be packed as <code>LRLRLRLRLR...</code>.</li><li><a href=https://openframeworks.cc/documentation/sound/ofSoundBuffer/#show_size><code>size()</code></a> returns the total buffer size.</li><li><a href=https://openframeworks.cc/documentation/sound/ofSoundBuffer/#show_getNumChannels><code>getNumChannels()</code></a> returns the number of channels.</li><li><a href=https://openframeworks.cc/documentation/sound/ofSoundBuffer/#show_getNumFrames><code>getNumFrames()</code></a> returns the number of frames, which is the buffer size per channel. This is essentially the size divided by the number of channels.</li></ul><p><code>ofSoundBuffer</code> also includes a few other getters and setters:</p><ul><li>Some to interface with the audio hardware, like <a href=https://openframeworks.cc/documentation/sound/ofSoundBuffer/#show_getDeviceID><code>getDeviceID()</code></a> and <a href=https://openframeworks.cc/documentation/sound/ofSoundBuffer/#show_setSampleRate><code>setSampleRate()</code></a>.</li><li>Some to manipulate the signal, like <a href=https://openframeworks.cc/documentation/sound/ofSoundBuffer/#show_fillWithNoise><code>fillWithNoise()</code></a> and <a href=https://openframeworks.cc/documentation/sound/ofSoundBuffer/#show_resample><code>resample()</code></a>.</li></ul><h2 id=sound-input>Sound Input <a href=#sound-input class=anchor aria-hidden=true>#</a></h2><p>To receive audio in OF, we need to:</p><ul><li>Set the input channels of our <code>ofSoundStream</code> to a value greater than <code>0</code>.</li><li>Set an audio listener to the <code>ofSoundStream</code> using <a href=https://openframeworks.cc/documentation/sound/ofSoundStreamSettings/#show_setInListener><code>ofSoundStreamSettings::setInListener()</code></a>. This can be any class that extends from <code>ofBaseSoundInput</code>, which includes our <code>ofApp</code>.</li><li>Implement the <a href=https://openframeworks.cc/documentation/types/ofBaseSoundInput/#show_audioIn><code>audioIn()</code></a> function in our listener class.</li></ul><p>If the app does not receive any audio and prints out messages like <code>RtAudio: no compiled support for specified API argument!</code>, you may not be using the right sound device.</p><ul><li>Review the printed output from the <code>ofSoundStream::printDeviceList()</code> call and select an appropriate device.</li><li>Set the corresponding API with <code>ofSoundStreamSettings::setApi()</code>.</li><li>Set the corresponding device ID with <code>ofSoundStreamSettings::setInDevice()</code> or directly in the sound stream with <code>ofSoundStream::setDeviceID()</code>.</li></ul><pre><code class=language-cpp>//ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void exit();
  void update();
  void draw();

  void audioIn(ofSoundBuffer&amp; input);

  ofSoundStream soundStream;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>//ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  // Print audio device list to the console.
  soundStream.printDeviceList();
  //soundStream.setDeviceID(1);

  // Setup sound stream.
  ofSoundStreamSettings settings;
  //settings.setApi(ofSoundDevice::Api::MS_DS);
  settings.setInListener(this);
  //settings.sampleRate = 44100;
  settings.numOutputChannels = 0;
  settings.numInputChannels = 2;
  soundStream.setup(settings);

  guiPanel.setup(&quot;Audio In&quot;, &quot;settings.json&quot;);
}

void ofApp::exit()
{
  soundStream.close();
}

void ofApp::update() 
{

}

void ofApp::draw() 
{
  guiPanel.draw();
}

void ofApp::audioIn(ofSoundBuffer&amp; input)
{

}
</code></pre><h3 id=rms>RMS <a href=#rms class=anchor aria-hidden=true>#</a></h3><p>To calculate audio levels, we need to consider all samples in the received buffer. We could try adding and averaging all values in our buffer, but since the values oscillate between <code>-1</code> and <code>1</code>, we would probably always end up with something near <code>0</code> (since the negatives will cancel out the positives). A good way to approximate the audio level is to calculate the root mean square (RMS), which ensures that the samples collected are always positive.</p><pre><code class=language-cpp>//ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void exit();
  void update();
  void draw();

  void audioIn(ofSoundBuffer&amp; input);

  ofSoundStream soundStream;

  ofParameter&lt;float&gt; smoothPct;
  ofParameter&lt;float&gt; volPeak;

  ofParameter&lt;float&gt; currVol;
  ofParameter&lt;float&gt; smoothVol;
  ofParameter&lt;float&gt; scaledVol;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>//ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  // Print audio device list to the console.
  soundStream.printDeviceList();
  //soundStream.setDeviceID(3);

  // Setup sound stream.
  ofSoundStreamSettings settings;
  //settings.setApi(ofSoundDevice::Api::MS_DS);
  settings.setInListener(this);
  //settings.sampleRate = 44100;
  settings.numOutputChannels = 0;
  settings.numInputChannels = 2;
  soundStream.setup(settings);

  // Use ofParameter for volume values so that we can print them in the GUI.
  currVol.set(&quot;Curr Vol&quot;, 0.0, 0.0, 1.0);
  smoothVol.set(&quot;Smooth Vol&quot;, 0.0, 0.0, 1.0);
  scaledVol.set(&quot;Scaled Vol&quot;, 0.0, 0.0, 1.0);

  smoothPct.set(&quot;Smooth Pct&quot;, 0.05, 0.0, 1.0);
  volPeak.set(&quot;Vol Peak&quot;, 0.001, 0.0, 1.0);

  guiPanel.setup(&quot;Audio In&quot;, &quot;settings.json&quot;);
  guiPanel.add(currVol);
  guiPanel.add(smoothVol);
  guiPanel.add(scaledVol);
  guiPanel.add(smoothPct);
  guiPanel.add(volPeak);
}

void ofApp::exit()
{
  soundStream.close();
}

void ofApp::update() 
{
  // Scale the volume up to a 0-1 range.
  volPeak = max(volPeak, smoothVol);
  scaledVol = ofMap(smoothVol, 0.0, volPeak, 0.0, 1.0, true);
}

void ofApp::draw() 
{
  float volWidth = ofMap(scaledVol, 0.0, 1.0, 0.0, ofGetWidth());
  ofSetColor(200, 0, 0);
  ofFill();
  ofDrawRectangle(0, ofGetHeight() - 120, volWidth, 120);
  ofSetColor(0);
  ofNoFill();
  ofDrawRectangle(0, ofGetHeight() - 120, ofGetWidth(), 120);

  guiPanel.draw();
}

void ofApp::audioIn(ofSoundBuffer&amp; input)
{
  // Calculate the volume using RMS.
  currVol = 0.0;
  int numCounted = 0;
  for (int i = 0; i &lt; input.getNumFrames(); i++)
  {
    // Samples should be between -1 and 1, but sometimes go a bit haywire 
    // when there's no data, so let's clamp the values to avoid outliers.
    float leftSample = ofClamp(input[i * 2 + 0], -1, 1) * 0.5;
    float rightSample = ofClamp(input[i * 2 + 1], -1, 1) * 0.5;

    currVol += leftSample * leftSample;
    currVol += rightSample * rightSample;
    
    numCounted += 2;
  }

  currVol /= (float)numCounted;
  currVol = sqrt(currVol);

  smoothVol = ofLerp(smoothVol, currVol, smoothPct);
}
</code></pre><p>In the above example, note that:</p><ul><li>The RMS value is very volatile, so we smooth it out using <code>ofLerp()</code>.</li><li>The RMS value does not necessarily go up to <code>1.0</code> at it&rsquo;s peak, so we scale it up using <code>ofMap()</code> and its peak recorded value.</li><li>Buffer samples sometimes go out of range. I&rsquo;m not sure why but I think it occurs when no data is present, and only on specific hardware. This needs to be cleaned up before making any calculations, so we adjust outlier values using <code>ofClamp()</code>.</li></ul><p>If we draw a graph of what our raw samples look like, we can indeed see that the tail end values seem to shoot up.</p><pre><code class=language-cpp>//ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void exit();
  void update();
  void draw();

  void audioIn(ofSoundBuffer&amp; input);

  ofSoundStream soundStream;

  std::vector&lt;float&gt; leftSamples;
  std::vector&lt;float&gt; rightSamples;

  ofParameter&lt;float&gt; smoothPct;
  ofParameter&lt;float&gt; volPeak;

  ofParameter&lt;float&gt; currVol;
  ofParameter&lt;float&gt; smoothVol;
  ofParameter&lt;float&gt; scaledVol;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>//ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  ofBackground(0);

  // Print audio device list to the console.
  soundStream.printDeviceList();
  //soundStream.setDeviceID(3);

  // Setup sound stream.
  ofSoundStreamSettings settings;
  //settings.setApi(ofSoundDevice::Api::MS_DS);
  settings.setInListener(this);
  //settings.sampleRate = 44100;
  settings.bufferSize = 512;
  settings.numOutputChannels = 0;
  settings.numInputChannels = 2;
  soundStream.setup(settings);

  // Initialize sample history.
  leftSamples.assign(settings.bufferSize, 0.0);
  rightSamples.assign(settings.bufferSize, 0.0);

  // Use ofParameter for volume values so that we can print them in the GUI.
  currVol.set(&quot;Curr Vol&quot;, 0.0, 0.0, 1.0);
  smoothVol.set(&quot;Smooth Vol&quot;, 0.0, 0.0, 1.0);
  scaledVol.set(&quot;Scaled Vol&quot;, 0.0, 0.0, 1.0);

  smoothPct.set(&quot;Smooth Pct&quot;, 0.05, 0.0, 1.0);
  volPeak.set(&quot;Vol Peak&quot;, 0.001, 0.0, 1.0);

  guiPanel.setup(&quot;Audio In&quot;, &quot;settings.json&quot;);
  guiPanel.add(currVol);
  guiPanel.add(smoothVol);
  guiPanel.add(scaledVol);
  guiPanel.add(smoothPct);
  guiPanel.add(volPeak);
}

void ofApp::exit()
{
  soundStream.close();
}

void ofApp::update() 
{
  // Scale the volume up to a 0-1 range.
  volPeak = max(volPeak, smoothVol);
  scaledVol = ofMap(smoothVol, 0.0, volPeak, 0.0, 1.0, true);
}

void ofApp::draw() 
{
  ofSetLineWidth(2.0);

  // Draw the left channel history.
  ofSetColor(200, 0, 0);
  ofBeginShape();
  for (int i = 0; i &lt; leftSamples.size(); i++) 
  {
    float x = ofMap(i, 0, leftSamples.size(), 0, ofGetWidth());
    float y = ofMap(leftSamples[i], -1.0, 1.0, 0, 200);
    ofVertex(x, y);
  }
  ofEndShape(false);
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, 0, ofGetWidth(), 200);

  // Draw the right channel history.
  ofSetColor(200, 0, 0);
  ofBeginShape();
  for (int i = 0; i &lt; rightSamples.size(); i++)
  {
    float x = ofMap(i, 0, rightSamples.size(), 0, ofGetWidth());
    float y = ofMap(rightSamples[i], -1.0, 1.0, 200, 400);
    ofVertex(x, y);
  }
  ofEndShape(false);
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, 200, ofGetWidth(), 200);

  // Draw the volume level.
  float volWidth = ofMap(scaledVol, 0.0, 1.0, 0.0, ofGetWidth());
  ofSetColor(200, 0, 0);
  ofFill();
  ofDrawRectangle(0, ofGetHeight() - 120, volWidth, 120);
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, ofGetHeight() - 120, ofGetWidth(), 120);

  guiPanel.draw();
}

void ofApp::audioIn(ofSoundBuffer&amp; input)
{
  // Calculate the volume using RMS.
  currVol = 0.0;
  int numCounted = 0;
  for (int i = 0; i &lt; input.getNumFrames(); i++)
  {
    // Samples should be between -1 and 1, but sometimes go a bit haywire 
    // when there's no data, so let's clamp the values to avoid outliers.
    leftSamples[i] = ofClamp(input[i * 2 + 0], -1, 1) * 0.5;
    rightSamples[i] = ofClamp(input[i * 2 + 1], -1, 1) * 0.5;

    currVol += leftSamples[i] * leftSamples[i];
    currVol += rightSamples[i] * rightSamples[i];
    
    numCounted += 2;
  }

  currVol /= (float)numCounted;
  currVol = sqrt(currVol);

  smoothVol = ofLerp(smoothVol, currVol, smoothPct);
}
</code></pre><figure style='display:block;margin:1em auto;width:600px'><a href=sound-graph.png><img style='display:block;margin:0 auto' src=sound-graph.png alt="Sound Graph"></a></figure><h3 id=onset-detection>Onset Detection <a href=#onset-detection class=anchor aria-hidden=true>#</a></h3><p>We can use the RMS for onset or beat detection. We can set a threshold value and every time the RMS goes above it, a new beat is recorded. We can then use this to have an action happen to the tempo of the audio.</p><pre><code class=language-cpp>//ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void exit();
  void update();
  void draw();

  void audioIn(ofSoundBuffer&amp; input);

  ofSoundStream soundStream;

  std::vector&lt;float&gt; leftSamples;
  std::vector&lt;float&gt; rightSamples;

  ofParameter&lt;float&gt; smoothPct;
  ofParameter&lt;float&gt; volPeak;

  ofParameter&lt;float&gt; currVol;
  ofParameter&lt;float&gt; smoothVol;
  ofParameter&lt;float&gt; scaledVol;

  ofParameter&lt;float&gt; onsetThreshold;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>//ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  ofBackground(0);

  // Print audio device list to the console.
  soundStream.printDeviceList();
  //soundStream.setDeviceID(3);

  // Setup sound stream.
  ofSoundStreamSettings settings;
  //settings.setApi(ofSoundDevice::Api::MS_DS);
  settings.setInListener(this);
  //settings.sampleRate = 44100;
  settings.bufferSize = 512;
  settings.numOutputChannels = 0;
  settings.numInputChannels = 2;
  soundStream.setup(settings);

  // Initialize sample history.
  leftSamples.assign(settings.bufferSize, 0.0);
  rightSamples.assign(settings.bufferSize, 0.0);

  // Use ofParameter for volume values so that we can print them in the GUI.
  currVol.set(&quot;Curr Vol&quot;, 0.0, 0.0, 1.0);
  smoothVol.set(&quot;Smooth Vol&quot;, 0.0, 0.0, 1.0);
  scaledVol.set(&quot;Scaled Vol&quot;, 0.0, 0.0, 1.0);

  smoothPct.set(&quot;Smooth Pct&quot;, 0.05, 0.0, 1.0);
  volPeak.set(&quot;Vol Peak&quot;, 0.001, 0.0, 1.0);

  onsetThreshold.set(&quot;Onset Thresh&quot;, 0.5, 0.0, 1.0);

  guiPanel.setup(&quot;Audio In&quot;, &quot;settings.json&quot;);
  guiPanel.add(currVol);
  guiPanel.add(smoothVol);
  guiPanel.add(scaledVol);
  guiPanel.add(smoothPct);
  guiPanel.add(volPeak);
  guiPanel.add(onsetThreshold);
}

void ofApp::exit()
{
  soundStream.close();
}

void ofApp::update() 
{
  // Scale the volume up to a 0-1 range.
  volPeak = max(volPeak, smoothVol);
  scaledVol = ofMap(smoothVol, 0.0, volPeak, 0.0, 1.0, true);
}

void ofApp::draw() 
{
  ofSetLineWidth(2.0);

  // Draw the left channel history.
  ofSetColor(200, 0, 0);
  ofBeginShape();
  for (int i = 0; i &lt; leftSamples.size(); i++) 
  {
    float x = ofMap(i, 0, leftSamples.size(), 0, ofGetWidth());
    float y = ofMap(leftSamples[i], -1.0, 1.0, 0, 200);
    ofVertex(x, y);
  }
  ofEndShape(false);
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, 0, ofGetWidth(), 200);

  // Draw the right channel history.
  ofSetColor(200, 0, 0);
  ofBeginShape();
  for (int i = 0; i &lt; rightSamples.size(); i++)
  {
    float x = ofMap(i, 0, rightSamples.size(), 0, ofGetWidth());
    float y = ofMap(rightSamples[i], -1.0, 1.0, 200, 400);
    ofVertex(x, y);
  }
  ofEndShape(false);
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, 200, ofGetWidth(), 200);

  // Draw the volume level.
  float volWidth = ofMap(scaledVol, 0.0, 1.0, 0.0, ofGetWidth());
  ofFill();
  if (scaledVol &lt; onsetThreshold)
  {
    ofSetColor(200, 0, 0);
  }
  else
  {
    ofSetColor(0, 200, 0);
  }
  ofDrawRectangle(0, ofGetHeight() - 120, volWidth, 120);
  // Draw the threshold level.
  ofSetColor(225);
  float threshPos = ofMap(onsetThreshold, 0.0, 1.0, 0.0, ofGetWidth());
  ofDrawRectangle(threshPos, ofGetHeight() - 120, 2, 120);
  // Draw a border around the box.
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, ofGetHeight() - 120, ofGetWidth(), 120);

  guiPanel.draw();
}

void ofApp::audioIn(ofSoundBuffer&amp; input)
{
  // Calculate the volume using RMS.
  currVol = 0.0;
  int numCounted = 0;
  for (int i = 0; i &lt; input.getNumFrames(); i++)
  {
    // Samples should be between -1 and 1, but sometimes go a bit haywire 
    // when there's no data, so let's clamp the values to avoid outliers.
    leftSamples[i] = ofClamp(input[i * 2 + 0], -1, 1) * 0.5;
    rightSamples[i] = ofClamp(input[i * 2 + 1], -1, 1) * 0.5;

    currVol += leftSamples[i] * leftSamples[i];
    currVol += rightSamples[i] * rightSamples[i];
    
    numCounted += 2;
  }

  currVol /= (float)numCounted;
  currVol = sqrt(currVol);

  smoothVol = ofLerp(smoothVol, currVol, smoothPct);
}
</code></pre><h3 id=fft>FFT <a href=#fft class=anchor aria-hidden=true>#</a></h3><p>Onset detection works fine when you have fairly isolated audio, like footsteps or a bass drum beat, but degenerates fairly quickly when the sound source becomes more complex and involves multiple frequencies.</p><p>The Fast Fourier Transform (FFT) is an algorithm used to take in a sound sample and compute the levels for an array of frequencies. This essentially splits up the audio into different bands that can be analyzed separately.</p><p>FFT does not work out of the box with OF sound input, so we will need to use the <a href=https://github.com/kylemcdonald/ofxFft>ofxFft</a> addon. This addon includes a few examples to get going as well as two different FFT implementations, but we&rsquo;ll just use the default for this example.</p><pre><code class=language-cpp>//ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxFft.h&quot;
#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void exit();
  void update();
  void draw();

  void audioIn(ofSoundBuffer&amp; input);

  ofSoundStream soundStream;

  ofxFft* fft;
  std::vector&lt;float&gt; amplitudeBands;

  std::vector&lt;float&gt; leftSamples;
  std::vector&lt;float&gt; rightSamples;

  ofParameter&lt;float&gt; smoothPct;
  ofParameter&lt;float&gt; volPeak;

  ofParameter&lt;float&gt; currVol;
  ofParameter&lt;float&gt; smoothVol;
  ofParameter&lt;float&gt; scaledVol;

  ofParameter&lt;float&gt; onsetThreshold;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>//ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  ofBackground(0);

  // Print audio device list to the console.
  soundStream.printDeviceList();
  //soundStream.setDeviceID(3);

  // Setup sound stream.
  ofSoundStreamSettings settings;
  //settings.setApi(ofSoundDevice::Api::MS_DS);
  settings.setInListener(this);
  //settings.sampleRate = 44100;
  settings.bufferSize = 64;
  settings.numOutputChannels = 0;
  settings.numInputChannels = 2;
  soundStream.setup(settings);

  // Setup FFT.
  fft = ofxFft::create(settings.bufferSize, OF_FFT_WINDOW_HAMMING);
  amplitudeBands.resize(settings.bufferSize, 0.0f);

  // Initialize sample history.
  leftSamples.assign(settings.bufferSize, 0.0);
  rightSamples.assign(settings.bufferSize, 0.0);

  // Use ofParameter for volume values so that we can print them in the GUI.
  currVol.set(&quot;Curr Vol&quot;, 0.0, 0.0, 1.0);
  smoothVol.set(&quot;Smooth Vol&quot;, 0.0, 0.0, 1.0);
  scaledVol.set(&quot;Scaled Vol&quot;, 0.0, 0.0, 1.0);

  smoothPct.set(&quot;Smooth Pct&quot;, 0.05, 0.0, 1.0);
  volPeak.set(&quot;Vol Peak&quot;, 0.001, 0.0, 1.0);

  onsetThreshold.set(&quot;Onset Thresh&quot;, 0.5, 0.0, 1.0);

  guiPanel.setup(&quot;Audio In&quot;, &quot;settings.json&quot;);
  guiPanel.add(currVol);
  guiPanel.add(smoothVol);
  guiPanel.add(scaledVol);
  guiPanel.add(smoothPct);
  guiPanel.add(volPeak);
  guiPanel.add(onsetThreshold);
}

void ofApp::exit()
{
  soundStream.close();
}

void ofApp::update() 
{
  // Scale the volume up to a 0-1 range.
  volPeak = max(volPeak, smoothVol);
  scaledVol = ofMap(smoothVol, 0.0, volPeak, 0.0, 1.0, true);
}

void ofApp::draw() 
{
  ofSetLineWidth(2.0);

  // Draw the left channel history.
  ofSetColor(200, 0, 0);
  ofBeginShape();
  for (int i = 0; i &lt; leftSamples.size(); i++) 
  {
    float x = ofMap(i, 0, leftSamples.size(), 0, ofGetWidth());
    float y = ofMap(leftSamples[i], -1.0, 1.0, 0, 200);
    ofVertex(x, y);
  }
  ofEndShape(false);
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, 0, ofGetWidth(), 200);

  // Draw the right channel history.
  ofSetColor(200, 0, 0);
  ofBeginShape();
  for (int i = 0; i &lt; rightSamples.size(); i++)
  {
    float x = ofMap(i, 0, rightSamples.size(), 0, ofGetWidth());
    float y = ofMap(rightSamples[i], -1.0, 1.0, 200, 400);
    ofVertex(x, y);
  }
  ofEndShape(false);
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, 200, ofGetWidth(), 200);

  // Draw the frequency spectrum (FFT).
  ofSetColor(0, 0, 200);
  ofFill();
  float bandWidth = ofGetWidth() / fft-&gt;getBinSize();
  for (int i = 0; i &lt; fft-&gt;getBinSize(); i++)
  {
    // Negative height to draw from the bottom up.
    ofDrawRectangle(i * bandWidth, 600, bandWidth, amplitudeBands[i] * -200);
  }
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, 400, ofGetWidth(), 200);

  // Draw the volume level.
  float volWidth = ofMap(scaledVol, 0.0, 1.0, 0.0, ofGetWidth());
  ofFill();
  if (scaledVol &lt; onsetThreshold)
  {
    ofSetColor(200, 0, 0);
  }
  else
  {
    ofSetColor(0, 200, 0);
  }
  ofDrawRectangle(0, ofGetHeight() - 120, volWidth, 120);
  // Draw the threshold level.
  ofSetColor(225);
  float threshPos = ofMap(onsetThreshold, 0.0, 1.0, 0.0, ofGetWidth());
  ofDrawRectangle(threshPos, ofGetHeight() - 120, 2, 120);
  // Draw a border around the box.
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, ofGetHeight() - 120, ofGetWidth(), 120);

  guiPanel.draw();
}

void ofApp::audioIn(ofSoundBuffer&amp; input)
{
  // Calculate the volume using RMS.
  currVol = 0.0;
  int numCounted = 0;
  for (int i = 0; i &lt; input.getNumFrames(); i++)
  {
    // Samples should be between -1 and 1, but sometimes go a bit haywire 
    // when there's no data, so let's clamp the values to avoid outliers.
    leftSamples[i] = ofClamp(input[i * 2 + 0], -1, 1) * 0.5;
    rightSamples[i] = ofClamp(input[i * 2 + 1], -1, 1) * 0.5;

    currVol += leftSamples[i] * leftSamples[i];
    currVol += rightSamples[i] * rightSamples[i];
    
    numCounted += 2;
  }
  currVol /= (float)numCounted;
  currVol = sqrt(currVol);
  // Smooth volume over time.
  smoothVol = ofLerp(smoothVol, currVol, smoothPct);

  // Calculate amplitudes.
  fft-&gt;setSignal(input.getBuffer());
  float* amplitude = fft-&gt;getAmplitude();
  // Scale FFT bands to 0-1 range.
  float maxValue = 0;
  for (int i = 0; i &lt; fft-&gt;getBinSize(); i++)
  {
    if (abs(amplitude[i]) &gt; maxValue)
    {
      maxValue = abs(amplitude[i]);
    }
  }
  // Smooth FFT bands over time.
  for (int i = 0; i &lt; fft-&gt;getBinSize(); i++)
  {
    if (maxValue &gt; 0)
    {
      amplitude[i] /= maxValue;
    }
    amplitudeBands[i] = ofLerp(amplitudeBands[i], amplitude[i], smoothPct);
  }
}
</code></pre><figure style='display:block;margin:1em auto;width:600px'><a href=sound-fft.png><img style='display:block;margin:0 auto' src=sound-fft.png alt="Sound FFT"></a></figure><h2 id=sound-player>Sound Player <a href=#sound-player class=anchor aria-hidden=true>#</a></h2><p><a href=https://openframeworks.cc///documentation/sound/ofSoundPlayer/><code>ofSoundPlayer</code></a> is used to play sound files. The OF examples do a good job of showing all the functionality here, so I won&rsquo;t spend time on it here.</p><h2 id=sound-synthesis>Sound Synthesis <a href=#sound-synthesis class=anchor aria-hidden=true>#</a></h2><p>Generating sound in OF also starts with an <code>ofSoundStream</code>:</p><ul><li>Set the output channels of our <code>ofSoundStream</code> to a value greater than <code>0</code>.</li><li>Set an audio listener to the <code>ofSoundStream</code> using <a href=https://openframeworks.cc/documentation/sound/ofSoundStreamSettings/#show_setOutListener><code>ofSoundStreamSettings.setOutListener()</code></a>. This can be any class that extends from <code>ofBaseSoundOutput</code>, which includes our <code>ofApp</code>.</li><li>Implement the <a href=https://openframeworks.cc/documentation/types/ofBaseSoundOutput/#!show_audioOut><code>audioOut()</code></a> function in our listener class.</li></ul><pre><code class=language-cpp>//ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp 
{
public:
  void setup();
  void update();
  void draw();

  void audioOut(ofSoundBuffer&amp; buffer);

  ofSoundStream soundStream;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>//ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  ofBackground(0);

  ofSoundStreamSettings settings;
  //settings.setApi(ofSoundDevice::Api::MS_DS);
  settings.setOutListener(this);
  //settings.sampleRate = 44100;
  settings.bufferSize = 256;
  settings.numOutputChannels = 2;
  settings.numInputChannels = 0;
  soundStream.setup(settings);

  guiPanel.setup(&quot;Audio Out&quot;, &quot;settings.json&quot;);
}

void ofApp::update()
{

}

void ofApp::draw()
{
  guiPanel.draw();
}

void ofApp::audioOut(ofSoundBuffer&amp; buffer)
{

}
</code></pre><h3 id=signal-generator>Signal Generator <a href=#signal-generator class=anchor aria-hidden=true>#</a></h3><p>We need to fill the buffer received in <code>audioOut()</code> with data to produce sound.</p><ul><li>We will generate a sine wave and send it to both left and right channels.</li><li>The pan (balance between left and right channels) will be updated using the mouse x position.</li><li>The phase (length of sine wave period) will be updated using the mouse y position. The shorter the phase, the higher the sound frequency.</li><li>We want the sine wave to be continuous, so we&rsquo;ll use a class variable <code>phaseVal</code> to keep track of the value across frames.</li><li>We want to avoid any jumps in phase values because these might lead to &ldquo;pops&rdquo; in the sound, so <code>phaseStep</code> will change gradually using <code>ofLerp()</code>.</li></ul><pre><code class=language-cpp>//ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp 
{
public:
  void setup();
  void update();
  void draw();

  void audioOut(ofSoundBuffer&amp; buffer);

  ofSoundStream soundStream;

  std::vector&lt;float&gt; leftSamples;
  std::vector&lt;float&gt; rightSamples;

  float phaseVal;
  float phaseStep;

  ofParameter&lt;float&gt; volume;
  ofParameter&lt;float&gt; pan;
  ofParameter&lt;float&gt; phaseSpeed;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>//ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  ofBackground(0);

  ofSoundStreamSettings settings;
  //settings.setApi(ofSoundDevice::Api::MS_DS);
  settings.setOutListener(this);
  //settings.sampleRate = 44100;
  settings.bufferSize = 256;
  settings.numOutputChannels = 2;
  settings.numInputChannels = 0;
  soundStream.setup(settings);

  phaseVal = 0;
  phaseStep = 0.0f;

  leftSamples.assign(settings.bufferSize, 0.0);
  rightSamples.assign(settings.bufferSize, 0.0);

  volume.set(&quot;Volume&quot;, 0.1, 0.0, 1.0);
  pan.set(&quot;Pan&quot;, 0.1, 0.0, 1.0);
  phaseSpeed.set(&quot;Phase Speed&quot;, 0.15, 0.0, 1.0);

  guiPanel.setup(&quot;Audio Out&quot;, &quot;settings.json&quot;);
  guiPanel.add(volume);
  guiPanel.add(pan);
  guiPanel.add(phaseSpeed);
}

void ofApp::update()
{
  pan = ofMap(ofGetMouseX(), 0, ofGetWidth(), 0, 1, true);
  float phaseStepTarget = ofMap(ofGetMouseY(), 0, ofGetHeight(), phaseSpeed, 0, true);
  phaseStep = ofLerp(phaseStep, phaseStepTarget, 0.95);
}

void ofApp::draw()
{
  ofSetLineWidth(2.0);

  // Draw the left channel history.
  ofSetColor(200, 0, 0);
  ofBeginShape();
  for (int i = 0; i &lt; leftSamples.size(); i++)
  {
    float x = ofMap(i, 0, leftSamples.size(), 0, ofGetWidth());
    float y = ofMap(leftSamples[i], -1.0, 1.0, 0, 200);
    ofVertex(x, y);
  }
  ofEndShape(false);
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, 0, ofGetWidth(), 200);

  // Draw the right channel history.
  ofSetColor(200, 0, 0);
  ofBeginShape();
  for (int i = 0; i &lt; rightSamples.size(); i++)
  {
    float x = ofMap(i, 0, rightSamples.size(), 0, ofGetWidth());
    float y = ofMap(rightSamples[i], -1.0, 1.0, 200, 400);
    ofVertex(x, y);
  }
  ofEndShape(false);
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, 200, ofGetWidth(), 200);

  guiPanel.draw();
}

void ofApp::audioOut(ofSoundBuffer&amp; buffer)
{
  float leftScale = 1 - pan;
  float rightScale = pan;

  // sin(n) seems to have trouble when n is very large.
  // Keep phase in the range of 0-TWO_PI.
  while (phaseVal &gt; TWO_PI)
  {
    phaseVal -= TWO_PI;
  }

  for (int i = 0; i &lt; buffer.getNumFrames(); i++)
  {
    phaseVal += phaseStep;
    float sample = sin(phaseVal);
    leftSamples[i] = buffer[i * 2 + 0] = sample * volume * leftScale;
    rightSamples[i] = buffer[i * 2 + 1] = sample * volume * rightScale;
  }
}
</code></pre><figure style='display:block;margin:1em auto;width:600px'><a href=sound-sin.png><img style='display:block;margin:0 auto' src=sound-sin.png alt="Sound Sin"></a></figure><h3 id=noise-generator>Noise Generator <a href=#noise-generator class=anchor aria-hidden=true>#</a></h3><p>We can generate signal from a variety of sources. Using <a href=https://en.wikipedia.org/wiki/Perlin_noise>Perlin noise</a> leads to interesting results, because it offers a good balance between randomness and continuity. In OF, we can use <a href=https://openframeworks.cc/documentation/math/ofMath/#show_ofSignedNoise><code>ofSignedNoise()</code></a> because it returns values in the same domain that our buffer expects, from <code>-1</code> to <code>1</code>.</p><pre><code class=language-cpp>//ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp 
{
public:
  void setup();
  void update();
  void draw();

  void audioOut(ofSoundBuffer&amp; buffer);

  ofSoundStream soundStream;

  std::vector&lt;float&gt; leftSamples;
  std::vector&lt;float&gt; rightSamples;

  float phaseVal;
  float phaseStep;

  ofParameter&lt;float&gt; volume;
  ofParameter&lt;float&gt; pan;
  ofParameter&lt;float&gt; phaseSpeed;
  ofParameter&lt;bool&gt; doNoise;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>//ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  ofBackground(0);

  ofSoundStreamSettings settings;
  //settings.setApi(ofSoundDevice::Api::MS_DS);
  settings.setOutListener(this);
  //settings.sampleRate = 44100;
  settings.bufferSize = 256;
  settings.numOutputChannels = 2;
  settings.numInputChannels = 0;
  soundStream.setup(settings);

  phaseVal = 0;
  phaseStep = 0.0f;

  leftSamples.assign(settings.bufferSize, 0.0);
  rightSamples.assign(settings.bufferSize, 0.0);

  volume.set(&quot;Volume&quot;, 0.1, 0.0, 1.0);
  pan.set(&quot;Pan&quot;, 0.1, 0.0, 1.0);
  phaseSpeed.set(&quot;Phase Speed&quot;, 0.15, 0.0, 1.0);
  doNoise.set(&quot;Do Noise&quot;, false);

  guiPanel.setup(&quot;Audio Out&quot;, &quot;settings.json&quot;);
  guiPanel.add(volume);
  guiPanel.add(pan);
  guiPanel.add(phaseSpeed);
  guiPanel.add(doNoise);
}

void ofApp::update()
{
  pan = ofMap(ofGetMouseX(), 0, ofGetWidth(), 0, 1, true);
  float phaseStepTarget = ofMap(ofGetMouseY(), 0, ofGetHeight(), phaseSpeed, 0, true);
  phaseStep = ofLerp(phaseStep, phaseStepTarget, 0.95);
}

void ofApp::draw()
{
  ofSetLineWidth(2.0);

  // Draw the left channel history.
  ofSetColor(200, 0, 0);
  ofBeginShape();
  for (int i = 0; i &lt; leftSamples.size(); i++)
  {
    float x = ofMap(i, 0, leftSamples.size(), 0, ofGetWidth());
    float y = ofMap(leftSamples[i], -1.0, 1.0, 0, 200);
    ofVertex(x, y);
  }
  ofEndShape(false);
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, 0, ofGetWidth(), 200);

  // Draw the right channel history.
  ofSetColor(200, 0, 0);
  ofBeginShape();
  for (int i = 0; i &lt; rightSamples.size(); i++)
  {
    float x = ofMap(i, 0, rightSamples.size(), 0, ofGetWidth());
    float y = ofMap(rightSamples[i], -1.0, 1.0, 200, 400);
    ofVertex(x, y);
  }
  ofEndShape(false);
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, 200, ofGetWidth(), 200);

  guiPanel.draw();
}

void ofApp::audioOut(ofSoundBuffer&amp; buffer)
{
  float leftScale = 1 - pan;
  float rightScale = pan;

  // sin(n) seems to have trouble when n is very large.
  // Keep phase in the range of 0-TWO_PI.
  while (phaseVal &gt; TWO_PI)
  {
    phaseVal -= TWO_PI;
  }

  if (doNoise)
  {
    for (int i = 0; i &lt; buffer.getNumFrames(); i++)
    {
      phaseVal += phaseStep;
      float sample = ofSignedNoise(phaseVal);
      leftSamples[i] = buffer[i * 2 + 0] = sample * volume * leftScale;
      rightSamples[i] = buffer[i * 2 + 1] = sample * volume * rightScale;
    }
  }
  else
  {
    for (int i = 0; i &lt; buffer.getNumFrames(); i++)
    {
      phaseVal += phaseStep;
      float sample = sin(phaseVal);
      leftSamples[i] = buffer[i * 2 + 0] = sample * volume * leftScale;
      rightSamples[i] = buffer[i * 2 + 1] = sample * volume * rightScale;
    }
  }
}
</code></pre><figure style='display:block;margin:1em auto;width:600px'><a href=sound-noise.png><img style='display:block;margin:0 auto' src=sound-noise.png alt="Sound Noise"></a></figure><h2 id=midi>MIDI <a href=#midi class=anchor aria-hidden=true>#</a></h2><p>MIDI (which stands for Musical Instrument Digital Interface) is a communication protocol that is a standard for audio messages. MIDI has been around since the 1980s and is pretty universal; if you have any piece of hardware or software that is used for music, there is a good chance it supports MIDI.</p><p>The MIDI specification consists of different types of messages, including:</p><ul><li><em>Note On</em> and <em>Note Off</em> to trigger notes.</li><li><em>Polyphonic Key Pressure</em> and <em>Pitch Bend</em> to affect the played notes.</li><li><em>Control Change</em> and <em>Program Change</em> to set mode and functionality.</li><li><em>System</em> to control playback and device specific features.</li></ul><p>In OF, we can use <a href=https://github.com/danomatika/ofxMidi><code>ofxMidi</code></a> for input and output.</p><p>The following example uses a controller to trigger notes in OF.</p><ul><li><code>ofApp</code> extends <code>ofxMidiListener</code> (on top of <code>ofBaseApp</code>) to get access to the MIDI listeners.</li><li><code>ofApp</code> implements the <code>newMidiMessage()</code> function to handle incoming messages.</li><li>All possible frequencies are calculated at startup and stored in a look-up table.</li><li>The target frequency is set whenever a MIDI note message is received.</li></ul><pre><code class=language-cpp>//ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxGui.h&quot;
#include &quot;ofxMidi.h&quot;

class ofApp : public ofBaseApp, public ofxMidiListener
{
public:
  void setup();
  void update();
  void draw();

  void updateWaveform(int&amp; resolution);
  void audioOut(ofSoundBuffer&amp; buffer);
  void newMidiMessage(ofxMidiMessage&amp; msg);

  ofSoundStream soundStream;

  std::vector&lt;float&gt; leftSamples;
  std::vector&lt;float&gt; rightSamples;

  ofxMidiIn midiIn;
  std::vector&lt;float&gt; midiFreqs;
  float freqTarget;

  std::vector&lt;float&gt; waveform;
  float phaseVal;
  float phaseStep;

  ofParameter&lt;float&gt; volume;
  ofParameter&lt;float&gt; pan;
  ofParameter&lt;int&gt; resolution;
  ofParameter&lt;float&gt; freqSpeed;
  ofParameter&lt;float&gt; frequency;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>//ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  ofBackground(0);

  // Setup sound output.
  ofSoundStreamSettings settings;
  //settings.setApi(ofSoundDevice::Api::MS_DS);
  settings.setOutListener(this);
  //settings.sampleRate = 44100;
  settings.bufferSize = 256;
  settings.numOutputChannels = 2;
  settings.numInputChannels = 0;
  soundStream.setup(settings);

  phaseVal = 0;
  phaseStep = 0.0f;

  leftSamples.assign(settings.bufferSize, 0.0);
  rightSamples.assign(settings.bufferSize, 0.0);

  // Setup MIDI input.
  midiIn.listInPorts();
  midiIn.openPort(0);
  midiIn.ignoreTypes(true, true, true);
  midiIn.addListener(this);

  // Build note to frequency table.
  // http://subsynth.sourceforge.net/midinote2freq.html
  midiFreqs.resize(127);
  int a = 440; // a is 440 hz...
  for (int i = 0; i &lt; midiFreqs.size(); i++)
  {
    midiFreqs[i] = (a / 32.0f) * powf(2, (i - 9) / 12.0f);
  }

  volume.set(&quot;Volume&quot;, 0.1, 0.0, 1.0);
  pan.set(&quot;Pan&quot;, 0.1, 0.0, 1.0);
  resolution.set(&quot;Resolution&quot;, 32, 3, 64);
  resolution.addListener(this, &amp;ofApp::updateWaveform);
  freqSpeed.set(&quot;Freq Speed&quot;, 0.2, 0.0, 1.0);
  frequency.set(&quot;Frequency&quot;, 0.0, 0.0, 12544.0);

  guiPanel.setup(&quot;Audio Out&quot;, &quot;settings.json&quot;);
  guiPanel.add(volume);
  guiPanel.add(pan);
  guiPanel.add(resolution);
  guiPanel.add(freqSpeed);
  guiPanel.add(frequency);

  // Set initial params.
  int res = resolution;
  updateWaveform(res);
}

void ofApp::update()
{
  pan = ofMap(ofGetMouseX(), 0, ofGetWidth(), 0, 1, true);
  frequency = ofLerp(frequency, freqTarget, freqSpeed);
}

void ofApp::draw()
{
  ofSetLineWidth(2.0);

  // Draw the left channel history.
  ofSetColor(200, 0, 0);
  ofBeginShape();
  for (int i = 0; i &lt; leftSamples.size(); i++)
  {
    float x = ofMap(i, 0, leftSamples.size(), 0, ofGetWidth());
    float y = ofMap(leftSamples[i], -1.0, 1.0, 0, 200);
    ofVertex(x, y);
  }
  ofEndShape(false);
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, 0, ofGetWidth(), 200);

  // Draw the right channel history.
  ofSetColor(200, 0, 0);
  ofBeginShape();
  for (int i = 0; i &lt; rightSamples.size(); i++)
  {
    float x = ofMap(i, 0, rightSamples.size(), 0, ofGetWidth());
    float y = ofMap(rightSamples[i], -1.0, 1.0, 200, 400);
    ofVertex(x, y);
  }
  ofEndShape(false);
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, 200, ofGetWidth(), 200);

  // Draw the waveform.
  ofSetColor(0, 200, 0);
  ofBeginShape();
  for (int i = 0; i &lt; waveform.size(); i++)
  {
    float x = ofMap(i, 0, waveform.size() - 1, 0, ofGetWidth());
    float y = ofMap(waveform[i], -1.0, 1.0, ofGetHeight() - 120, ofGetHeight());
    ofVertex(x, y);
  }
  ofEndShape(false);
  ofSetColor(225);
  ofNoFill();
  ofDrawRectangle(0, ofGetHeight() - 120, ofGetWidth(), 120);

  guiPanel.draw();
}

// https://openframeworks.cc/ofBook/chapters/sound.html
void ofApp::updateWaveform(int&amp; resolution)
{
  waveform.resize(resolution);

  // &quot;waveformStep&quot; maps a full oscillation of sin() to the size 
  // of the waveform lookup table
  float waveformStep = TWO_PI / (float)waveform.size();

  for (int i = 0; i &lt; waveform.size(); i++)
  {
    waveform[i] = sin(i * waveformStep);
  }
}

void ofApp::audioOut(ofSoundBuffer&amp; buffer)
{
  float leftScale = 1 - pan;
  float rightScale = pan;

  // sin(n) seems to have trouble when n is very large.
  // Keep phase in the range of 0-TWO_PI.
  while (phaseVal &gt; TWO_PI)
  {
    phaseVal -= TWO_PI;
  }

  float sampleRate = buffer.getSampleRate();
  phaseStep = frequency / sampleRate;

  for (int i = 0; i &lt; buffer.getNumFrames(); i++)
  {
    phaseVal += phaseStep;
    int idx = (int)(phaseVal * waveform.size()) % waveform.size();
    float sample = waveform[idx];
    leftSamples[i] = buffer[i * 2 + 0] = sample * volume * leftScale;
    rightSamples[i] = buffer[i * 2 + 1] = sample * volume * rightScale;
  }
}

void ofApp::newMidiMessage(ofxMidiMessage&amp; msg)
{
  ofLogNotice(__FUNCTION__) &lt;&lt; msg.getStatusString(msg.status) &lt;&lt; &quot; Pitch: &quot; &lt;&lt; msg.pitch &lt;&lt; &quot; Velocity: &quot; &lt;&lt; msg.velocity &lt;&lt; &quot; Control: &quot; &lt;&lt; msg.control &lt;&lt; &quot; Value: &quot; &lt;&lt; msg.value;
  if (msg.status == MidiStatus::MIDI_NOTE_ON)
  {
    freqTarget = midiFreqs[msg.pitch];
  }
  else if (msg.status == MidiStatus::MIDI_NOTE_OFF)
  {
    freqTarget = 0;
  }
}
</code></pre><h2 id=sound-addons>Sound Addons <a href=#sound-addons class=anchor aria-hidden=true>#</a></h2><p>There are a few other sound addons available to explore. Some recommendations:</p><ul><li><a href=https://github.com/roymacdonald/ofxSoundObjects>ofxSoundObjects</a> uses the idea of <em>sound objects</em> as components that audio moves through. Each has an input and output, so they can be connected to one another to stack sounds and filters.</li><li><a href=https://github.com/TonicAudio/ofxTonic>ofxTonic</a> is an OF wrapper for <a href=https://github.com/TonicAudio/Tonic>Tonic</a>, a high performance C++ audio synthesis library. It works on top of the OF sound engine and makes sound generation fun and easy.</li></ul><div class="page-footer-meta d-flex flex-column flex-md-row justify-content-between"></div><div class="docs-navigation d-flex justify-content-between"><a href=https://seeingmachines.betamovement.net/docs/class-12/mobile-development/><div class="card my-1"><div class="card-body py-2">&larr; Mobile Development</div></div></a></div></main></div></div></div><footer class="footer text-muted"><div class=container-xxl><div class=row><div class="col-lg-8 order-last order-lg-first"><ul class=list-inline><li class=list-inline-item>Powered by <a class=text-muted href=https://github.com/>GitHub</a>, <a class=text-muted href=https://gohugo.io/>Hugo</a>, and <a class=text-muted href=https://getdoks.org/>Doks</a></li></ul></div><div class="col-lg-8 order-first order-lg-last text-lg-end"><ul class=list-inline></ul></div></div></div></footer><script src=https://seeingmachines.betamovement.net/js/bootstrap.min.7315382e899a7d7132d93fdf0d6682c67a93f0e72ee1a757f33f3207de3b14e2460a935c9d4cec78f86d94ab892d053c70540695eed0bbb7bf5bdc979e6f5a9f.js integrity="sha512-cxU4LomafXEy2T/fDWaCxnqT8Ocu4adX8z8yB947FOJGCpNcnUzsePhtlKuJLQU8cFQGle7Qu7e/W9yXnm9anw==" crossorigin=anonymous defer></script>
<script src=https://seeingmachines.betamovement.net/js/highlight.min.93c197e7097c47fc0788b21721b3c308e18e43299f1e45e8ff2697d13cd62908cc5949a053c1fb7242d7b4a60eb07bd106061252f7aa925ef7e91033ea59d9b9.js integrity="sha512-k8GX5wl8R/wHiLIXIbPDCOGOQymfHkXo/yaX0TzWKQjMWUmgU8H7ckLXtKYOsHvRBgYSUveqkl736RAz6lnZuQ==" crossorigin=anonymous defer></script>
<script src=https://seeingmachines.betamovement.net/main.min.162c56a0426544de0d010e66c56e321579655c400c9aae06a6823e7682de379adadf2165bd416fea191e4e7e410fbf1fd2c35a759aa43ff2e3787067669bf81b.js integrity="sha512-FixWoEJlRN4NAQ5mxW4yFXllXEAMmq4GpoI+doLeN5ra3yFlvUFv6hkeTn5BD78f0sNadZqkP/LjeHBnZpv4Gw==" crossorigin=anonymous defer></script>
<script src=https://seeingmachines.betamovement.net/index.min.91b38a5362499748b9b11af4a433f38197caf27626109e714842bf07ac3b2bee595bc90553a3685ee80df9639d4c1c0df7068fcb7fead997523150b6d14cd933.js integrity="sha512-kbOKU2JJl0i5sRr0pDPzgZfK8nYmEJ5xSEK/B6w7K+5ZW8kFU6NoXugN+WOdTBwN9waPy3/q2ZdSMVC20UzZMw==" crossorigin=anonymous defer></script></body></html>