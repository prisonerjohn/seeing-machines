<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=preload as=font href=https://seeingmachines.betamovement.net/fonts/vendor/jost/jost-v4-latin-regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://seeingmachines.betamovement.net/fonts/vendor/jost/jost-v4-latin-500.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://seeingmachines.betamovement.net/fonts/vendor/jost/jost-v4-latin-700.woff2 type=font/woff2 crossorigin><script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script><link rel=stylesheet href=https://seeingmachines.betamovement.net/main.8d021019b9ce3f15211b87c945c913e36aaf7bf23d3e2a81f9da6c01ea22a3c97caa4400b3466899838f5b4b52d3749af9554379487e932c3e83530c676aeca2.css integrity="sha512-jQIQGbnOPxUhG4fJRckT42qve/I9PiqB+dpsAeoio8l8qkQAs0ZomYOPW0tS03Sa+VVDeUh+kyw+g1MMZ2rsog==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>Images and Video - Seeing Machines</title><meta name=description content="File Formats # Digital images come in a variety of formats, each with their own properties.
Vector Graphics # Vector formats define a set of points and instructions on how to draw them. The instructions are run by a program to raster the image in order to view it.
Some of the more common vector formats are SVG, EPS, PDF, and AI.
If we open the following SVG file in a text editor, we will notice that it is fairly easy to read the format."><link rel=canonical href=https://seeingmachines.betamovement.net/docs/class-1/images-and-video/><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="Images and Video"><meta property="og:description" content="File Formats # Digital images come in a variety of formats, each with their own properties.
Vector Graphics # Vector formats define a set of points and instructions on how to draw them. The instructions are run by a program to raster the image in order to view it.
Some of the more common vector formats are SVG, EPS, PDF, and AI.
If we open the following SVG file in a text editor, we will notice that it is fairly easy to read the format."><meta property="og:url" content="https://seeingmachines.betamovement.net/docs/class-1/images-and-video/"><meta property="og:site_name" content="Seeing Machines"><meta property="article:published_time" content="2022-09-18T13:42:06-04:00"><meta property="article:modified_time" content="2022-09-18T13:42:06-04:00"><meta property="og:image" content="https://seeingmachines.betamovement.net/default-image.png"><meta property="og:image:alt" content="Seeing Machines"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content><meta name=twitter:creator content="@prisonerjohn"><meta name=twitter:title content="Images and Video"><meta name=twitter:description content><meta name=twitter:image content="https://seeingmachines.betamovement.net/default-image.png"><meta name=twitter:image:alt content="Images and Video"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://seeingmachines.betamovement.net/#/schema/person/1","name":"Seeing Machines","url":"https://seeingmachines.betamovement.net/","sameAs":[],"image":{"@type":"ImageObject","@id":"https://seeingmachines.betamovement.net/#/schema/image/1","url":"https://seeingmachines.betamovement.net/default-image.png","width":1024,"height":768,"caption":"Seeing Machines"}},{"@type":"WebSite","@id":"https://seeingmachines.betamovement.net/#/schema/website/1","url":"https://seeingmachines.betamovement.net/","name":"Seeing Machines","description":"A programming course where we’ll explore various techniques and solutions for tracking and sensing people or objects in space.","publisher":{"@id":"https://seeingmachines.betamovement.net/#/schema/person/1"}},{"@type":"WebPage","@id":"https://seeingmachines.betamovement.net/docs/class-1/images-and-video/","url":"https://seeingmachines.betamovement.net/docs/class-1/images-and-video/","name":"Images and Video","description":"","isPartOf":{"@id":"https://seeingmachines.betamovement.net/#/schema/website/1"},"about":{"@id":"https://seeingmachines.betamovement.net/#/schema/person/1"},"datePublished":"2022-09-18T13:42:06CET","dateModified":"2022-09-18T13:42:06CET","breadcrumb":{"@id":"https://seeingmachines.betamovement.net/docs/class-1/images-and-video/#/schema/breadcrumb/1"},"primaryImageOfPage":{"@id":"https://seeingmachines.betamovement.net/docs/class-1/images-and-video/#/schema/image/2"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://seeingmachines.betamovement.net/docs/class-1/images-and-video/"]}]},{"@type":"BreadcrumbList","@id":"https://seeingmachines.betamovement.net/docs/class-1/images-and-video/#/schema/breadcrumb/1","name":"Breadcrumbs","itemListElement":[{"@type":"ListItem","position":1,"item":{"@type":"WebPage","@id":"https://seeingmachines.betamovement.net/","url":"https://seeingmachines.betamovement.net/","name":"Home"}},{"@type":"ListItem","position":2,"item":{"@type":"WebPage","@id":"https://seeingmachines.betamovement.net/docs/","url":"https://seeingmachines.betamovement.net/docs/","name":"Docs"}},{"@type":"ListItem","position":3,"item":{"@type":"WebPage","@id":"https://seeingmachines.betamovement.net/docs/class-1/","url":"https://seeingmachines.betamovement.net/docs/class-1/","name":"Class 1"}},{"@type":"ListItem","position":4,"item":{"@id":"https://seeingmachines.betamovement.net/docs/class-1/images-and-video/"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Article","@id":"https://seeingmachines.betamovement.net/#/schema/article/1","headline":"Images and Video","description":"","isPartOf":{"@id":"https://seeingmachines.betamovement.net/docs/class-1/images-and-video/"},"mainEntityOfPage":{"@id":"https://seeingmachines.betamovement.net/docs/class-1/images-and-video/"},"datePublished":"2022-09-18T13:42:06CET","dateModified":"2022-09-18T13:42:06CET","author":{"@id":"https://seeingmachines.betamovement.net/#/schema/person/2"},"publisher":{"@id":"https://seeingmachines.betamovement.net/#/schema/person/1"},"image":{"@id":"https://seeingmachines.betamovement.net/docs/class-1/images-and-video/#/schema/image/2"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://seeingmachines.betamovement.net/#/schema/person/2","name":"Elie Zananiri","sameAs":["https://twitter.com/prisonerjohn","https://www.linkedin.com/in/prisonerjohn/","https://github.com/prisonerjohn"]}]},{"@context":"https://schema.org","@graph":[{"@type":"ImageObject","@id":"https://seeingmachines.betamovement.net/docs/class-1/images-and-video/#/schema/image/2","url":"https://seeingmachines.betamovement.net/default-image.png","contentUrl":"https://seeingmachines.betamovement.net/default-image.png","caption":"Images and Video"}]}]}</script><meta name=theme-color content="#fff"><link rel=icon href=https://seeingmachines.betamovement.net/favicon.ico sizes=any><link rel=icon type=image/svg+xml href=https://seeingmachines.betamovement.net/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=https://seeingmachines.betamovement.net/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://seeingmachines.betamovement.net/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://seeingmachines.betamovement.net/favicon-16x16.png><link rel=manifest crossorigin=use-credentials href=https://seeingmachines.betamovement.net/site.webmanifest></head><body class="docs single"><div class=sticky-top><div class=header-bar></div><header class="navbar navbar-expand-lg navbar-light doks-navbar"><nav class="container-xxl flex-wrap flex-lg-nowrap" aria-label="Main navigation"><a class="navbar-brand order-0" href=https://seeingmachines.betamovement.net/ aria-label="Seeing Machines">Seeing Machines</a>
<button class="btn btn-link order-0 ms-auto d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasExample aria-controls=offcanvasExample><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-more-horizontal"><circle cx="12" cy="12" r="1"/><circle cx="19" cy="12" r="1"/><circle cx="5" cy="12" r="1"/></svg></button><div class="offcanvas offcanvas-start d-lg-none" tabindex=-1 id=offcanvasExample aria-labelledby=offcanvasExampleLabel><div class=header-bar></div><div class=offcanvas-header><h5 class=offcanvas-title id=offcanvasExampleLabel>Browse docs</h5><button type=button class=btn-close data-bs-dismiss=offcanvas aria-label=Close></button></div><div class=offcanvas-body><aside class="doks-sidebar mt-n3"><nav id=doks-docs-nav aria-label="Tertiary navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-f7e883054c348d897063924d41a7ec2d aria-expanded=false>
Class 0</button><div class=collapse id=section-f7e883054c348d897063924d41a7ec2d><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-0/foreword/>Foreword</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-0/intro-to-of/>Intro to OF</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e43c4a6cb52ad623673f8e77a5b10104 aria-expanded=true>
Class 1</button><div class="collapse show" id=section-e43c4a6cb52ad623673f8e77a5b10104><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/variables-and-arrays/>Variables and Arrays</a></li><li><a class="docs-link rounded active" href=https://seeingmachines.betamovement.net/docs/class-1/images-and-video/>Images and Video</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-2ef5a7f02774e1be242988dba4c3056c aria-expanded=false>
Class 2</button><div class=collapse id=section-2ef5a7f02774e1be242988dba4c3056c><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/computer-vision/>Computer Vision</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-6a3be28bcd9707b6b8ff8ac55a6b8cb2 aria-expanded=false>
Class 3</button><div class=collapse id=section-6a3be28bcd9707b6b8ff8ac55a6b8cb2><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-3/intro-to-opencv/>Intro to OpenCV</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-3/object-tracking/>Object Tracking</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e01cc216a97c1db953e2304e6aa8998a aria-expanded=false>
Class 4</button><div class=collapse id=section-e01cc216a97c1db953e2304e6aa8998a><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/logging/>Logging</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/depth-sensing/>Depth Sensing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-56c4b82e7a8861de86a5ebe5eaa62225 aria-expanded=false>
Assignments</button><div class=collapse id=section-56c4b82e7a8861de86a5ebe5eaa62225><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-1/>Assignment 1</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-2/>Assignment 2</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-3/>Assignment 3</a></li></ul></div></li></ul></nav></aside></div></div><button class="btn btn-menu order-2 d-block d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasDoks aria-controls=offcanvasDoks aria-label="Open main menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><div class="offcanvas offcanvas-end border-0 py-lg-1" tabindex=-1 id=offcanvasDoks data-bs-backdrop=true aria-labelledby=offcanvasDoksLabel><div class="header-bar d-lg-none"></div><div class="offcanvas-header d-lg-none"><h2 class="h5 offcanvas-title ps-2" id=offcanvasDoksLabel><a class=text-dark href=https://seeingmachines.betamovement.net/>Seeing Machines</a></h2><button type=button class="btn-close text-reset me-2" data-bs-dismiss=offcanvas aria-label="Close main menu"></button></div><div class="offcanvas-body p-4 p-lg-0"><ul class="nav flex-column flex-lg-row align-items-lg-center mt-2 mt-lg-0 ms-lg-2 me-lg-auto"><li class=nav-item><a class="nav-link ps-0 py-1 active" href=https://seeingmachines.betamovement.net/docs/class-0/foreword>Docs</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=https://seeingmachines.betamovement.net/docs/assignments>Assignments</a></li></ul><hr class="text-black-50 my-4 d-lg-none"><form class="doks-search position-relative flex-grow-1 ms-lg-auto me-lg-2"><input id=search class="form-control is-search" type=search placeholder="Search docs..." aria-label="Search docs..." autocomplete=off><div id=suggestions class="shadow bg-white rounded d-none"></div></form><hr class="text-black-50 my-4 d-lg-none"><ul class="nav flex-column flex-lg-row"><li class=nav-item><a class="nav-link social-link" href=https://github.com/prisonerjohn/seeing-machines><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg><small class="ms-2 d-lg-none">GitHub</small></a></li><li class=nav-item><a class="nav-link social-link" href=https://twitter.com/prisonerjohn><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-twitter"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg><small class="ms-2 d-lg-none">Twitter</small></a></li></ul><hr class="text-black-50 my-4 d-lg-none"><button id=mode class="btn btn-link" type=button aria-label="Toggle user interface mode">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></div></div></nav></header></div><div class=container-xxl><aside class=doks-sidebar><nav id=doks-docs-nav class="collapse d-lg-none" aria-label="Tertiary navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-f7e883054c348d897063924d41a7ec2d aria-expanded=false>
Class 0</button><div class=collapse id=section-f7e883054c348d897063924d41a7ec2d><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-0/foreword/>Foreword</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-0/intro-to-of/>Intro to OF</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e43c4a6cb52ad623673f8e77a5b10104 aria-expanded=true>
Class 1</button><div class="collapse show" id=section-e43c4a6cb52ad623673f8e77a5b10104><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/variables-and-arrays/>Variables and Arrays</a></li><li><a class="docs-link rounded active" href=https://seeingmachines.betamovement.net/docs/class-1/images-and-video/>Images and Video</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-2ef5a7f02774e1be242988dba4c3056c aria-expanded=false>
Class 2</button><div class=collapse id=section-2ef5a7f02774e1be242988dba4c3056c><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/computer-vision/>Computer Vision</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-6a3be28bcd9707b6b8ff8ac55a6b8cb2 aria-expanded=false>
Class 3</button><div class=collapse id=section-6a3be28bcd9707b6b8ff8ac55a6b8cb2><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-3/intro-to-opencv/>Intro to OpenCV</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-3/object-tracking/>Object Tracking</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e01cc216a97c1db953e2304e6aa8998a aria-expanded=false>
Class 4</button><div class=collapse id=section-e01cc216a97c1db953e2304e6aa8998a><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/logging/>Logging</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/depth-sensing/>Depth Sensing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-56c4b82e7a8861de86a5ebe5eaa62225 aria-expanded=false>
Assignments</button><div class=collapse id=section-56c4b82e7a8861de86a5ebe5eaa62225><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-1/>Assignment 1</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-2/>Assignment 2</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-3/>Assignment 3</a></li></ul></div></li></ul></nav></aside></div><div class="wrap container-xxl" role=document><div class=content><div class="row flex-xl-nowrap"><div class="col-lg-5 col-xl-4 docs-sidebar d-none d-lg-block"><nav class=docs-links aria-label="Main navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-f7e883054c348d897063924d41a7ec2d aria-expanded=false>
Class 0</button><div class=collapse id=section-f7e883054c348d897063924d41a7ec2d><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-0/foreword/>Foreword</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-0/intro-to-of/>Intro to OF</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e43c4a6cb52ad623673f8e77a5b10104 aria-expanded=true>
Class 1</button><div class="collapse show" id=section-e43c4a6cb52ad623673f8e77a5b10104><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/variables-and-arrays/>Variables and Arrays</a></li><li><a class="docs-link rounded active" href=https://seeingmachines.betamovement.net/docs/class-1/images-and-video/>Images and Video</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-2ef5a7f02774e1be242988dba4c3056c aria-expanded=false>
Class 2</button><div class=collapse id=section-2ef5a7f02774e1be242988dba4c3056c><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/computer-vision/>Computer Vision</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-6a3be28bcd9707b6b8ff8ac55a6b8cb2 aria-expanded=false>
Class 3</button><div class=collapse id=section-6a3be28bcd9707b6b8ff8ac55a6b8cb2><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-3/intro-to-opencv/>Intro to OpenCV</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-3/object-tracking/>Object Tracking</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e01cc216a97c1db953e2304e6aa8998a aria-expanded=false>
Class 4</button><div class=collapse id=section-e01cc216a97c1db953e2304e6aa8998a><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/logging/>Logging</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/depth-sensing/>Depth Sensing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-56c4b82e7a8861de86a5ebe5eaa62225 aria-expanded=false>
Assignments</button><div class=collapse id=section-56c4b82e7a8861de86a5ebe5eaa62225><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-1/>Assignment 1</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-2/>Assignment 2</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-3/>Assignment 3</a></li></ul></div></li></ul></nav></div><nav class="docs-toc d-none d-xl-block col-xl-3" aria-label="Secondary navigation"><div class=d-xl-none><button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#onThisPage aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>On this page</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button><div class=collapse id=onThisPage><div class="card card-body mt-3 py-1"><div class=page-links><nav id=TableOfContents><ul><li><a href=#file-formats>File Formats</a><ul><li><a href=#vector-graphics>Vector Graphics</a></li><li><a href=#raster-graphics>Raster Graphics</a></li><li><a href=#video>Video</a></li><li><a href=#processing-images>Processing Images</a></li></ul></li><li><a href=#images-in-of>Images in OF</a><ul><li><a href=#the-data-folder>The <code>data</code> Folder</a></li><li><a href=#ofimage><code>ofImage</code></a></li></ul></li><li><a href=#image-attributes>Image Attributes</a><ul><li><a href=#pixel-access>Pixel Access</a></li><li><a href=#image-format>Image Format</a></li><li><a href=#pixel-format>Pixel Format</a></li></ul></li></ul></nav></div></div></div></div><div class="page-links d-none d-xl-block"><h3>On this page</h3><nav id=TableOfContents><ul><li><a href=#file-formats>File Formats</a><ul><li><a href=#vector-graphics>Vector Graphics</a></li><li><a href=#raster-graphics>Raster Graphics</a></li><li><a href=#video>Video</a></li><li><a href=#processing-images>Processing Images</a></li></ul></li><li><a href=#images-in-of>Images in OF</a><ul><li><a href=#the-data-folder>The <code>data</code> Folder</a></li><li><a href=#ofimage><code>ofImage</code></a></li></ul></li><li><a href=#image-attributes>Image Attributes</a><ul><li><a href=#pixel-access>Pixel Access</a></li><li><a href=#image-format>Image Format</a></li><li><a href=#pixel-format>Pixel Format</a></li></ul></li></ul></nav></div></nav><main class="docs-content col-lg-11 col-xl-9"><h1>Images and Video</h1><p class=lead></p><nav class=d-xl-none aria-label="Quaternary navigation"><div class=d-xl-none><button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#onThisPage aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>On this page</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button><div class=collapse id=onThisPage><div class="card card-body mt-3 py-1"><div class=page-links><nav id=TableOfContents><ul><li><a href=#file-formats>File Formats</a><ul><li><a href=#vector-graphics>Vector Graphics</a></li><li><a href=#raster-graphics>Raster Graphics</a></li><li><a href=#video>Video</a></li><li><a href=#processing-images>Processing Images</a></li></ul></li><li><a href=#images-in-of>Images in OF</a><ul><li><a href=#the-data-folder>The <code>data</code> Folder</a></li><li><a href=#ofimage><code>ofImage</code></a></li></ul></li><li><a href=#image-attributes>Image Attributes</a><ul><li><a href=#pixel-access>Pixel Access</a></li><li><a href=#image-format>Image Format</a></li><li><a href=#pixel-format>Pixel Format</a></li></ul></li></ul></nav></div></div></div></div><div class="page-links d-none d-xl-block"><h3>On this page</h3><nav id=TableOfContents><ul><li><a href=#file-formats>File Formats</a><ul><li><a href=#vector-graphics>Vector Graphics</a></li><li><a href=#raster-graphics>Raster Graphics</a></li><li><a href=#video>Video</a></li><li><a href=#processing-images>Processing Images</a></li></ul></li><li><a href=#images-in-of>Images in OF</a><ul><li><a href=#the-data-folder>The <code>data</code> Folder</a></li><li><a href=#ofimage><code>ofImage</code></a></li></ul></li><li><a href=#image-attributes>Image Attributes</a><ul><li><a href=#pixel-access>Pixel Access</a></li><li><a href=#image-format>Image Format</a></li><li><a href=#pixel-format>Pixel Format</a></li></ul></li></ul></nav></div></nav><h2 id=file-formats>File Formats <a href=#file-formats class=anchor aria-hidden=true>#</a></h2><p>Digital images come in a variety of formats, each with their own properties.</p><h3 id=vector-graphics>Vector Graphics <a href=#vector-graphics class=anchor aria-hidden=true>#</a></h3><p><em>Vector</em> formats define a set of points and instructions on how to draw them. The instructions are run by a program to raster the image in order to view it.</p><p>Some of the more common vector formats are <code>SVG</code>, <code>EPS</code>, <code>PDF</code>, and <code>AI</code>.</p><p>If we open the following <code>SVG</code> file in a text editor, we will notice that it is fairly easy to read the format. It almost reads like a Processing program 😉</p><figure style='display:block;margin:1em auto'><img style='display:block;margin:0 auto' src=shapes.svg alt="Shapes SVG"></figure><pre><code class=language-svg>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;
&lt;svg
   ...
   height=&quot;512&quot;
   width=&quot;512&quot;&gt;
  ...
  &lt;g
     transform=&quot;translate(0,-161.53332)&quot;
     id=&quot;layer1&quot;&gt;
    &lt;circle
       style=&quot;stroke-width:0.26458332;fill:#00ffff;fill-opacity:1&quot;
       r=&quot;52.916664&quot;
       cy=&quot;229.26665&quot;
       cx=&quot;67.73333&quot;
       id=&quot;path3713&quot; /&gt;
    &lt;rect
       y=&quot;228.20831&quot;
       x=&quot;5.2916665&quot;
       height=&quot;63.5&quot;
       width=&quot;63.5&quot;
       id=&quot;rect4520&quot;
       style=&quot;fill:#ff0000;fill-opacity:1;stroke-width:0.25843021&quot; /&gt;
    &lt;path
       id=&quot;path4524&quot;
       d=&quot;M 49.514879,171.88985 123.5982,282.2589 Z&quot;
       style=&quot;fill:none;stroke:#00b400;stroke-width:2.64583325;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1&quot; /&gt;
  &lt;/g&gt;
&lt;/svg&gt;
</code></pre><p>Pros:</p><ul><li>Small file sizes, because minimal information is being stored.</li><li>Images can be scaled up without any quality loss or increase in file size. This is because the instruction set does not change, the only thing that changes is the point values.</li></ul><p>Cons:</p><ul><li>Low level of detail.</li><li>Limited types of effects, because we don&rsquo;t have all the image data available in the format.</li></ul><h3 id=raster-graphics>Raster Graphics <a href=#raster-graphics class=anchor aria-hidden=true>#</a></h3><p><em>Raster</em> formats define pixel values in a rectangular grid of pixels. The bigger the image, the greater the data set, and thus the larger the file size.</p><p>Some of the more common vector formats are <code>JPG</code>, <code>PNG</code>, <code>GIF</code>, and <code>TIF</code>.</p><figure style='display:block;margin:1em auto'><img style='display:block;margin:0 auto' src=shapes.png alt="Shapes PNG"></figure><p>Pros:</p><ul><li>High quality and detail, especially at high resolutions.</li><li>More advanced image effects, because every pixel can be edited.</li></ul><p>Cons:</p><ul><li>File sizes tend to be bigger.</li><li>Images lose quality when scaled up.</li></ul><p>In order not to end up with huge file sizes, many raster formats are compressed. Some compression methods are <em>lossy</em>, meaning that some of the data is lost when it is compressed, and others are <em>lossless</em>, meaning that all the data is recovered once the data is uncompressed.</p><h3 id=video>Video <a href=#video class=anchor aria-hidden=true>#</a></h3><p>Videos are just a series of images that need to be processed and displayed very quickly.</p><p>Video formats are always rasters and are mostly compressed.</p><ul><li>Some formats are simply extensions of their image counterparts, like <code>Motion JPG</code> for example, which is just a series of <code>JPG</code>-compressed frames.</li><li>Others are specific to video, like <code>H.264</code>, which has a form of compression over time, where some pixels are predicted based on known pixels in previous and future key frames. This is called <em>temporal compression</em>.</li></ul><p>Efficient compression is necessary for video because of the huge amount of data that it carries. While film used to run at 24 frames per second, high definition video now runs standard at 60 frames per second, and sometimes goes as high as 240 fps! Combining these fast frame rates with large resolutions like 4K means that hundreds of millions of pixels need to be processed every second for a video to play smoothly.</p><h3 id=processing-images>Processing Images <a href=#processing-images class=anchor aria-hidden=true>#</a></h3><p>When working with image data, we will usually want to work with rasterized uncompressed images. This is because many algorithms require looping efficiently through all pixels in an image, or doing quick look-ups between neighboring pixels.</p><p>The good news is that this usually happens in the image loader or video codec, before an image or video frame gets to us. For example in OF, FreeImage will automatically decompress <code>JPG</code> or <code>PNG</code> images and provide us the &ldquo;final&rdquo; pixels in the frame.</p><p>While we will almost never have to worry about decoding an image or a video frame ourselves, we should still be mindful of what format the data comes in, and make sure that it is suitable for our application.</p><h2 id=images-in-of>Images in OF <a href=#images-in-of class=anchor aria-hidden=true>#</a></h2><h3 id=the-data-folder>The <code>data</code> Folder <a href=#the-data-folder class=anchor aria-hidden=true>#</a></h3><p>The simplest way to access files in an OF app is to include them in the project&rsquo;s <code>data</code> folder. If this looks familiar, it&rsquo;s because this idea is borrowed from Processing. The <code>data</code> folder is located in <code>&lt;project>/bin/data</code> and each project will have its own dedicated <code>data</code> folder.</p><p>If we drop our files in the <code>data</code> folder, they can be accessed in the app without having to figure out the full path on disk where the file is located, which can be very handy.</p><h3 id=ofimage><code>ofImage</code> <a href=#ofimage class=anchor aria-hidden=true>#</a></h3><p><a href=https://openframeworks.cc/documentation/graphics/ofImage/><code>ofImage</code></a> is the general type to use to work with images in openFrameworks. <code>ofImage</code> includes methods to load files from disk, draw images to the screen, access pixel data, etc.</p><p><code>ofImage</code> is a type, which we can create like any other variable type.</p><pre><code class=language-cpp>// ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void draw();

  ofImage dogImg;
};
</code></pre><div class="alert alert-info d-flex" role=alert><div class="flex-shrink-1 alert-icon">✌️</div><div class=w-100><p><strong>Declaring variables in the header file</strong></p><p>Variables we want to use in any method (function) of our class should be declared in the header. This means that they are in the entire class&rsquo; <em>scope</em>.</p><p>If we declare a variable inside one of our methods like <code>ofApp::setup()</code> or <code>ofApp::draw()</code>, that variable will only be part of that specifc method&rsquo;s scope, and will not be accessible outside of it.</p></div></div><p>We will load an image named <a href=dog-grass.jpg><code>dog-grass.jpg</code></a> from our <code>data</code> folder in the <code>ofApp::setup()</code> function. We only need to load the image into memory once, so we do it when the app starts up.</p><p>We want to draw the image every frame, so we will do that in the <code>ofApp::draw()</code> function.</p><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  dogImg.load(&quot;dog-grass.jpg&quot;);
}

void ofApp::draw()
{
  dogImg.draw(0, 0);
}
</code></pre><div class="alert alert-info d-flex" role=alert><div class="flex-shrink-1 alert-icon">✌️</div><div class=w-100><p><strong>What happened to the other built-in ofApp methods?</strong></p><p>In this specific example, we are not using most of the <code>ofApp</code> placeholder methods like <code>ofApp::update()</code>, <code>ofApp::keyPressed()</code>, <code>ofApp::mouseMoved()</code>, etc. We can remove them from our class if we will not be using them, and this will increase readability because the code will not be filled with stub functions.</p><p>However, note that the method needs to be removed from both the header <code>.h</code> and the implementation <code>.cpp</code> files or else the compiler will assume something is missing and will throw an error.</p></div></div><p>If we navigate under the hood and see what <code>ofImage.load()</code> is actually doing, we see that it calls many functions from the <code>FreeImage</code> library to determine the file&rsquo;s format, uncompress the data, and load it into values for each pixel.</p><h2 id=image-attributes>Image Attributes <a href=#image-attributes class=anchor aria-hidden=true>#</a></h2><p>An image data structure usually comprises of:</p><ul><li>a size (a width and height)</li><li>a pixel format</li><li>a value for each pixel</li></ul><p>This looks a lot like the arrays we have been exploring in the previous section. This makes arrays great options to represent image data in a computer program.</p><p>Even though an image has two dimensions (a width and a height), the pixel array is usually one-dimensional, packing the rows one after the other in sequence.</p><figure style='display:block;margin:1em auto'><img style='display:block;margin:0 auto' src=grid-pix.png alt="Grid Pixels"></figure><p>Some frameworks allow accessing pixels using the column <code>x</code> and row <code>y</code>, like <a href=https://www.processing.org/reference/PImage_get_.html><code>PImage.get()</code></a> in Processing and <a href=https://openframeworks.cc//documentation/graphics/ofImage/#!show_getColor><code>ofImage.getColor()</code></a> in openFrameworks. These convenience functions are very useful as they take care of figuring out all the index arithmetic for us.</p><p>The following example reads the value of a pixel under the mouse cursor.</p><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  // Load the dog image.
  dogImg.load(&quot;dog-grass.jpg&quot;);

  // Set the window size to match the image.
  ofSetWindowShape(dogImg.getWidth(), dogImg.getHeight());
}

void ofApp::draw()
{
  // Draw the image as the background.
  ofSetColor(255);
  dogImg.draw(0, 0);

  // Get a reference to the image pixels.
  ofPixels dogPix = dogImg.getPixels();
  // Get the color value under the mouse.
  ofColor color = dogPix.getColor(mouseX, mouseY);

  // Draw a rectangle under the mouse using the pixel color.
  ofFill();
  ofSetColor(color);
  ofDrawRectangle(mouseX - 25, mouseY - 25, 50, 50);
  // Add an outline so we can see the rectangle better.
  ofNoFill();
  ofSetColor(0);
  ofDrawRectangle(mouseX - 25, mouseY - 25, 50, 50);
}
</code></pre><ul><li><a href=https://openframeworks.cc/documentation/application/ofAppRunner/#show_ofSetWindowShape><code>ofSetWindowShape()</code></a> resizes the window to the size of the loaded image. Note that this function can be called any time while the app is running, and can override the starting window dimensions that are set in <code>main.cpp</code>.</li><li><a href=https://openframeworks.cc/documentation/graphics/ofImage/#!show_getPixels><code>ofImage.getPixels()</code></a> returns an <a href=https://openframeworks.cc/documentation/graphics/ofPixels/><code>ofPixels</code></a> object containing the pixel color values. <code>ofPixels</code> is a class backed by an array, with helper methods to access the data it contains.</li><li><a href=https://openframeworks.cc/documentation/graphics/ofPixels/#show_getColor><code>ofPixels.getColor()</code></a> is one of these helper methods, which returns an <a href=https://openframeworks.cc/documentation/types/ofColor/><code>ofColor</code></a> value at a specified column and row index. <code>ofColor</code> is a data structure used to access the different channels that make up a color value.</li></ul><h3 id=pixel-access>Pixel Access <a href=#pixel-access class=anchor aria-hidden=true>#</a></h3><p>A standard color pixel will have 3 color channels: red, green, and blue (<code>RGB</code>). While Processing packs all channels into a single <code>int</code>, this is not common practice.</p><p>The color values are usually packed <em>sequentially</em> in the array. Instead of each pixel holding a single value, it will hold 3.</p><figure style='display:block;margin:1em auto'><img style='display:block;margin:0 auto' src=grid-rgb.png alt="Grid RGB"></figure><p>The pixel array then has total size:</p><pre><code class=language-cpp>size = width * height * channels
</code></pre><p>In order to access the pixel in a 1D array using a 2D index, we first need to convert it.</p><pre><code class=language-cpp>index = y * width + x
</code></pre><p>How do we access a pixel index in an <code>RGB</code> image?</p><p>Because each pixel has three color values (for each <code>RGB</code> channel), we need to multiply our pixel index by <code>3</code> to take that offset into account.</p><pre><code class=language-cpp>pixel = y * width + x

index = pixel * 3
index = (y * width + x) * 3
</code></pre><details><summary><code>ofPixels.getColor()</code> can also accept a single argument for the index (instead of two arguments for the column and row). How can we modify the previous example to use the single index version of <code>getColor()</code>?</summary><p>We can use the formula above to convert our column and row to an index value in the color array.</p><pre><code class=language-cpp>// ofApp.cpp

// ...

void ofApp::draw()
{
  // ...

  // Get a reference to the image pixels.
  ofPixels dogPix = dogImg.getPixels();
  // Get the color value under the mouse.
  //ofColor color = dogPix.getColor(mouseX, mouseY);
  int index = (mouseY * dogPix.getWidth() + mouseX) * dogPix.getNumChannels();
  ofColor color = dogPix.getColor(index);

  // ...
}
</code></pre><p>Note the use of <a href=https://openframeworks.cc//documentation/graphics/ofPixels/#!show_getNumChannels><code>ofPixels.getNumChannels()</code></a> instead of the literal <code>3</code>. This ensures the code will work with all image types and not just RGB images.</p></details><p>Conversely, if we want to get a 2D value from a 1D index, we can use integer division:</p><pre><code class=language-cpp>x = index % width
y = index / width
</code></pre><p>The following example reads the value of a pixel sequentially, based on the sketch frame number.</p><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
    // Load the dog image.
    dogImg.load(&quot;dog-grass.jpg&quot;);

    // Set the window size to match the image.
    ofSetWindowShape(dogImg.getWidth(), dogImg.getHeight());
}

void ofApp::draw()
{
  // Draw the image as the background.
  ofSetColor(255);
  dogImg.draw(0, 0);

  // Cache the image dimensions in variables for easy access.
  int imgWidth = dogImg.getWidth();
  int imgHeight = dogImg.getHeight();

  // Use the modulo operator to make sure the frame index is never 
  // greater than the max number of pixels in the image.
  int frameIndex = ofGetFrameNum() % (imgWidth * imgHeight);
  int x = frameIndex % imgWidth;
  int y = frameIndex / imgWidth;

  // Get a reference to the image pixels.
  ofPixels dogPix = dogImg.getPixels();
  // Get the color value for this frame.
  int pixelIndex = frameIndex * dogPix.getNumChannels();
  ofColor color = dogPix.getColor(pixelIndex);

  // Draw a rectangle under the mouse using the pixel color.
  ofFill();
  ofSetColor(color);
  ofDrawRectangle(x - 25, y - 25, 50, 50);
  // Add an outline so we can see the rectangle better.
  ofNoFill();
  ofSetColor(0);
  ofDrawRectangle(x - 25, y - 25, 50, 50);
}
</code></pre><h3 id=image-format>Image Format <a href=#image-format class=anchor aria-hidden=true>#</a></h3><p>The most common image type we will work with is <code>RGB</code> color images.</p><p>We will also work with single-channel formats, usually called grayscale or luminance. These are particularly handy for devices that only capture a brightness level, like infrared cameras or depth sensors.</p><p>Some images also have an alpha channel for transparency, like <code>RGBA</code>. Our example image happens to have transparency, but we will encounter this rarely in this class as most sensors do not use the alpha channel.</p><p>Another format worth mentioning is <a href=https://en.wikipedia.org/wiki/YUV><code>YUV</code></a>, which is a color encoding that is based on the range of human perception. Instead of using three channels for color, it uses one for brightness and two for color shift. This gives similar results to <code>RGB</code> but at much smaller sizes (usually a third), and this is why <code>YUV</code> formats are often used for webcam streams.</p><h3 id=pixel-format>Pixel Format <a href=#pixel-format class=anchor aria-hidden=true>#</a></h3><p>Pixel color values can be stored in a few different formats. The more bits a format can hold, the more range the values can have, and the larger the size of the frame gets.</p><ul><li><code>unsigned char</code> is the most common format. It uses integers and each channel has 8 bits of data and values range from <code>0</code> to <code>255</code>.</li><li><code>float</code> uses floating point 32 bit data. The usual range is from <code>0.0</code> to <code>1.0</code> but this format can be used for <a href=https://en.wikipedia.org/wiki/High-dynamic-range_imaging>HDR</a> effects, where the values can extend past <code>1.0</code> or for storing non-color data, where we can even use negative values. We will use <code>float</code> when working with depth sensors and when storing non-color data inside our pixels.</li><li><code>unsigned short</code> is another integer format but with 16 bits of data, meaning values range from <code>0</code> to <code>65535</code>. We will also use this format when working with depth sensors, where precision is very important and we need more than the <code>256</code> distinct values that we get from <code>unsigned char</code>.</li></ul><p>The following example demonstrates how to access the pixel array data directly, using <a href=https://openframeworks.cc/documentation/graphics/ofPixels/#show_getData><code>ofPixels.getData()</code></a>.</p><p>This is a bit more complicated, and may not be necessary in most applications. However, it tends to be the fastest way to manipulate pixel values and is the recommended approach when having to process large images pixel by pixel.</p><pre><code class=language-cpp>// ofApp.cpp

// ...

void ofApp::draw()
{
  // ...

  // Get a reference to the image pixels.
  unsigned char* dogData = dogImg.getPixels().getData();
  // Get the color value for this frame.
  int numChannels = dogImg.getPixels().getNumChannels();
  int pixelIndex = mouseY * dogImg.getWidth() + mouseX;
  ofColor color = ofColor(
    dogData[pixelIndex * numChannels + 0], // R
    dogData[pixelIndex * numChannels + 1], // G
    dogData[pixelIndex * numChannels + 2]  // B
  );

  // ...
}
</code></pre><div class="alert alert-info d-flex" role=alert><div class="flex-shrink-1 alert-icon">✌️</div><div class=w-100><p><strong>What does the <code>*</code> after <code>unsigned char</code> mean?</strong></p><p>The <code>*</code> represents something called a <em>pointer</em>. Pointers are a complex topic that we will cover in depth later in the course, but for now just think of them as representing arrays with a variable size (or arrays with a size we do not know at compile time).</p><p>The code above needs to work for any image of any size, so we cannot assume that the <code>unsigned char</code> array will have a specific number of elements in it. Using <code>unsigned char*</code> tells the compiler that the array size will be dynamically allocated when it is created.</p></div></div><div class="page-footer-meta d-flex flex-column flex-md-row justify-content-between"></div><div class="docs-navigation d-flex justify-content-between"><a href=https://seeingmachines.betamovement.net/docs/class-1/variables-and-arrays/><div class="card my-1"><div class="card-body py-2">&larr; Variables and Arrays</div></div></a><a class=ms-auto href=https://seeingmachines.betamovement.net/docs/assignments/assignment-3/><div class="card my-1"><div class="card-body py-2">Assignment 3 &rarr;</div></div></a></div></main></div></div></div><footer class="footer text-muted"><div class=container-xxl><div class=row><div class="col-lg-8 order-last order-lg-first"><ul class=list-inline><li class=list-inline-item>Powered by <a class=text-muted href=https://github.com/>GitHub</a>, <a class=text-muted href=https://gohugo.io/>Hugo</a>, and <a class=text-muted href=https://getdoks.org/>Doks</a></li></ul></div><div class="col-lg-8 order-first order-lg-last text-lg-end"><ul class=list-inline></ul></div></div></div></footer><script src=https://seeingmachines.betamovement.net/js/bootstrap.min.6cdb76625316a021e696f0641e0948e88df021948825dbf90228403664b1691ff7a291ac9d485a8da13b1cc8b9d543ba6dce6702692ff979943a02038ffbd52e.js integrity="sha512-bNt2YlMWoCHmlvBkHglI6I3wIZSIJdv5AihANmSxaR/3opGsnUhajaE7HMi51UO6bc5nAmkv+XmUOgIDj/vVLg==" crossorigin=anonymous defer></script>
<script src=https://seeingmachines.betamovement.net/js/highlight.min.93c197e7097c47fc0788b21721b3c308e18e43299f1e45e8ff2697d13cd62908cc5949a053c1fb7242d7b4a60eb07bd106061252f7aa925ef7e91033ea59d9b9.js integrity="sha512-k8GX5wl8R/wHiLIXIbPDCOGOQymfHkXo/yaX0TzWKQjMWUmgU8H7ckLXtKYOsHvRBgYSUveqkl736RAz6lnZuQ==" crossorigin=anonymous defer></script>
<script src=https://seeingmachines.betamovement.net/main.min.162c56a0426544de0d010e66c56e321579655c400c9aae06a6823e7682de379adadf2165bd416fea191e4e7e410fbf1fd2c35a759aa43ff2e3787067669bf81b.js integrity="sha512-FixWoEJlRN4NAQ5mxW4yFXllXEAMmq4GpoI+doLeN5ra3yFlvUFv6hkeTn5BD78f0sNadZqkP/LjeHBnZpv4Gw==" crossorigin=anonymous defer></script>
<script src=https://seeingmachines.betamovement.net/index.min.b7c8621be91b0fa3a950184f6f008eebbc8d6c25dbe1b0d18a21ad0e0dfa496e1e53afc81de6dddd2d8548ec4f3ff600e6ae85b30c38c9daaa348f2ab5d6b459.js integrity="sha512-t8hiG+kbD6OpUBhPbwCO67yNbCXb4bDRiiGtDg36SW4eU6/IHebd3S2FSOxPP/YA5q6Fsww4ydqqNI8qtda0WQ==" crossorigin=anonymous defer></script></body></html>