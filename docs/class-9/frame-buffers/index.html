<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=preload as=font href=https://seeingmachines.betamovement.net/fonts/vendor/jost/jost-v4-latin-regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://seeingmachines.betamovement.net/fonts/vendor/jost/jost-v4-latin-500.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://seeingmachines.betamovement.net/fonts/vendor/jost/jost-v4-latin-700.woff2 type=font/woff2 crossorigin><script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script><link rel=stylesheet href=https://seeingmachines.betamovement.net/main.42fe22dfe022cc0fba3cb6f20f694a40a705e406951e7b127a5e079472bea667f273069c4efd2734ed2815f651a67b23df404c97418ea6c6b1c0b74114bac9c5.css integrity="sha512-Qv4i3+AizA+6PLbyD2lKQKcF5AaVHnsSel4HlHK+pmfycwacTv0nNO0oFfZRpnsj30BMl0GOpsaxwLdBFLrJxQ==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>Frame Buffers - Seeing Machines</title><meta name=description content="When we draw something in OF, whether it&amp;rsquo;s a circle or an image or a 3D shape, it gets drawn to the screen by default. But we don&amp;rsquo;t need to necessarily draw to the screen; we can also draw to an offscreen location called a framebuffer.
A framebuffer object (or FBO) is a simple OpenGL object that lives in graphics memory that we can draw into. We can think of it as a &amp;ldquo;virtual window&amp;rdquo;; anything we can draw on screen we can draw inside this window."><link rel=canonical href=https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="Frame Buffers"><meta property="og:description" content="When we draw something in OF, whether it&rsquo;s a circle or an image or a 3D shape, it gets drawn to the screen by default. But we don&rsquo;t need to necessarily draw to the screen; we can also draw to an offscreen location called a framebuffer.
A framebuffer object (or FBO) is a simple OpenGL object that lives in graphics memory that we can draw into. We can think of it as a &ldquo;virtual window&rdquo;; anything we can draw on screen we can draw inside this window."><meta property="og:url" content="https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/"><meta property="og:site_name" content="Seeing Machines"><meta property="article:published_time" content="2022-11-13T09:51:58-05:00"><meta property="article:modified_time" content="2022-11-13T09:51:58-05:00"><meta property="og:image" content="https://seeingmachines.betamovement.net/default-image.png"><meta property="og:image:alt" content="Seeing Machines"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content><meta name=twitter:creator content="@prisonerjohn"><meta name=twitter:title content="Frame Buffers"><meta name=twitter:description content><meta name=twitter:image content="https://seeingmachines.betamovement.net/default-image.png"><meta name=twitter:image:alt content="Frame Buffers"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://seeingmachines.betamovement.net/#/schema/person/1","name":"Seeing Machines","url":"https://seeingmachines.betamovement.net/","sameAs":[],"image":{"@type":"ImageObject","@id":"https://seeingmachines.betamovement.net/#/schema/image/1","url":"https://seeingmachines.betamovement.net/default-image.png","width":1024,"height":768,"caption":"Seeing Machines"}},{"@type":"WebSite","@id":"https://seeingmachines.betamovement.net/#/schema/website/1","url":"https://seeingmachines.betamovement.net/","name":"Seeing Machines","description":"A programming course where weâ€™ll explore various techniques and solutions for tracking and sensing people or objects in space.","publisher":{"@id":"https://seeingmachines.betamovement.net/#/schema/person/1"}},{"@type":"WebPage","@id":"https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/","url":"https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/","name":"Frame Buffers","description":"","isPartOf":{"@id":"https://seeingmachines.betamovement.net/#/schema/website/1"},"about":{"@id":"https://seeingmachines.betamovement.net/#/schema/person/1"},"datePublished":"2022-11-13T09:51:58CET","dateModified":"2022-11-13T09:51:58CET","breadcrumb":{"@id":"https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/#/schema/breadcrumb/1"},"primaryImageOfPage":{"@id":"https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/#/schema/image/2"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/"]}]},{"@type":"BreadcrumbList","@id":"https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/#/schema/breadcrumb/1","name":"Breadcrumbs","itemListElement":[{"@type":"ListItem","position":1,"item":{"@type":"WebPage","@id":"https://seeingmachines.betamovement.net/","url":"https://seeingmachines.betamovement.net/","name":"Home"}},{"@type":"ListItem","position":2,"item":{"@type":"WebPage","@id":"https://seeingmachines.betamovement.net/docs/","url":"https://seeingmachines.betamovement.net/docs/","name":"Docs"}},{"@type":"ListItem","position":3,"item":{"@type":"WebPage","@id":"https://seeingmachines.betamovement.net/docs/class-9/","url":"https://seeingmachines.betamovement.net/docs/class-9/","name":"Class 9"}},{"@type":"ListItem","position":4,"item":{"@id":"https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Article","@id":"https://seeingmachines.betamovement.net/#/schema/article/1","headline":"Frame Buffers","description":"","isPartOf":{"@id":"https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/"},"mainEntityOfPage":{"@id":"https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/"},"datePublished":"2022-11-13T09:51:58CET","dateModified":"2022-11-13T09:51:58CET","author":{"@id":"https://seeingmachines.betamovement.net/#/schema/person/2"},"publisher":{"@id":"https://seeingmachines.betamovement.net/#/schema/person/1"},"image":{"@id":"https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/#/schema/image/2"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://seeingmachines.betamovement.net/#/schema/person/2","name":"Elie Zananiri","sameAs":["https://twitter.com/prisonerjohn","https://www.linkedin.com/in/prisonerjohn/","https://github.com/prisonerjohn"]}]},{"@context":"https://schema.org","@graph":[{"@type":"ImageObject","@id":"https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/#/schema/image/2","url":"https://seeingmachines.betamovement.net/default-image.png","contentUrl":"https://seeingmachines.betamovement.net/default-image.png","caption":"Frame Buffers"}]}]}</script><meta name=theme-color content="#fff"><link rel=icon href=https://seeingmachines.betamovement.net/favicon.ico sizes=any><link rel=icon type=image/svg+xml href=https://seeingmachines.betamovement.net/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=https://seeingmachines.betamovement.net/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://seeingmachines.betamovement.net/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://seeingmachines.betamovement.net/favicon-16x16.png><link rel=manifest crossorigin=use-credentials href=https://seeingmachines.betamovement.net/site.webmanifest></head><body class="docs single"><div class=sticky-top><div class=header-bar></div><header class="navbar navbar-expand-lg navbar-light doks-navbar"><nav class="container-xxl flex-wrap flex-lg-nowrap" aria-label="Main navigation"><a class="navbar-brand order-0" href=https://seeingmachines.betamovement.net/ aria-label="Seeing Machines">Seeing Machines</a>
<button class="btn btn-link order-0 ms-auto d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasExample aria-controls=offcanvasExample><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-more-horizontal"><circle cx="12" cy="12" r="1"/><circle cx="19" cy="12" r="1"/><circle cx="5" cy="12" r="1"/></svg></button><div class="offcanvas offcanvas-start d-lg-none" tabindex=-1 id=offcanvasExample aria-labelledby=offcanvasExampleLabel><div class=header-bar></div><div class=offcanvas-header><h5 class=offcanvas-title id=offcanvasExampleLabel>Browse docs</h5><button type=button class=btn-close data-bs-dismiss=offcanvas aria-label=Close></button></div><div class=offcanvas-body><aside class="doks-sidebar mt-n3"><nav id=doks-docs-nav aria-label="Tertiary navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-5f2cae171c6192fa410df4385f7218aa aria-expanded=false>
Prologue</button><div class=collapse id=section-5f2cae171c6192fa410df4385f7218aa><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-0/getting-started/>Getting Started</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e43c4a6cb52ad623673f8e77a5b10104 aria-expanded=false>
Class 1</button><div class=collapse id=section-e43c4a6cb52ad623673f8e77a5b10104><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/foreword/>Foreword</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/intro-to-of/>Intro to OF</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-2ef5a7f02774e1be242988dba4c3056c aria-expanded=false>
Class 2</button><div class=collapse id=section-2ef5a7f02774e1be242988dba4c3056c><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/data-types/>Data Types</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/arrays/>Arrays</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/images-and-video/>Images and Video</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-6a3be28bcd9707b6b8ff8ac55a6b8cb2 aria-expanded=false>
Class 3</button><div class=collapse id=section-6a3be28bcd9707b6b8ff8ac55a6b8cb2><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-3/computer-vision/>Computer Vision</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e01cc216a97c1db953e2304e6aa8998a aria-expanded=false>
Class 4</button><div class=collapse id=section-e01cc216a97c1db953e2304e6aa8998a><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/intro-to-opencv/>Intro to OpenCV</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/object-tracking/>Object Tracking</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-cb8d2462ebd86364c3502e7084b7f391 aria-expanded=false>
Class 5</button><div class=collapse id=section-cb8d2462ebd86364c3502e7084b7f391><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/logging/>Logging</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/depth-sensing/>Depth Sensing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c5400dee9e161c6d7e46af7661005794 aria-expanded=false>
Class 6</button><div class=collapse id=section-c5400dee9e161c6d7e46af7661005794><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/pointers/>Pointers</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/depth-images/>Depth Images</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ff9150b580f893ddadd43394cb6173a3 aria-expanded=false>
Class 7</button><div class=collapse id=section-ff9150b580f893ddadd43394cb6173a3><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/3d-primer/>3D Primer</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/depth-world/>Depth World</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c28d8545333b2785a226d11aa3b3b4ed aria-expanded=false>
Class 8</button><div class=collapse id=section-c28d8545333b2785a226d11aa3b3b4ed><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/networking/>Networking</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/texture-sharing/>Texture Sharing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-0bbdd9311c2cb50588b0a462a5438610 aria-expanded=true>
Class 9</button><div class="collapse show" id=section-0bbdd9311c2cb50588b0a462a5438610><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-9/draw-bounds/>Draw Bounds</a></li><li><a class="docs-link rounded active" href=https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/>Frame Buffers</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c75af093fd3f2e096e4fe21c7e51e7c7 aria-expanded=false>
Class 10</button><div class=collapse id=section-c75af093fd3f2e096e4fe21c7e51e7c7><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/classes/>Classes</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/mapping/>Mapping</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ddbaeabfbe390c84589d5d1c423b9284 aria-expanded=false>
Class 11</button><div class=collapse id=section-ddbaeabfbe390c84589d5d1c423b9284><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-11/machine-learning/>Machine Learning</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-960119d951e6b24e70eaf82d456d181f aria-expanded=false>
Class 12</button><div class=collapse id=section-960119d951e6b24e70eaf82d456d181f><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-12/mobile-development/>Mobile Development</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-37c0442fba31d7a7923dce6846a60711 aria-expanded=false>
Class 13</button><div class=collapse id=section-37c0442fba31d7a7923dce6846a60711><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-13/sound/>Sound</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-56c4b82e7a8861de86a5ebe5eaa62225 aria-expanded=false>
Assignments</button><div class=collapse id=section-56c4b82e7a8861de86a5ebe5eaa62225><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-1/>Assignment 1</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-2/>Assignment 2</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-3/>Assignment 3</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-4/>Assignment 4</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/final-project/>Final Project</a></li></ul></div></li></ul></nav></aside></div></div><button class="btn btn-menu order-2 d-block d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasDoks aria-controls=offcanvasDoks aria-label="Open main menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><div class="offcanvas offcanvas-end border-0 py-lg-1" tabindex=-1 id=offcanvasDoks data-bs-backdrop=true aria-labelledby=offcanvasDoksLabel><div class="header-bar d-lg-none"></div><div class="offcanvas-header d-lg-none"><h2 class="h5 offcanvas-title ps-2" id=offcanvasDoksLabel><a class=text-dark href=https://seeingmachines.betamovement.net/>Seeing Machines</a></h2><button type=button class="btn-close text-reset me-2" data-bs-dismiss=offcanvas aria-label="Close main menu"></button></div><div class="offcanvas-body p-4 p-lg-0"><ul class="nav flex-column flex-lg-row align-items-lg-center mt-2 mt-lg-0 ms-lg-2 me-lg-auto"><li class=nav-item><a class="nav-link ps-0 py-1 active" href=https://seeingmachines.betamovement.net/docs>Docs</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=https://seeingmachines.betamovement.net/docs/assignments>Assignments</a></li></ul><hr class="text-black-50 my-4 d-lg-none"><form class="doks-search position-relative flex-grow-1 ms-lg-auto me-lg-2"><input id=search class="form-control is-search" type=search placeholder="Search docs..." aria-label="Search docs..." autocomplete=off><div id=suggestions class="shadow bg-white rounded d-none"></div></form><hr class="text-black-50 my-4 d-lg-none"><ul class="nav flex-column flex-lg-row"><li class=nav-item><a class="nav-link social-link" href=https://github.com/prisonerjohn/seeing-machines><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg><small class="ms-2 d-lg-none">GitHub</small></a></li><li class=nav-item><a class="nav-link social-link" href=https://twitter.com/prisonerjohn><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-twitter"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg><small class="ms-2 d-lg-none">Twitter</small></a></li></ul><hr class="text-black-50 my-4 d-lg-none"><button id=mode class="btn btn-link" type=button aria-label="Toggle user interface mode">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></div></div></nav></header></div><div class=container-xxl><aside class=doks-sidebar><nav id=doks-docs-nav class="collapse d-lg-none" aria-label="Tertiary navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-5f2cae171c6192fa410df4385f7218aa aria-expanded=false>
Prologue</button><div class=collapse id=section-5f2cae171c6192fa410df4385f7218aa><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-0/getting-started/>Getting Started</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e43c4a6cb52ad623673f8e77a5b10104 aria-expanded=false>
Class 1</button><div class=collapse id=section-e43c4a6cb52ad623673f8e77a5b10104><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/foreword/>Foreword</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/intro-to-of/>Intro to OF</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-2ef5a7f02774e1be242988dba4c3056c aria-expanded=false>
Class 2</button><div class=collapse id=section-2ef5a7f02774e1be242988dba4c3056c><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/data-types/>Data Types</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/arrays/>Arrays</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/images-and-video/>Images and Video</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-6a3be28bcd9707b6b8ff8ac55a6b8cb2 aria-expanded=false>
Class 3</button><div class=collapse id=section-6a3be28bcd9707b6b8ff8ac55a6b8cb2><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-3/computer-vision/>Computer Vision</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e01cc216a97c1db953e2304e6aa8998a aria-expanded=false>
Class 4</button><div class=collapse id=section-e01cc216a97c1db953e2304e6aa8998a><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/intro-to-opencv/>Intro to OpenCV</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/object-tracking/>Object Tracking</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-cb8d2462ebd86364c3502e7084b7f391 aria-expanded=false>
Class 5</button><div class=collapse id=section-cb8d2462ebd86364c3502e7084b7f391><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/logging/>Logging</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/depth-sensing/>Depth Sensing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c5400dee9e161c6d7e46af7661005794 aria-expanded=false>
Class 6</button><div class=collapse id=section-c5400dee9e161c6d7e46af7661005794><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/pointers/>Pointers</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/depth-images/>Depth Images</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ff9150b580f893ddadd43394cb6173a3 aria-expanded=false>
Class 7</button><div class=collapse id=section-ff9150b580f893ddadd43394cb6173a3><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/3d-primer/>3D Primer</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/depth-world/>Depth World</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c28d8545333b2785a226d11aa3b3b4ed aria-expanded=false>
Class 8</button><div class=collapse id=section-c28d8545333b2785a226d11aa3b3b4ed><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/networking/>Networking</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/texture-sharing/>Texture Sharing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-0bbdd9311c2cb50588b0a462a5438610 aria-expanded=true>
Class 9</button><div class="collapse show" id=section-0bbdd9311c2cb50588b0a462a5438610><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-9/draw-bounds/>Draw Bounds</a></li><li><a class="docs-link rounded active" href=https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/>Frame Buffers</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c75af093fd3f2e096e4fe21c7e51e7c7 aria-expanded=false>
Class 10</button><div class=collapse id=section-c75af093fd3f2e096e4fe21c7e51e7c7><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/classes/>Classes</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/mapping/>Mapping</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ddbaeabfbe390c84589d5d1c423b9284 aria-expanded=false>
Class 11</button><div class=collapse id=section-ddbaeabfbe390c84589d5d1c423b9284><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-11/machine-learning/>Machine Learning</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-960119d951e6b24e70eaf82d456d181f aria-expanded=false>
Class 12</button><div class=collapse id=section-960119d951e6b24e70eaf82d456d181f><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-12/mobile-development/>Mobile Development</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-37c0442fba31d7a7923dce6846a60711 aria-expanded=false>
Class 13</button><div class=collapse id=section-37c0442fba31d7a7923dce6846a60711><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-13/sound/>Sound</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-56c4b82e7a8861de86a5ebe5eaa62225 aria-expanded=false>
Assignments</button><div class=collapse id=section-56c4b82e7a8861de86a5ebe5eaa62225><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-1/>Assignment 1</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-2/>Assignment 2</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-3/>Assignment 3</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-4/>Assignment 4</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/final-project/>Final Project</a></li></ul></div></li></ul></nav></aside></div><div class="wrap container-xxl" role=document><div class=content><div class="row flex-xl-nowrap"><div class="col-lg-5 col-xl-4 docs-sidebar d-none d-lg-block"><nav class=docs-links aria-label="Main navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-5f2cae171c6192fa410df4385f7218aa aria-expanded=false>
Prologue</button><div class=collapse id=section-5f2cae171c6192fa410df4385f7218aa><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-0/getting-started/>Getting Started</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e43c4a6cb52ad623673f8e77a5b10104 aria-expanded=false>
Class 1</button><div class=collapse id=section-e43c4a6cb52ad623673f8e77a5b10104><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/foreword/>Foreword</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-1/intro-to-of/>Intro to OF</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-2ef5a7f02774e1be242988dba4c3056c aria-expanded=false>
Class 2</button><div class=collapse id=section-2ef5a7f02774e1be242988dba4c3056c><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/data-types/>Data Types</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/arrays/>Arrays</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-2/images-and-video/>Images and Video</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-6a3be28bcd9707b6b8ff8ac55a6b8cb2 aria-expanded=false>
Class 3</button><div class=collapse id=section-6a3be28bcd9707b6b8ff8ac55a6b8cb2><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-3/computer-vision/>Computer Vision</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-e01cc216a97c1db953e2304e6aa8998a aria-expanded=false>
Class 4</button><div class=collapse id=section-e01cc216a97c1db953e2304e6aa8998a><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/intro-to-opencv/>Intro to OpenCV</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-4/object-tracking/>Object Tracking</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-cb8d2462ebd86364c3502e7084b7f391 aria-expanded=false>
Class 5</button><div class=collapse id=section-cb8d2462ebd86364c3502e7084b7f391><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/logging/>Logging</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-5/depth-sensing/>Depth Sensing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c5400dee9e161c6d7e46af7661005794 aria-expanded=false>
Class 6</button><div class=collapse id=section-c5400dee9e161c6d7e46af7661005794><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/pointers/>Pointers</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-6/depth-images/>Depth Images</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ff9150b580f893ddadd43394cb6173a3 aria-expanded=false>
Class 7</button><div class=collapse id=section-ff9150b580f893ddadd43394cb6173a3><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/3d-primer/>3D Primer</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-7/depth-world/>Depth World</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c28d8545333b2785a226d11aa3b3b4ed aria-expanded=false>
Class 8</button><div class=collapse id=section-c28d8545333b2785a226d11aa3b3b4ed><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/networking/>Networking</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-8/texture-sharing/>Texture Sharing</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-0bbdd9311c2cb50588b0a462a5438610 aria-expanded=true>
Class 9</button><div class="collapse show" id=section-0bbdd9311c2cb50588b0a462a5438610><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-9/draw-bounds/>Draw Bounds</a></li><li><a class="docs-link rounded active" href=https://seeingmachines.betamovement.net/docs/class-9/frame-buffers/>Frame Buffers</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-c75af093fd3f2e096e4fe21c7e51e7c7 aria-expanded=false>
Class 10</button><div class=collapse id=section-c75af093fd3f2e096e4fe21c7e51e7c7><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/classes/>Classes</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-10/mapping/>Mapping</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-ddbaeabfbe390c84589d5d1c423b9284 aria-expanded=false>
Class 11</button><div class=collapse id=section-ddbaeabfbe390c84589d5d1c423b9284><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-11/machine-learning/>Machine Learning</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-960119d951e6b24e70eaf82d456d181f aria-expanded=false>
Class 12</button><div class=collapse id=section-960119d951e6b24e70eaf82d456d181f><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-12/mobile-development/>Mobile Development</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-37c0442fba31d7a7923dce6846a60711 aria-expanded=false>
Class 13</button><div class=collapse id=section-37c0442fba31d7a7923dce6846a60711><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/class-13/sound/>Sound</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-56c4b82e7a8861de86a5ebe5eaa62225 aria-expanded=false>
Assignments</button><div class=collapse id=section-56c4b82e7a8861de86a5ebe5eaa62225><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-1/>Assignment 1</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-2/>Assignment 2</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-3/>Assignment 3</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/assignment-4/>Assignment 4</a></li><li><a class="docs-link rounded" href=https://seeingmachines.betamovement.net/docs/assignments/final-project/>Final Project</a></li></ul></div></li></ul></nav></div><nav class="docs-toc d-none d-xl-block col-xl-3" aria-label="Secondary navigation"><div class=d-xl-none><button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#onThisPage aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>On this page</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button><div class=collapse id=onThisPage><div class="card card-body mt-3 py-1"><div class=page-links><nav id=TableOfContents><ul><li><a href=#offbo>ofFbo</a></li><li><a href=#3d>3D</a></li><li><a href=#multi-window>Multi-window</a></li><li><a href=#blending>Blending</a></li></ul></nav></div></div></div></div><div class="page-links d-none d-xl-block"><h3>On this page</h3><nav id=TableOfContents><ul><li><a href=#offbo>ofFbo</a></li><li><a href=#3d>3D</a></li><li><a href=#multi-window>Multi-window</a></li><li><a href=#blending>Blending</a></li></ul></nav></div></nav><main class="docs-content col-lg-11 col-xl-9"><h1>Frame Buffers</h1><p class=lead></p><nav class=d-xl-none aria-label="Quaternary navigation"><div class=d-xl-none><button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#onThisPage aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>On this page</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button><div class=collapse id=onThisPage><div class="card card-body mt-3 py-1"><div class=page-links><nav id=TableOfContents><ul><li><a href=#offbo>ofFbo</a></li><li><a href=#3d>3D</a></li><li><a href=#multi-window>Multi-window</a></li><li><a href=#blending>Blending</a></li></ul></nav></div></div></div></div><div class="page-links d-none d-xl-block"><h3>On this page</h3><nav id=TableOfContents><ul><li><a href=#offbo>ofFbo</a></li><li><a href=#3d>3D</a></li><li><a href=#multi-window>Multi-window</a></li><li><a href=#blending>Blending</a></li></ul></nav></div></nav><p>When we draw something in OF, whether it&rsquo;s a circle or an image or a 3D shape, it gets drawn to the screen by default. But we don&rsquo;t need to necessarily draw to the screen; we can also draw to an offscreen location called a <em>framebuffer</em>.</p><p>A framebuffer object (or FBO) is a simple OpenGL object that lives in graphics memory that we can draw into. We can think of it as a &ldquo;virtual window&rdquo;; anything we can draw on screen we can draw inside this window.</p><h2 id=offbo>ofFbo <a href=#offbo class=anchor aria-hidden=true>#</a></h2><p>In openFrameworks, the <a href=https://openframeworks.cc/documentation/gl/ofFbo/><code>ofFbo</code></a> object is a wrapper around a framebuffer.</p><ul><li>We first need to create the <code>ofFbo</code> using <a href=https://openframeworks.cc/documentation/gl/ofFbo/#show_allocate><code>allocate()</code></a>.</li><li>We can turn it on or off using the <a href=https://openframeworks.cc/documentation/gl/ofFbo/#show_begin><code>begin()</code></a> and <a href=https://openframeworks.cc/documentation/gl/ofFbo/#show_end><code>end()</code></a> functions.<ul><li>Anything we draw between the calls to <code>begin()</code> and <code>end()</code> will be drawn inside that <code>ofFbo</code>.</li></ul></li><li>An <code>ofFbo</code> actually renders to an <code>ofTexture</code>, and we can generally use an <code>ofFbo</code> anywhere we would use a texture.<ul><li>We can draw the FBO directly to the screen using <a href=https://openframeworks.cc/documentation/gl/ofFbo/#show_draw><code>draw()</code></a>.</li><li>We can retrieve the texture using <a href=https://openframeworks.cc/documentation/gl/ofFbo/#show_getTexture><code>getTexture()</code></a>.</li></ul></li></ul><pre><code class=language-cpp>// ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void update();
  void draw();

  void keyPressed(int key);

  ofFbo canvasFbo;

  ofParameter&lt;ofColor&gt; tintColor;
  ofParameter&lt;bool&gt; clearFbo;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  ofSetWindowShape(640, 720);

  // Allocate the frame buffer.
  ofFboSettings settings;
  settings.width = 640;
  settings.height = 360;
  canvasFbo.allocate(settings);

  // Setup the parameters.
  tintColor.set(&quot;Tint Color&quot;, ofColor(0, 255, 0));
  clearFbo.set(&quot;Clear Background&quot;, false);

  // Setup the gui.
  guiPanel.setup(&quot;Fbo Draw&quot;, &quot;settings.json&quot;);
  guiPanel.add(tintColor);
  guiPanel.add(clearFbo);
}

void ofApp::update()
{
  canvasFbo.begin();
  {
    if (clearFbo)
    {
      // Clear the background.
      ofBackground(0);
      clearFbo = false;
    }

    if (ofGetMousePressed() &amp;&amp; !guiPanel.getShape().inside(ofGetMouseX(), ofGetMouseY()))
    {
      // Draw a circle if the mouse is pressed and not over the GUI.
      ofSetColor(255);
      ofDrawCircle(ofGetMouseX(), ofGetMouseY(), 20);
    }
  }
  canvasFbo.end();
}

void ofApp::draw()
{
  // Draw the canvas above with no tint.
  ofSetColor(255);
  canvasFbo.draw(0, 0);

  // Draw the canvas below with a tint color.
  ofSetColor(tintColor);
  canvasFbo.draw(0, 360);

  guiPanel.draw();
}

void ofApp::keyPressed(int key)
{
  if (key == ' ')
  {
    clearFbo = true;
  }
}
</code></pre><p>The <code>ofFbo</code> object lives on the GPU. The data is available as an <code>ofTexture</code> only. <code>ofTexture</code> data can be read back to the CPU using the <a href=https://openframeworks.cc/documentation/gl/ofFbo/#show_readToPixels><code>readToPixels()</code></a> function. This will store the data in the passed <code>ofPixels</code> object, which can then be used anywhere you would use any other pixel data, like with OpenCV. Note however that most systems are set up and optimized for CPU to GPU data transfer, not the other way around. While GPU to CPU does work, it should be used sparingly as it could slow down your application.</p><pre><code class=language-cpp>// ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxCv.h&quot;
#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void update();
  void draw();

  void keyPressed(int key);

  ofxCv::ContourFinder contourFinder;
  
  ofFbo canvasFbo;
  ofFbo visionFbo;

  ofPixels canvasPixels;

  ofParameter&lt;ofColor&gt; tintColor;
  ofParameter&lt;bool&gt; clearFbo;

  ofParameter&lt;float&gt; minArea;
  ofParameter&lt;float&gt; maxArea;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
    ofSetWindowShape(640, 720);

    // Allocate the frame buffers.
    ofFboSettings settings;
    settings.width = 640;
    settings.height = 360;
    canvasFbo.allocate(settings);
    visionFbo.allocate(settings);

    // Setup the parameters.
    tintColor.set(&quot;Tint Color&quot;, ofColor(0, 255, 0));
    clearFbo.set(&quot;Clear Background&quot;, false);

    minArea.set(&quot;Min Area&quot;, 0.01f, 0, 0.5f);
    maxArea.set(&quot;Max Area&quot;, 0.05f, 0, 0.5f);

    // Setup the gui.
    guiPanel.setup(&quot;Fbo Draw&quot;, &quot;settings.json&quot;);
    guiPanel.add(tintColor);
    guiPanel.add(clearFbo);
    guiPanel.add(minArea);
    guiPanel.add(maxArea);
}

void ofApp::update()
{
  canvasFbo.begin();
  {
    if (clearFbo)
    {
      // Clear the background.
      ofBackground(0);
      clearFbo = false;
    }

    if (ofGetMousePressed() &amp;&amp; !guiPanel.getShape().inside(ofGetMouseX(), ofGetMouseY()))
    {
      // Draw a circle if the mouse is pressed and not over the GUI.
      ofSetColor(255);
      ofDrawCircle(ofGetMouseX(), ofGetMouseY(), 20);
    }
  }
  canvasFbo.end();

  // Download the FBO data as pixels.
  canvasFbo.readToPixels(canvasPixels);

  // Find contours.
  contourFinder.setMinAreaNorm(minArea);
  contourFinder.setMaxAreaNorm(maxArea);
  contourFinder.findContours(canvasPixels);

  // Draw the result offscreen.
  visionFbo.begin();
  {
    ofBackground(127);

    contourFinder.draw();
  }
  visionFbo.end();
}

void ofApp::draw()
{
  // Draw the canvas above with no tint.
  ofSetColor(255);
  canvasFbo.draw(0, 0);

  // Draw the contours below with a tint color.
  ofSetColor(tintColor);
  visionFbo.draw(0, 360);

  guiPanel.draw();
}

void ofApp::keyPressed(int key)
{
  if (key == ' ')
  {
    clearFbo = true;
  }
}
</code></pre><p>An <code>ofFbo</code> is a good way to position and scale an <code>ofTexture</code> before drawing it. Everything can be drawn inside the FBO texture at native resolution, then transformed as a whole. This is particularly useful for drawing objects that don&rsquo;t have any scaling built-in, like <code>ofxCv::ContourFinder</code> for example.</p><pre><code class=language-cpp>// ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxCv.h&quot;
#include &quot;ofxGui.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void update();
  void draw();

  void keyPressed(int key);

  void toggleFullscreen(bool&amp; fullscreen);

  ofxCv::ContourFinder contourFinder;
  
  ofFbo canvasFbo;
  ofFbo visionFbo;

  ofPixels canvasPixels;

  ofParameter&lt;bool&gt; fullscreen;

  ofParameter&lt;ofColor&gt; tintColor;
  ofParameter&lt;bool&gt; clearFbo;

  ofParameter&lt;float&gt; minArea;
  ofParameter&lt;float&gt; maxArea;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  ofSetWindowShape(640, 720);

  // Allocate the frame buffers.
  ofFboSettings settings;
  settings.width = 640;
  settings.height = 360;
  canvasFbo.allocate(settings);
  visionFbo.allocate(settings);

  // Setup the parameters.
  fullscreen.set(&quot;Fullscreen&quot;, false);
  fullscreen.addListener(this, &amp;ofApp::toggleFullscreen);

  tintColor.set(&quot;Tint Color&quot;, ofColor(0, 255, 0));
  clearFbo.set(&quot;Clear Background&quot;, false);

  minArea.set(&quot;Min Area&quot;, 0.01f, 0, 0.5f);
  maxArea.set(&quot;Max Area&quot;, 0.05f, 0, 0.5f);

  // Setup the gui.
  guiPanel.setup(&quot;Fbo Draw&quot;, &quot;settings.json&quot;);
  guiPanel.add(fullscreen);
  guiPanel.add(tintColor);
  guiPanel.add(clearFbo);
  guiPanel.add(minArea);
  guiPanel.add(maxArea);
}

void ofApp::update()
{
  canvasFbo.begin();
  {
    if (clearFbo)
    {
      // Clear the background.
      ofBackground(0);
      clearFbo = false;
    }

    if (ofGetMousePressed() &amp;&amp; !guiPanel.getShape().inside(ofGetMouseX(), ofGetMouseY()))
    {
      // Draw a circle if the mouse is pressed and not over the GUI.
      ofSetColor(255);
      ofDrawCircle(ofGetMouseX(), ofGetMouseY(), 20);
    }
  }
  canvasFbo.end();

  // Download the FBO data as pixels.
  canvasFbo.readToPixels(canvasPixels);

  // Find contours.
  contourFinder.setMinAreaNorm(minArea);
  contourFinder.setMaxAreaNorm(maxArea);
  contourFinder.findContours(canvasPixels);

  // Draw the result offscreen.
  visionFbo.begin();
  {
    ofBackground(127);

    canvasFbo.draw(0, 0);

    contourFinder.draw();
  }
  visionFbo.end();
}

void ofApp::draw()
{
  if (fullscreen)
  {
    // Draw the contours fullscreen with no tint.
    ofRectangle drawRect = ofRectangle(0, 0, visionFbo.getWidth(), visionFbo.getHeight());
    drawRect.scaleTo(ofGetCurrentViewport());
    ofSetColor(255);
    visionFbo.draw(drawRect);
  }
  else
  {
    // Draw the canvas above with no tint.
    ofSetColor(255);
    canvasFbo.draw(0, 0);

    // Draw the contours below with a tint color.
    ofSetColor(tintColor);
    visionFbo.draw(0, 360);
  }

  guiPanel.draw();
}

void ofApp::keyPressed(int key)
{
  if (key == ' ')
  {
    clearFbo = true;
  }
  else if (key == OF_KEY_TAB)
  {
    fullscreen = !fullscreen;
    ofSetFullscreen(fullscreen);
  }
}

void ofApp::toggleFullscreen(bool&amp; fullscreen)
{
  ofSetFullscreen(fullscreen);
}
</code></pre><h2 id=3d>3D <a href=#3d class=anchor aria-hidden=true>#</a></h2><p>FBOs are also quite useful when working in 3D space, as they can provide a &ldquo;window&rdquo; into the 3D world. This window can then be manipulated just like any other <code>ofTexture</code>.</p><p>The following example uses a RealSense to generate a point cloud, and an <code>ofEasyCam</code> to display it in 3D.</p><pre><code class=language-cpp>camera.begin();
ofEnableDepthTest();
ofPushMatrix();

// Adjust points to match OF 3D space.
ofScale(100);
ofRotateXDeg(180);
rsDevice-&gt;getColorTex().bind();
rsDevice-&gt;getPointsMesh().draw();
rsDevice-&gt;getColorTex().unbind();

ofPopMatrix();
ofDisableDepthTest();
camera.end();
</code></pre><p>By default, the camera will take up the entire window resolution to draw the world in. This is less than ideal if we want to draw other elements in the window.</p><figure style='display:block;margin:1em auto;width:600px'><a href=fbo-overlap.png><img style='display:block;margin:0 auto' src=fbo-overlap.png alt="FBO Overlap"></a><figcaption><em>FBO Overlap</em></figcaption></figure><p>We can pass an <code>ofRectangle</code> to <a href=https://openframeworks.cc/documentation/3d/ofCamera/#show_begin><code>ofCamera.begin()</code></a> to tell it how to delimit the space it renders in.</p><pre><code class=language-cpp>// ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxCv.h&quot;
#include &quot;ofxGui.h&quot;
#include &quot;ofxRealSense2.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void update();
  void draw();

  void keyPressed(int key);

  void deviceAdded(string&amp; serialNumber);

  ofxRealSense2::Context rsContext;

  ofImage thresholdImg;

  ofxCv::ContourFinder contourFinder;
  
  ofEasyCam camera;

  ofFbo visionFbo;

  ofParameter&lt;float&gt; nearThreshold;
  ofParameter&lt;float&gt; farThreshold;

  ofParameter&lt;float&gt; minArea;
  ofParameter&lt;float&gt; maxArea;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  // Texture coordinates from RealSense are normalized (between 0-1).
  // This call normalizes all OF texture coordinates so that they match.
  ofDisableArbTex();

  ofSetWindowShape(1280, 720);

  // Start the RealSense context.
  // Devices are added in the deviceAdded() callback function.
  ofAddListener(rsContext.deviceAddedEvent, this, &amp;ofApp::deviceAdded);
  rsContext.setup(false);

  // Allocate the frame buffers.
  ofFboSettings settings;
  settings.width = 640;
  settings.height = 360;
  visionFbo.allocate(settings);

  // Setup the parameters.
  nearThreshold.set(&quot;Near Threshold&quot;, 0.01f, 0.0f, 0.1f);
  farThreshold.set(&quot;Far Threshold&quot;, 0.02f, 0.0f, 0.1f);
  minArea.set(&quot;Min Area&quot;, 0.01f, 0, 0.5f);
  maxArea.set(&quot;Max Area&quot;, 0.05f, 0, 0.5f);

  // Setup the gui.
  guiPanel.setup(&quot;Depth Threshold&quot;, &quot;settings.json&quot;);
  guiPanel.add(nearThreshold);
  guiPanel.add(farThreshold);
  guiPanel.add(minArea);
  guiPanel.add(maxArea);
}

void ofApp::deviceAdded(string&amp; serialNumber)
{
  ofLogNotice(__FUNCTION__) &lt;&lt; &quot;Starting device &quot; &lt;&lt; serialNumber;
  auto device = rsContext.getDevice(serialNumber);
  device-&gt;enableDepth();
  device-&gt;enableColor();
  device-&gt;enablePoints();
  device-&gt;startPipeline();

  // Uncomment this to add the device specific settings to the GUI.
  //guiPanel.add(device-&gt;params);
}

void ofApp::update()
{
  rsContext.update();

  shared_ptr&lt;ofxRealSense2::Device&gt; rsDevice = rsContext.getDevice(0);
  if (rsDevice &amp;&amp; rsDevice-&gt;isFrameNew())
  {
    // Threshold the depth.
    ofFloatPixels rawDepthPix = rsDevice-&gt;getRawDepthPix();
    ofFloatPixels thresholdNear, thresholdFar, thresholdResult;
    ofxCv::threshold(rawDepthPix, thresholdNear, nearThreshold);
    ofxCv::threshold(rawDepthPix, thresholdFar, farThreshold, true);
    ofxCv::bitwise_and(thresholdNear, thresholdFar, thresholdResult);
    thresholdImg.setFromPixels(thresholdResult);

    // Find contours.
    contourFinder.setMinAreaNorm(minArea);
    contourFinder.setMaxAreaNorm(maxArea);
    contourFinder.findContours(thresholdImg);

    // Draw CV operations.
    visionFbo.begin();
    {
      // Draw the threshold background.
      ofSetColor(255);
      thresholdImg.draw(0, 0);

      // Draw the contours over it.
      ofSetColor(0, 255, 0);
      contourFinder.draw();
    }
    visionFbo.end();
  }
}

void ofApp::draw()
{
  shared_ptr&lt;ofxRealSense2::Device&gt; rsDevice = rsContext.getDevice(0);
  if (rsDevice)
  {
    // 2x2 window.
    int frameWidth = ofGetWidth() / 2;
    int frameHeight = ofGetHeight() / 2;

    rsDevice-&gt;getDepthTex().draw(0, 0, frameWidth, frameHeight);
    rsDevice-&gt;getColorTex().draw(0, frameHeight, frameWidth, frameHeight);
    visionFbo.draw(frameWidth, 0, frameWidth, frameHeight);

    camera.begin(ofRectangle(frameWidth, frameHeight, frameWidth, frameHeight));
    ofEnableDepthTest();
    ofPushMatrix();

    // Adjust points to match OF 3D space.
    ofScale(100);
    ofRotateXDeg(180);

    rsDevice-&gt;getColorTex().bind();
    rsDevice-&gt;getPointsMesh().draw();
    rsDevice-&gt;getColorTex().unbind();

    ofPopMatrix();
    ofDisableDepthTest();
    camera.end();
  }

  // Draw the gui.
  guiPanel.draw();
}

void ofApp::keyPressed(int key)
{
  if (key == OF_KEY_TAB)
  {
    ofToggleFullscreen();
  }
}
</code></pre><p>While this works, we are still drawing directly in the app window, and would be unable to manipulate the camera render as a texture. A better approach is to draw the camera output directly in an <code>ofFbo</code>. Because we&rsquo;re using the entire frame buffer resolution for our drawing, we can revert to <code>ofCamera.begin()</code> without passing it a viewport.</p><pre><code class=language-cpp>// ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxCv.h&quot;
#include &quot;ofxGui.h&quot;
#include &quot;ofxRealSense2.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void update();
  void draw();

  void keyPressed(int key);

  void deviceAdded(string&amp; serialNumber);

  ofxRealSense2::Context rsContext;

  ofImage thresholdImg;

  ofxCv::ContourFinder contourFinder;
  
  ofEasyCam camera;

  ofFbo visionFbo;
  ofFbo pointsFbo;

  ofParameter&lt;float&gt; nearThreshold;
  ofParameter&lt;float&gt; farThreshold;

  ofParameter&lt;float&gt; minArea;
  ofParameter&lt;float&gt; maxArea;

  ofParameter&lt;int&gt; drawMode;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  // Texture coordinates from RealSense are normalized (between 0-1).
  // This call normalizes all OF texture coordinates so that they match.
  ofDisableArbTex();

  ofSetWindowShape(1280, 720);

  // Start the RealSense context.
  // Devices are added in the deviceAdded() callback function.
  ofAddListener(rsContext.deviceAddedEvent, this, &amp;ofApp::deviceAdded);
  rsContext.setup(false);

  // Allocate the frame buffers.
  ofFboSettings settings;
  settings.width = 640;
  settings.height = 360;
  visionFbo.allocate(settings);
  pointsFbo.allocate(settings);

  // Setup the parameters.
  nearThreshold.set(&quot;Near Threshold&quot;, 0.01f, 0.0f, 0.1f);
  farThreshold.set(&quot;Far Threshold&quot;, 0.02f, 0.0f, 0.1f);
  minArea.set(&quot;Min Area&quot;, 0.01f, 0, 0.5f);
  maxArea.set(&quot;Max Area&quot;, 0.05f, 0, 0.5f);
  drawMode.set(&quot;Draw Mode&quot;, 0, 0, 4);

  // Setup the gui.
  guiPanel.setup(&quot;Depth Threshold&quot;, &quot;settings.json&quot;);
  guiPanel.add(nearThreshold);
  guiPanel.add(farThreshold);
  guiPanel.add(minArea);
  guiPanel.add(maxArea);
  guiPanel.add(drawMode);
}

void ofApp::deviceAdded(string&amp; serialNumber)
{
  ofLogNotice(__FUNCTION__) &lt;&lt; &quot;Starting device &quot; &lt;&lt; serialNumber;
  auto device = rsContext.getDevice(serialNumber);
  device-&gt;enableDepth();
  device-&gt;enableColor();
  device-&gt;enablePoints();
  device-&gt;startPipeline();

  // Uncomment this to add the device specific settings to the GUI.
  //guiPanel.add(device-&gt;params);
}

void ofApp::update()
{
  rsContext.update();

  shared_ptr&lt;ofxRealSense2::Device&gt; rsDevice = rsContext.getDevice(0);
  if (rsDevice &amp;&amp; rsDevice-&gt;isFrameNew())
  {
    // Threshold the depth.
    ofFloatPixels rawDepthPix = rsDevice-&gt;getRawDepthPix();
    ofFloatPixels thresholdNear, thresholdFar, thresholdResult;
    ofxCv::threshold(rawDepthPix, thresholdNear, nearThreshold);
    ofxCv::threshold(rawDepthPix, thresholdFar, farThreshold, true);
    ofxCv::bitwise_and(thresholdNear, thresholdFar, thresholdResult);
    thresholdImg.setFromPixels(thresholdResult);

    // Find contours.
    contourFinder.setMinAreaNorm(minArea);
    contourFinder.setMaxAreaNorm(maxArea);
    contourFinder.findContours(thresholdImg);

    // Draw CV operations.
    visionFbo.begin();
    {
      // Draw the threshold background.
      ofSetColor(255);
      thresholdImg.draw(0, 0);

      // Draw the contours over it.
      ofSetColor(0, 255, 0);
      contourFinder.draw();
    }
    visionFbo.end();

    // Draw 3D world.
    pointsFbo.begin();
    {
      ofBackground(0);

      camera.begin();
      ofEnableDepthTest();
      ofPushMatrix();

      // Adjust points to match OF 3D space.
      ofScale(1000);
      ofRotateXDeg(180);

      rsDevice-&gt;getColorTex().bind();
      rsDevice-&gt;getPointsMesh().draw();
      rsDevice-&gt;getColorTex().unbind();
      
      ofPopMatrix();
      ofDisableDepthTest();
      camera.end();
    }
    pointsFbo.end();
  }
}

void ofApp::draw()
{
  shared_ptr&lt;ofxRealSense2::Device&gt; rsDevice = rsContext.getDevice(0);
  if (rsDevice)
  {
    if (drawMode == 0)
    {
      // 2x2 window.
      int frameWidth = ofGetWidth() / 2;
      int frameHeight = ofGetHeight() / 2;

      rsDevice-&gt;getDepthTex().draw(0, 0, frameWidth, frameHeight);
      rsDevice-&gt;getColorTex().draw(0, frameHeight, frameWidth, frameHeight);
      visionFbo.draw(frameWidth, 0, frameWidth, frameHeight);
      pointsFbo.draw(frameWidth, frameHeight, frameWidth, frameHeight);
    }
    else if(drawMode == 1)
    {
      // Draw fullscreen depth.
      rsDevice-&gt;getDepthTex().draw(ofGetCurrentViewport());
    }
    else if (drawMode == 2)
    {
      // Draw fullscreen color.
      rsDevice-&gt;getColorTex().draw(ofGetCurrentViewport());
    }
    else if (drawMode == 3)
    {
      // Draw fullscreen vision.
      visionFbo.draw(ofGetCurrentViewport());
    }
    else if (drawMode == 4)
    {
      // Draw fullscreen points.
      pointsFbo.draw(ofGetCurrentViewport());
    }
  }

  // Draw the gui.
  guiPanel.draw();
}

void ofApp::keyPressed(int key)
{
  if (key == OF_KEY_TAB)
  {
    ofToggleFullscreen();
  }
  else if (key == ' ')
  {
    drawMode = (drawMode + 1) % 5;
  }
}
</code></pre><p>You might notice that the camera controls are acting a little weird. This is because the <code>ofEasyCam</code> thinks that it&rsquo;s drawing in the bounds <code>(0, 0) to (640, 360)</code> as that is the size of the <code>ofFbo</code>, and it therefore limits the mouse controls to that area of the window. This can be adjusted by giving <code>ofEasyCam</code> actual bounds rectangle that the world is being drawn in using <a href=https://openframeworks.cc/documentation/3d/ofEasyCam/#show_setControlArea><code>ofEasyCam.setControlArea()</code></a>. This should make mouse control feel more natural.</p><pre><code class=language-cpp>// ofApp.cpp

// ...

void ofApp::draw()
{
  shared_ptr&lt;ofxRealSense2::Device&gt; rsDevice = rsContext.getDevice(0);
  if (rsDevice)
  {
    ofRectangle camDrawRect;

    if (drawMode == 0)
    {
      // 2x2 window.
      int frameWidth = ofGetWidth() / 2;
      int frameHeight = ofGetHeight() / 2;

      rsDevice-&gt;getDepthTex().draw(0, 0, frameWidth, frameHeight);
      rsDevice-&gt;getColorTex().draw(0, frameHeight, frameWidth, frameHeight);
      visionFbo.draw(frameWidth, 0, frameWidth, frameHeight);

      camDrawRect = ofRectangle(frameWidth, frameHeight, frameWidth, frameHeight);
      pointsFbo.draw(camDrawRect);
    }
    else if(drawMode == 1)
    {
      // Draw fullscreen depth.
      rsDevice-&gt;getDepthTex().draw(ofGetCurrentViewport());
    }
    else if (drawMode == 2)
    {
      // Draw fullscreen color.
      rsDevice-&gt;getColorTex().draw(ofGetCurrentViewport());
    }
    else if (drawMode == 3)
    {
      // Draw fullscreen vision.
      visionFbo.draw(ofGetCurrentViewport());
    }
    else if (drawMode == 4)
    {
      // Draw fullscreen points.
      camDrawRect = ofGetCurrentViewport();
      pointsFbo.draw(camDrawRect);
    }

    camera.setControlArea(camDrawRect);
  }

  // Draw the gui.
  guiPanel.draw();
}

// ...
</code></pre><figure style='display:block;margin:1em auto;width:600px'><a href=fbo-quads.png><img style='display:block;margin:0 auto' src=fbo-quads.png alt="FBO Quads"></a><figcaption><em>FBO Quads</em></figcaption></figure><h2 id=multi-window>Multi-window <a href=#multi-window class=anchor aria-hidden=true>#</a></h2><p>When working in installation settings, we will usually have a multi-display setup. A common configuration is to have one monitor for controls and preview windows, and another display (either a large screen monitor or projector) for the main content. openFrameworks makes working with multiple windows easy, and includes some examples in <code>/path/to/OF/examples/windowing</code> demonstrating how this works.</p><p>The important thing to remember is that this needs to be configured before the <code>ofApp</code> starts running, therefore in the <code>main()</code> function found in <code>main.cpp</code>.</p><pre><code class=language-cpp>// main.cpp
#include &quot;ofApp.h&quot;

int main()
{
  ofGLFWWindowSettings settings;

  settings.setSize(1280, 720);
  settings.setPosition(glm::vec2(0, 0));
  settings.resizable = true;
  settings.decorated = true;
  settings.title = &quot;Party Time&quot;;

  auto mainApp = make_shared&lt;ofApp&gt;();

  // Control window.
  auto controlWindow = ofCreateWindow(settings);
  controlWindow-&gt;setWindowPosition(ofGetScreenWidth() / 2 - settings.getWidth() / 2, ofGetScreenHeight() / 2 - settings.getHeight() / 2);

  // Main window.
  settings.setSize(1920, 1080);
  settings.setPosition(glm::vec2(1920, 0));
  settings.resizable = false;
  settings.decorated = false;
  settings.shareContextWith = controlWindow;
  auto projWindow = ofCreateWindow(settings);
  projWindow-&gt;setVerticalSync(false);
  ofAddListener(projWindow-&gt;events().draw, mainApp.get(), &amp;ofApp::drawProjection);

  ofRunApp(controlWindow, mainApp);
  ofRunMainLoop();
}
</code></pre><p>One of the simplest ways to set this up is to use a second draw function in the same <code>ofApp</code>, which will draw in the second window. Note that by just redrawing our FBOs in the second window, we don&rsquo;t need to re-render the contours or the point cloud, as this is already saved in the frame buffer texture.</p><pre><code class=language-cpp>// ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxCv.h&quot;
#include &quot;ofxGui.h&quot;
#include &quot;ofxRealSense2.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void update();
  void draw();

  void drawProjection(ofEventArgs&amp; args);

  void keyPressed(int key);

  void deviceAdded(string&amp; serialNumber);

  ofxRealSense2::Context rsContext;

  ofImage thresholdImg;

  ofxCv::ContourFinder contourFinder;
  
  ofEasyCam camera;

  ofFbo visionFbo;
  ofFbo pointsFbo;

  ofParameter&lt;float&gt; nearThreshold;
  ofParameter&lt;float&gt; farThreshold;

  ofParameter&lt;float&gt; minArea;
  ofParameter&lt;float&gt; maxArea;

  ofParameter&lt;int&gt; drawMode;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  // Texture coordinates from RealSense are normalized (between 0-1).
  // This call normalizes all OF texture coordinates so that they match.
  ofDisableArbTex();

  // Start the RealSense context.
  // Devices are added in the deviceAdded() callback function.
  ofAddListener(rsContext.deviceAddedEvent, this, &amp;ofApp::deviceAdded);
  rsContext.setup(false);

  // Allocate the frame buffers.
  ofFboSettings settings;
  settings.width = 640;
  settings.height = 360;
  visionFbo.allocate(settings);
  pointsFbo.allocate(settings);

  // Setup the parameters.
  nearThreshold.set(&quot;Near Threshold&quot;, 0.01f, 0.0f, 0.1f);
  farThreshold.set(&quot;Far Threshold&quot;, 0.02f, 0.0f, 0.1f);
  minArea.set(&quot;Min Area&quot;, 0.01f, 0, 0.5f);
  maxArea.set(&quot;Max Area&quot;, 0.05f, 0, 0.5f);
  drawMode.set(&quot;Draw Mode&quot;, 0, 0, 3);

  // Setup the gui.
  guiPanel.setup(&quot;Depth Threshold&quot;, &quot;settings.json&quot;);
  guiPanel.add(nearThreshold);
  guiPanel.add(farThreshold);
  guiPanel.add(minArea);
  guiPanel.add(maxArea);
  guiPanel.add(drawMode);
}

void ofApp::deviceAdded(string&amp; serialNumber)
{
  ofLogNotice(__FUNCTION__) &lt;&lt; &quot;Starting device &quot; &lt;&lt; serialNumber;
  auto device = rsContext.getDevice(serialNumber);
  device-&gt;enableDepth();
  device-&gt;enableColor();
  device-&gt;enablePoints();
  device-&gt;startPipeline();

  // Uncomment this to add the device specific settings to the GUI.
  //guiPanel.add(device-&gt;params);
}

void ofApp::update()
{
  rsContext.update();

  shared_ptr&lt;ofxRealSense2::Device&gt; rsDevice = rsContext.getDevice(0);
  if (rsDevice &amp;&amp; rsDevice-&gt;isFrameNew())
  {
    // Threshold the depth.
    ofFloatPixels rawDepthPix = rsDevice-&gt;getRawDepthPix();
    ofFloatPixels thresholdNear, thresholdFar, thresholdResult;
    ofxCv::threshold(rawDepthPix, thresholdNear, nearThreshold);
    ofxCv::threshold(rawDepthPix, thresholdFar, farThreshold, true);
    ofxCv::bitwise_and(thresholdNear, thresholdFar, thresholdResult);
    thresholdImg.setFromPixels(thresholdResult);

    // Find contours.
    contourFinder.setMinAreaNorm(minArea);
    contourFinder.setMaxAreaNorm(maxArea);
    contourFinder.findContours(thresholdImg);

    // Draw CV operations.
    visionFbo.begin();
    {
      // Draw the threshold background.
      ofSetColor(255);
      thresholdImg.draw(0, 0);

      // Draw the contours over it.
      ofSetColor(0, 255, 0);
      contourFinder.draw();
    }
    visionFbo.end();

    // Draw 3D world.
    pointsFbo.begin();
    {
      ofBackground(0);

      camera.begin();
      ofEnableDepthTest();
      ofPushMatrix();

      // Adjust points to match OF 3D space.
      ofScale(1000);
      ofRotateXDeg(180);

      rsDevice-&gt;getColorTex().bind();
      rsDevice-&gt;getPointsMesh().draw();
      rsDevice-&gt;getColorTex().unbind();
      
      ofPopMatrix();
      ofDisableDepthTest();
      camera.end();
    }
    pointsFbo.end();
  }
}

void ofApp::draw()
{
  shared_ptr&lt;ofxRealSense2::Device&gt; rsDevice = rsContext.getDevice(0);
  if (rsDevice)
  {
    // 2x2 window.
    int frameWidth = ofGetWidth() / 2;
    int frameHeight = ofGetHeight() / 2;

    rsDevice-&gt;getDepthTex().draw(0, 0, frameWidth, frameHeight);
    rsDevice-&gt;getColorTex().draw(0, frameHeight, frameWidth, frameHeight);
    visionFbo.draw(frameWidth, 0, frameWidth, frameHeight);

    ofRectangle camDrawRect = ofRectangle(frameWidth, frameHeight, frameWidth, frameHeight);
    pointsFbo.draw(camDrawRect);

    camera.setControlArea(camDrawRect);
  }

  // Draw the gui.
  guiPanel.draw();
}

void ofApp::drawProjection(ofEventArgs&amp; args)
{
  shared_ptr&lt;ofxRealSense2::Device&gt; rsDevice = rsContext.getDevice(0);
  if (rsDevice)
  {
    if (drawMode == 0)
    {
      // Draw fullscreen depth.
      rsDevice-&gt;getDepthTex().draw(ofGetCurrentViewport());
    }
    else if (drawMode == 1)
    {
      // Draw fullscreen color.
      rsDevice-&gt;getColorTex().draw(ofGetCurrentViewport());
    }
    else if (drawMode == 2)
    {
      // Draw fullscreen vision.
      visionFbo.draw(ofGetCurrentViewport());
    }
    else if (drawMode == 3)
    {
      // Draw fullscreen points.
      pointsFbo.draw(ofGetCurrentViewport());
    }
  }
}

void ofApp::keyPressed(int key)
{
  if (key == ' ')
  {
    drawMode = (drawMode + 1) % 4;
  }
}
</code></pre><h2 id=blending>Blending <a href=#blending class=anchor aria-hidden=true>#</a></h2><p>If we think of FBOs as layers, we can get interesting results by stacking them and applying different blend modes to them. OpenGL has built-in blend functions that are used to calculate the color of pixels that are overlaid in the same buffer, and these can be accessed using the <a href=https://openframeworks.cc/documentation/graphics/ofGraphics/#!show_ofEnableBlendMode><code>ofEnableBlendMode()</code></a> global function. If you use Photoshop, some of these like <code>OF_BLENDMODE_ADD</code> and <code>OF_BLENDMODE_MULTIPLY</code> should sound familiar.</p><p>Let&rsquo;s update our RealSense example to render the point cloud in the projection window using custom blend modes.</p><ul><li>Set the RealSense alignment mode to <code>Align::Color</code> to ensure that depth, color, and point frames are in the same coordinate space.</li><li>Use a new FBO to render a masked color image, by multiplying the threshold image by the full color image. This is done using <code>OF_BLENDMODE_MULTIPLY</code>. Note that this could have been achieved using OpenCV, but using blend modes happens almost automatically on the <code>ofTexture</code>!</li><li>Draw the point cloud using the masked color image for texture, and <code>OF_BLENDMODE_SCREEN</code>. This ensures that color pixels override any black pixels and get drawn, even if they are behind the black pixels in 3D space.</li></ul><pre><code class=language-cpp>// ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxCv.h&quot;
#include &quot;ofxGui.h&quot;
#include &quot;ofxRealSense2.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void update();
  void draw();

  void drawProjection(ofEventArgs&amp; args);

  void deviceAdded(string&amp; serialNumber);

  ofxRealSense2::Context rsContext;

  ofImage thresholdImg;

  ofxCv::ContourFinder contourFinder;
  
  ofEasyCam camera;

  ofFbo visionFbo;
  ofFbo colorFbo;
  ofFbo pointsFbo;

  ofParameter&lt;float&gt; nearThreshold;
  ofParameter&lt;float&gt; farThreshold;

  ofParameter&lt;float&gt; minArea;
  ofParameter&lt;float&gt; maxArea;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  // Texture coordinates from RealSense are normalized (between 0-1).
  // This call normalizes all OF texture coordinates so that they match.
  ofDisableArbTex();

  // Start the RealSense context.
  // Devices are added in the deviceAdded() callback function.
  ofAddListener(rsContext.deviceAddedEvent, this, &amp;ofApp::deviceAdded);
  rsContext.setup(false);

  // Allocate the frame buffers.
  ofFboSettings settings;
  settings.width = 640;
  settings.height = 360;
  visionFbo.allocate(settings);
  colorFbo.allocate(settings);
  pointsFbo.allocate(settings);

  // Setup the parameters.
  nearThreshold.set(&quot;Near Threshold&quot;, 0.01f, 0.0f, 0.1f);
  farThreshold.set(&quot;Far Threshold&quot;, 0.02f, 0.0f, 0.1f);
  
  minArea.set(&quot;Min Area&quot;, 0.01f, 0, 0.5f);
  maxArea.set(&quot;Max Area&quot;, 0.05f, 0, 0.5f);

  // Setup the gui.
  guiPanel.setup(&quot;Depth Threshold&quot;, &quot;settings.json&quot;);
  guiPanel.add(nearThreshold);
  guiPanel.add(farThreshold);
  guiPanel.add(minArea);
  guiPanel.add(maxArea);
}

void ofApp::deviceAdded(string&amp; serialNumber)
{
  ofLogNotice(__FUNCTION__) &lt;&lt; &quot;Starting device &quot; &lt;&lt; serialNumber;
  auto device = rsContext.getDevice(serialNumber);
  device-&gt;enableDepth();
  device-&gt;enableColor();
  device-&gt;enablePoints();
  device-&gt;startPipeline();

  device-&gt;alignMode = ofxRealSense2::Device::Align::Color;

  // Uncomment this to add the device specific settings to the GUI.
  //guiPanel.add(device-&gt;params);
}

void ofApp::update()
{
  rsContext.update();

  shared_ptr&lt;ofxRealSense2::Device&gt; rsDevice = rsContext.getDevice(0);
  if (rsDevice &amp;&amp; rsDevice-&gt;isFrameNew())
  {
    // Threshold the depth.
    ofFloatPixels rawDepthPix = rsDevice-&gt;getRawDepthPix();
    ofFloatPixels thresholdNear, thresholdFar, thresholdResult;
    ofxCv::threshold(rawDepthPix, thresholdNear, nearThreshold);
    ofxCv::threshold(rawDepthPix, thresholdFar, farThreshold, true);
    ofxCv::bitwise_and(thresholdNear, thresholdFar, thresholdResult);
    thresholdImg.setFromPixels(thresholdResult);

    // Find contours.
    contourFinder.setMinAreaNorm(minArea);
    contourFinder.setMaxAreaNorm(maxArea);
    contourFinder.findContours(thresholdImg);

    // Draw CV operations.
    visionFbo.begin();
    {
      // Draw the threshold background.
      ofSetColor(255);
      thresholdImg.draw(0, 0);

      // Draw the contours over it.
      ofSetColor(0, 255, 0);
      contourFinder.draw();
    }
    visionFbo.end();

    // Draw masked color.
    colorFbo.begin();
    {
      // Draw the color background.
      rsDevice-&gt;getColorTex().draw(0, 0);

      // Set the blend mode to multiply to clip out any black pixels.
      ofEnableBlendMode(OF_BLENDMODE_MULTIPLY);

      // Draw the threshold image on top.
      // The result will be a colored threshold image.
      thresholdImg.draw(0, 0);
    }
    colorFbo.end();

    // Draw 3D world.
    pointsFbo.begin();
    {
      ofBackground(0);

      camera.begin();
      ofPushMatrix();

      // Adjust points to match OF 3D space.
      ofScale(1000);
      ofRotateXDeg(180);

      // Set the blend mode to screen to let any pixels with color through.
      ofEnableBlendMode(OF_BLENDMODE_SCREEN);

      // Draw the point cloud using the masked color texture.
      colorFbo.getTexture().bind();
      rsDevice-&gt;getPointsMesh().draw();
      colorFbo.getTexture().unbind();
      
      ofPopMatrix();
      camera.end();
    }
    pointsFbo.end();
  }
}

void ofApp::draw()
{
  shared_ptr&lt;ofxRealSense2::Device&gt; rsDevice = rsContext.getDevice(0);
  if (rsDevice)
  {
    // 2x2 window.
    int frameWidth = ofGetWidth() / 2;
    int frameHeight = ofGetHeight() / 2;

    rsDevice-&gt;getDepthTex().draw(0, 0, frameWidth, frameHeight);
    colorFbo.draw(0, frameHeight, frameWidth, frameHeight);
    visionFbo.draw(frameWidth, 0, frameWidth, frameHeight);

    ofRectangle camDrawRect = ofRectangle(frameWidth, frameHeight, frameWidth, frameHeight);
    pointsFbo.draw(camDrawRect);

    camera.setControlArea(camDrawRect);
  }

  // Draw the gui.
  guiPanel.draw();
}

void ofApp::drawProjection(ofEventArgs&amp; args)
{
  // Draw fullscreen points.
  pointsFbo.draw(ofGetCurrentViewport());
}
</code></pre><p>Finally, we can add custom alpha blending on the projection output.</p><ul><li>Change the background in the points FBO from <code>ofBackground(0)</code> to <a href=https://openframeworks.cc/documentation/graphics/ofGraphics/#!show_ofClear><code>ofClear(0, 0)</code></a>. <code>ofClear()</code> works like <code>ofBackground()</code> but can also take a second parameter for alpha. By clearing alpha to <code>0</code>, we are making the FBO texture transparent, which will make more interesting overlays.</li><li>Add a call to <a href=https://openframeworks.cc/documentation/graphics/ofGraphics/#show_ofSetBackgroundAuto><code>ofSetBackgroundAuto(false)</code></a> at the start of <code>drawProjection()</code>. This disables auto-clearing the window and will allow us to overlay textures over many frames. Note that we usually do not need to call <code>ofSetBackgroundAuto()</code> every frame, but since we are setting it for our second window, this is the best place to call this function.</li><li>Draw the background color and the point cloud FBO using a variable alpha value to get different ghostly effects.</li></ul><figure style='display:block;margin:1em auto;width:600px'><a href=fbo-fade.png><img style='display:block;margin:0 auto' src=fbo-fade.png alt="FBO Fade"></a><figcaption><em>FBO Fade</em></figcaption></figure><pre><code class=language-cpp>// ofApp.h
#pragma once

#include &quot;ofMain.h&quot;

#include &quot;ofxCv.h&quot;
#include &quot;ofxGui.h&quot;
#include &quot;ofxRealSense2.h&quot;

class ofApp : public ofBaseApp
{
public:
  void setup();
  void update();
  void draw();

  void drawProjection(ofEventArgs&amp; args);

  void deviceAdded(string&amp; serialNumber);

  ofxRealSense2::Context rsContext;

  ofImage thresholdImg;

  ofxCv::ContourFinder contourFinder;
  
  ofEasyCam camera;

  ofFbo visionFbo;
  ofFbo colorFbo;
  ofFbo pointsFbo;

  ofParameter&lt;float&gt; nearThreshold;
  ofParameter&lt;float&gt; farThreshold;

  ofParameter&lt;float&gt; minArea;
  ofParameter&lt;float&gt; maxArea;

  ofParameter&lt;int&gt; fadeAlpha;
  ofParameter&lt;int&gt; drawAlpha;

  ofxPanel guiPanel;
};
</code></pre><pre><code class=language-cpp>// ofApp.cpp
#include &quot;ofApp.h&quot;

void ofApp::setup()
{
  // Texture coordinates from RealSense are normalized (between 0-1).
  // This call normalizes all OF texture coordinates so that they match.
  ofDisableArbTex();

  // Start the RealSense context.
  // Devices are added in the deviceAdded() callback function.
  ofAddListener(rsContext.deviceAddedEvent, this, &amp;ofApp::deviceAdded);
  rsContext.setup(false);

  // Allocate the frame buffers.
  ofFboSettings settings;
  settings.width = 640;
  settings.height = 360;
  visionFbo.allocate(settings);
  colorFbo.allocate(settings);
  pointsFbo.allocate(settings);

  // Setup the parameters.
  nearThreshold.set(&quot;Near Threshold&quot;, 0.01f, 0.0f, 0.1f);
  farThreshold.set(&quot;Far Threshold&quot;, 0.02f, 0.0f, 0.1f);
  
  minArea.set(&quot;Min Area&quot;, 0.01f, 0, 0.5f);
  maxArea.set(&quot;Max Area&quot;, 0.05f, 0, 0.5f);

  fadeAlpha.set(&quot;Fade Alpha&quot;, 16, 0, 255);
  drawAlpha.set(&quot;Draw Alpha&quot;, 127, 0, 255);

  // Setup the gui.
  guiPanel.setup(&quot;Depth Threshold&quot;, &quot;settings.json&quot;);
  guiPanel.add(nearThreshold);
  guiPanel.add(farThreshold);
  guiPanel.add(minArea);
  guiPanel.add(maxArea);
  guiPanel.add(fadeAlpha);
  guiPanel.add(drawAlpha);
}

void ofApp::deviceAdded(std::string&amp; serialNumber)
{
  ofLogNotice(__FUNCTION__) &lt;&lt; &quot;Starting device &quot; &lt;&lt; serialNumber;
  auto device = rsContext.getDevice(serialNumber);
  device-&gt;enableDepth();
  device-&gt;enableColor();
  device-&gt;enablePoints();
  device-&gt;startPipeline();

  device-&gt;alignMode = ofxRealSense2::Device::Align::Color;

  // Uncomment this to add the device specific settings to the GUI.
  //guiPanel.add(device-&gt;params);
}

void ofApp::update()
{
  rsContext.update();

  shared_ptr&lt;ofxRealSense2::Device&gt; rsDevice = rsContext.getDevice(0);
  if (rsDevice &amp;&amp; rsDevice-&gt;isFrameNew())
  {
    // Threshold the depth.
    ofFloatPixels rawDepthPix = rsDevice-&gt;getRawDepthPix();
    ofFloatPixels thresholdNear, thresholdFar, thresholdResult;
    ofxCv::threshold(rawDepthPix, thresholdNear, nearThreshold);
    ofxCv::threshold(rawDepthPix, thresholdFar, farThreshold, true);
    ofxCv::bitwise_and(thresholdNear, thresholdFar, thresholdResult);
    thresholdImg.setFromPixels(thresholdResult);

    // Find contours.
    contourFinder.setMinAreaNorm(minArea);
    contourFinder.setMaxAreaNorm(maxArea);
    contourFinder.findContours(thresholdImg);

    // Draw CV operations.
    visionFbo.begin();
    {
      // Draw the threshold background.
      ofSetColor(255);
      thresholdImg.draw(0, 0);

      // Draw the contours over it.
      ofSetColor(0, 255, 0);
      contourFinder.draw();
    }
    visionFbo.end();

    // Draw masked color.
    colorFbo.begin();
    {
      // Draw the color background.
      rsDevice-&gt;getColorTex().draw(0, 0);

      // Set the blend mode to multiply to clip out any black pixels.
      ofEnableBlendMode(OF_BLENDMODE_MULTIPLY);

      // Draw the threshold image on top.
      // The result will be a colored threshold image.
      thresholdImg.draw(0, 0);
    }
    colorFbo.end();

    // Draw 3D world.
    pointsFbo.begin();
    {
      ofClear(0, 0);

      camera.begin();
      ofPushMatrix();

      // Adjust points to match OF 3D space.
      ofScale(1000);
      ofRotateXDeg(180);

      // Set the blend mode to screen to let any pixels with color through.
      ofEnableBlendMode(OF_BLENDMODE_SCREEN);

      // Draw the point cloud using the masked color texture.
      colorFbo.getTexture().bind();
      rsDevice-&gt;getPointsMesh().draw();
      colorFbo.getTexture().unbind();
      
      ofPopMatrix();
      camera.end();
    }
    pointsFbo.end();
  }
}

void ofApp::draw()
{
  shared_ptr&lt;ofxRealSense2::Device&gt; rsDevice = rsContext.getDevice(0);
  if (rsDevice)
  {
    // 2x2 window.
    int frameWidth = ofGetWidth() / 2;
    int frameHeight = ofGetHeight() / 2;

    rsDevice-&gt;getDepthTex().draw(0, 0, frameWidth, frameHeight);
    colorFbo.draw(0, frameHeight, frameWidth, frameHeight);
    visionFbo.draw(frameWidth, 0, frameWidth, frameHeight);

    ofRectangle camDrawRect = ofRectangle(frameWidth, frameHeight, frameWidth, frameHeight);
    pointsFbo.draw(camDrawRect);

    camera.setControlArea(camDrawRect);
  }

  // Draw the gui.
  guiPanel.draw();
}

void ofApp::drawProjection(ofEventArgs&amp; args)
{
  // Disable clearing the background automatically.
  ofSetBackgroundAuto(false);

  // Draw a background color with optional transparency.
  ofSetColor(0, fadeAlpha);
  ofDrawRectangle(ofGetCurrentViewport());

  // Draw fullscreen points.
  ofSetColor(255, drawAlpha);
  pointsFbo.draw(ofGetCurrentViewport());
}
</code></pre><figure style="width:600px;height:400px;display:block;margin:0 auto"><iframe width=600 height=375 src=https://www.youtube.com/embed/haX3AIHSQ1E frameborder=0 allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><figcaption><i>rag & bone elevates the catwalk with technology</i></figcaption></figure><div class="page-footer-meta d-flex flex-column flex-md-row justify-content-between"></div><div class="docs-navigation d-flex justify-content-between"><a href=https://seeingmachines.betamovement.net/docs/class-9/draw-bounds/><div class="card my-1"><div class="card-body py-2">&larr; Draw Bounds</div></div></a><a class=ms-auto href=https://seeingmachines.betamovement.net/docs/class-10/classes/><div class="card my-1"><div class="card-body py-2">Classes &rarr;</div></div></a></div></main></div></div></div><footer class="footer text-muted"><div class=container-xxl><div class=row><div class="col-lg-8 order-last order-lg-first"><ul class=list-inline><li class=list-inline-item>Powered by <a class=text-muted href=https://github.com/>GitHub</a>, <a class=text-muted href=https://gohugo.io/>Hugo</a>, and <a class=text-muted href=https://getdoks.org/>Doks</a></li></ul></div><div class="col-lg-8 order-first order-lg-last text-lg-end"><ul class=list-inline></ul></div></div></div></footer><script src=https://seeingmachines.betamovement.net/js/bootstrap.min.7315382e899a7d7132d93fdf0d6682c67a93f0e72ee1a757f33f3207de3b14e2460a935c9d4cec78f86d94ab892d053c70540695eed0bbb7bf5bdc979e6f5a9f.js integrity="sha512-cxU4LomafXEy2T/fDWaCxnqT8Ocu4adX8z8yB947FOJGCpNcnUzsePhtlKuJLQU8cFQGle7Qu7e/W9yXnm9anw==" crossorigin=anonymous defer></script>
<script src=https://seeingmachines.betamovement.net/js/highlight.min.93c197e7097c47fc0788b21721b3c308e18e43299f1e45e8ff2697d13cd62908cc5949a053c1fb7242d7b4a60eb07bd106061252f7aa925ef7e91033ea59d9b9.js integrity="sha512-k8GX5wl8R/wHiLIXIbPDCOGOQymfHkXo/yaX0TzWKQjMWUmgU8H7ckLXtKYOsHvRBgYSUveqkl736RAz6lnZuQ==" crossorigin=anonymous defer></script>
<script src=https://seeingmachines.betamovement.net/main.min.162c56a0426544de0d010e66c56e321579655c400c9aae06a6823e7682de379adadf2165bd416fea191e4e7e410fbf1fd2c35a759aa43ff2e3787067669bf81b.js integrity="sha512-FixWoEJlRN4NAQ5mxW4yFXllXEAMmq4GpoI+doLeN5ra3yFlvUFv6hkeTn5BD78f0sNadZqkP/LjeHBnZpv4Gw==" crossorigin=anonymous defer></script>
<script src=https://seeingmachines.betamovement.net/index.min.203346894d44c56c3b03d0375f007f24897adc9fda8be4dcb3c8ccd7311025cad3b3b51b8ca51857ff1c89d4f4e9aba969ea61443d1cfe4bf11fa044adad8312.js integrity="sha512-IDNGiU1ExWw7A9A3XwB/JIl63J/ai+Tcs8jM1zEQJcrTs7UbjKUYV/8cidT06aupaephRD0c/kvxH6BEra2DEg==" crossorigin=anonymous defer></script></body></html>